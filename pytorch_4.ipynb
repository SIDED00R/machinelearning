{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch_4.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNlGZsqYp5IPh2dHvf9raWs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SIDED00R/machinelearning/blob/main/pytorch_4.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0r4KOL2a_Ne",
        "outputId": "e052adc9-e3aa-4126-cdb0-9f113bfe8144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from __future__ import print_function\n",
        "from torch import nn, optim, cuda\n",
        "from torch.utils import data\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn.functional as F\n",
        "import time\n",
        "\n",
        "batch_size=64\n",
        "device='cuda' if cuda.is_available() else 'cpu'\n",
        "print(f'traing mnist model on {device}\\n{\"=\"*44}')\n",
        "\n",
        "train_dataset = datasets.MNIST(root = './mnist_data?',\n",
        "                                train = True,\n",
        "                                transform=transforms.ToTensor(),\n",
        "                                download=True\n",
        "                                )\n",
        "test_dataset=datasets.MNIST(root = './mnist_data?',\n",
        "                                train = False,\n",
        "                                transform=transforms.ToTensor(),\n",
        "                                )\n",
        "train_loader=data.DataLoader(dataset=train_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=True)\n",
        "test_loader=data.DataLoader(dataset=test_dataset,\n",
        "                              batch_size=batch_size,\n",
        "                              shuffle=False)\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.conv1=nn.Conv2d(1,10,kernel_size=5)\n",
        "    self.conv2=nn.Conv2d(10,20,kernel_size=5)\n",
        "    self.mp=nn.MaxPool2d(2)\n",
        "    self.fc=nn.Linear(320,10)\n",
        "  def forward(self,x):\n",
        "    in_size=x.size(0)\n",
        "    x=F.relu(self.mp(self.conv1(x)))\n",
        "    x=F.relu(self.mp(self.conv2(x)))\n",
        "    x=x.view(in_size,-1)\n",
        "    x=self.fc(x)\n",
        "    return F.log_softmax(x)\n",
        "\n",
        "model=Net()\n",
        "model.to(device)\n",
        "criterion=nn.CrossEntropyLoss()\n",
        "optimizer=optim.SGD(model.parameters(), lr=0.01, momentum=0.5)\n",
        "def train(epoch):\n",
        "  model.train()\n",
        "  for batch_idx, (data, target) in enumerate(train_loader):\n",
        "    data,target=data.to(device), target.to(device)\n",
        "    optimizer.zero_grad()\n",
        "    ouput=model(data)\n",
        "    loss=criterion(ouput,target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx%10==0:\n",
        "      print('train epoch: {} | batch staus: {}/{} ({: .0f}%) | Loss: {: .6f}'.format(epoch,batch_idx*len(data), len(train_loader.dataset),\n",
        "                                                                                     100.*batch_idx / len(train_loader), loss.item()))\n",
        "  \n",
        "def test():\n",
        "  model.eval()\n",
        "  test_loss=0\n",
        "  correct=0\n",
        "  for data, target in test_loader:\n",
        "    data, target=data.to(device), target.to(device)\n",
        "    output=model(data)\n",
        "    test_loss += criterion(output,target).item()\n",
        "    pred=output.data.max(1,keepdim=True)[1]\n",
        "    correct += pred.eq(target.data.view_as(pred)).cpu().sum()\n",
        "\n",
        "  test_loss/=len(test_loader.dataset)\n",
        "  print(f'=======\\n test set: average loss: {test_loss: .4f}, Accuracy: {correct}/{len(test_loader.dataset)}'\n",
        "  f'({100. * correct / len(test_loader.dataset):.0f}%)')\n",
        "\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    since = time.time()\n",
        "    for epoch in range(1, 10):\n",
        "        epoch_start = time.time()\n",
        "        train(epoch)\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Training time: {m:.0f}m {s:.0f}s')\n",
        "        test()\n",
        "        m, s = divmod(time.time() - epoch_start, 60)\n",
        "        print(f'Testing time: {m:.0f}m {s:.0f}s')\n"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "traing mnist model on cpu\n",
            "============================================\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:718: UserWarning: Named tensors and all their associated APIs are an experimental feature and subject to change. Please do not use them for anything important until they are released as stable. (Triggered internally at  /pytorch/c10/core/TensorImpl.h:1156.)\n",
            "  return torch.max_pool2d(input, kernel_size, stride, padding, dilation, ceil_mode)\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:40: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "train epoch: 1 | batch staus: 0/60000 ( 0%) | Loss:  2.291279\n",
            "train epoch: 1 | batch staus: 640/60000 ( 1%) | Loss:  2.287013\n",
            "train epoch: 1 | batch staus: 1280/60000 ( 2%) | Loss:  2.283849\n",
            "train epoch: 1 | batch staus: 1920/60000 ( 3%) | Loss:  2.274393\n",
            "train epoch: 1 | batch staus: 2560/60000 ( 4%) | Loss:  2.266190\n",
            "train epoch: 1 | batch staus: 3200/60000 ( 5%) | Loss:  2.227670\n",
            "train epoch: 1 | batch staus: 3840/60000 ( 6%) | Loss:  2.229599\n",
            "train epoch: 1 | batch staus: 4480/60000 ( 7%) | Loss:  2.179660\n",
            "train epoch: 1 | batch staus: 5120/60000 ( 9%) | Loss:  2.133399\n",
            "train epoch: 1 | batch staus: 5760/60000 ( 10%) | Loss:  2.070689\n",
            "train epoch: 1 | batch staus: 6400/60000 ( 11%) | Loss:  2.012194\n",
            "train epoch: 1 | batch staus: 7040/60000 ( 12%) | Loss:  1.857902\n",
            "train epoch: 1 | batch staus: 7680/60000 ( 13%) | Loss:  1.534467\n",
            "train epoch: 1 | batch staus: 8320/60000 ( 14%) | Loss:  1.508765\n",
            "train epoch: 1 | batch staus: 8960/60000 ( 15%) | Loss:  1.249457\n",
            "train epoch: 1 | batch staus: 9600/60000 ( 16%) | Loss:  1.185692\n",
            "train epoch: 1 | batch staus: 10240/60000 ( 17%) | Loss:  0.809021\n",
            "train epoch: 1 | batch staus: 10880/60000 ( 18%) | Loss:  0.836950\n",
            "train epoch: 1 | batch staus: 11520/60000 ( 19%) | Loss:  0.787042\n",
            "train epoch: 1 | batch staus: 12160/60000 ( 20%) | Loss:  0.632033\n",
            "train epoch: 1 | batch staus: 12800/60000 ( 21%) | Loss:  0.501397\n",
            "train epoch: 1 | batch staus: 13440/60000 ( 22%) | Loss:  0.604002\n",
            "train epoch: 1 | batch staus: 14080/60000 ( 23%) | Loss:  0.540100\n",
            "train epoch: 1 | batch staus: 14720/60000 ( 25%) | Loss:  0.489120\n",
            "train epoch: 1 | batch staus: 15360/60000 ( 26%) | Loss:  0.870595\n",
            "train epoch: 1 | batch staus: 16000/60000 ( 27%) | Loss:  0.370128\n",
            "train epoch: 1 | batch staus: 16640/60000 ( 28%) | Loss:  0.693327\n",
            "train epoch: 1 | batch staus: 17280/60000 ( 29%) | Loss:  0.522915\n",
            "train epoch: 1 | batch staus: 17920/60000 ( 30%) | Loss:  0.466430\n",
            "train epoch: 1 | batch staus: 18560/60000 ( 31%) | Loss:  0.554995\n",
            "train epoch: 1 | batch staus: 19200/60000 ( 32%) | Loss:  0.681258\n",
            "train epoch: 1 | batch staus: 19840/60000 ( 33%) | Loss:  0.449492\n",
            "train epoch: 1 | batch staus: 20480/60000 ( 34%) | Loss:  0.402224\n",
            "train epoch: 1 | batch staus: 21120/60000 ( 35%) | Loss:  0.488799\n",
            "train epoch: 1 | batch staus: 21760/60000 ( 36%) | Loss:  0.370726\n",
            "train epoch: 1 | batch staus: 22400/60000 ( 37%) | Loss:  0.520633\n",
            "train epoch: 1 | batch staus: 23040/60000 ( 38%) | Loss:  0.467934\n",
            "train epoch: 1 | batch staus: 23680/60000 ( 39%) | Loss:  0.286196\n",
            "train epoch: 1 | batch staus: 24320/60000 ( 41%) | Loss:  0.361101\n",
            "train epoch: 1 | batch staus: 24960/60000 ( 42%) | Loss:  0.388688\n",
            "train epoch: 1 | batch staus: 25600/60000 ( 43%) | Loss:  0.223836\n",
            "train epoch: 1 | batch staus: 26240/60000 ( 44%) | Loss:  0.440707\n",
            "train epoch: 1 | batch staus: 26880/60000 ( 45%) | Loss:  0.336066\n",
            "train epoch: 1 | batch staus: 27520/60000 ( 46%) | Loss:  0.214478\n",
            "train epoch: 1 | batch staus: 28160/60000 ( 47%) | Loss:  0.481583\n",
            "train epoch: 1 | batch staus: 28800/60000 ( 48%) | Loss:  0.328754\n",
            "train epoch: 1 | batch staus: 29440/60000 ( 49%) | Loss:  0.289103\n",
            "train epoch: 1 | batch staus: 30080/60000 ( 50%) | Loss:  0.309181\n",
            "train epoch: 1 | batch staus: 30720/60000 ( 51%) | Loss:  0.475031\n",
            "train epoch: 1 | batch staus: 31360/60000 ( 52%) | Loss:  0.468836\n",
            "train epoch: 1 | batch staus: 32000/60000 ( 53%) | Loss:  0.515575\n",
            "train epoch: 1 | batch staus: 32640/60000 ( 54%) | Loss:  0.299529\n",
            "train epoch: 1 | batch staus: 33280/60000 ( 55%) | Loss:  0.473752\n",
            "train epoch: 1 | batch staus: 33920/60000 ( 57%) | Loss:  0.241788\n",
            "train epoch: 1 | batch staus: 34560/60000 ( 58%) | Loss:  0.337339\n",
            "train epoch: 1 | batch staus: 35200/60000 ( 59%) | Loss:  0.169896\n",
            "train epoch: 1 | batch staus: 35840/60000 ( 60%) | Loss:  0.308559\n",
            "train epoch: 1 | batch staus: 36480/60000 ( 61%) | Loss:  0.264207\n",
            "train epoch: 1 | batch staus: 37120/60000 ( 62%) | Loss:  0.277045\n",
            "train epoch: 1 | batch staus: 37760/60000 ( 63%) | Loss:  0.220611\n",
            "train epoch: 1 | batch staus: 38400/60000 ( 64%) | Loss:  0.444473\n",
            "train epoch: 1 | batch staus: 39040/60000 ( 65%) | Loss:  0.168133\n",
            "train epoch: 1 | batch staus: 39680/60000 ( 66%) | Loss:  0.404630\n",
            "train epoch: 1 | batch staus: 40320/60000 ( 67%) | Loss:  0.473310\n",
            "train epoch: 1 | batch staus: 40960/60000 ( 68%) | Loss:  0.156936\n",
            "train epoch: 1 | batch staus: 41600/60000 ( 69%) | Loss:  0.443380\n",
            "train epoch: 1 | batch staus: 42240/60000 ( 70%) | Loss:  0.303397\n",
            "train epoch: 1 | batch staus: 42880/60000 ( 71%) | Loss:  0.207997\n",
            "train epoch: 1 | batch staus: 43520/60000 ( 72%) | Loss:  0.269720\n",
            "train epoch: 1 | batch staus: 44160/60000 ( 74%) | Loss:  0.282312\n",
            "train epoch: 1 | batch staus: 44800/60000 ( 75%) | Loss:  0.408539\n",
            "train epoch: 1 | batch staus: 45440/60000 ( 76%) | Loss:  0.338059\n",
            "train epoch: 1 | batch staus: 46080/60000 ( 77%) | Loss:  0.475214\n",
            "train epoch: 1 | batch staus: 46720/60000 ( 78%) | Loss:  0.266234\n",
            "train epoch: 1 | batch staus: 47360/60000 ( 79%) | Loss:  0.170943\n",
            "train epoch: 1 | batch staus: 48000/60000 ( 80%) | Loss:  0.218512\n",
            "train epoch: 1 | batch staus: 48640/60000 ( 81%) | Loss:  0.179430\n",
            "train epoch: 1 | batch staus: 49280/60000 ( 82%) | Loss:  0.225895\n",
            "train epoch: 1 | batch staus: 49920/60000 ( 83%) | Loss:  0.247714\n",
            "train epoch: 1 | batch staus: 50560/60000 ( 84%) | Loss:  0.263776\n",
            "train epoch: 1 | batch staus: 51200/60000 ( 85%) | Loss:  0.224219\n",
            "train epoch: 1 | batch staus: 51840/60000 ( 86%) | Loss:  0.182507\n",
            "train epoch: 1 | batch staus: 52480/60000 ( 87%) | Loss:  0.293919\n",
            "train epoch: 1 | batch staus: 53120/60000 ( 88%) | Loss:  0.132331\n",
            "train epoch: 1 | batch staus: 53760/60000 ( 90%) | Loss:  0.167807\n",
            "train epoch: 1 | batch staus: 54400/60000 ( 91%) | Loss:  0.204534\n",
            "train epoch: 1 | batch staus: 55040/60000 ( 92%) | Loss:  0.188594\n",
            "train epoch: 1 | batch staus: 55680/60000 ( 93%) | Loss:  0.408346\n",
            "train epoch: 1 | batch staus: 56320/60000 ( 94%) | Loss:  0.241763\n",
            "train epoch: 1 | batch staus: 56960/60000 ( 95%) | Loss:  0.329573\n",
            "train epoch: 1 | batch staus: 57600/60000 ( 96%) | Loss:  0.300528\n",
            "train epoch: 1 | batch staus: 58240/60000 ( 97%) | Loss:  0.102713\n",
            "train epoch: 1 | batch staus: 58880/60000 ( 98%) | Loss:  0.258220\n",
            "train epoch: 1 | batch staus: 59520/60000 ( 99%) | Loss:  0.222027\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0032, Accuracy: 9427/10000(94%)\n",
            "Testing time: 0m 25s\n",
            "train epoch: 2 | batch staus: 0/60000 ( 0%) | Loss:  0.198446\n",
            "train epoch: 2 | batch staus: 640/60000 ( 1%) | Loss:  0.153183\n",
            "train epoch: 2 | batch staus: 1280/60000 ( 2%) | Loss:  0.319408\n",
            "train epoch: 2 | batch staus: 1920/60000 ( 3%) | Loss:  0.053223\n",
            "train epoch: 2 | batch staus: 2560/60000 ( 4%) | Loss:  0.161243\n",
            "train epoch: 2 | batch staus: 3200/60000 ( 5%) | Loss:  0.152750\n",
            "train epoch: 2 | batch staus: 3840/60000 ( 6%) | Loss:  0.204709\n",
            "train epoch: 2 | batch staus: 4480/60000 ( 7%) | Loss:  0.223737\n",
            "train epoch: 2 | batch staus: 5120/60000 ( 9%) | Loss:  0.185953\n",
            "train epoch: 2 | batch staus: 5760/60000 ( 10%) | Loss:  0.139650\n",
            "train epoch: 2 | batch staus: 6400/60000 ( 11%) | Loss:  0.265111\n",
            "train epoch: 2 | batch staus: 7040/60000 ( 12%) | Loss:  0.277130\n",
            "train epoch: 2 | batch staus: 7680/60000 ( 13%) | Loss:  0.207749\n",
            "train epoch: 2 | batch staus: 8320/60000 ( 14%) | Loss:  0.248266\n",
            "train epoch: 2 | batch staus: 8960/60000 ( 15%) | Loss:  0.241550\n",
            "train epoch: 2 | batch staus: 9600/60000 ( 16%) | Loss:  0.209445\n",
            "train epoch: 2 | batch staus: 10240/60000 ( 17%) | Loss:  0.145886\n",
            "train epoch: 2 | batch staus: 10880/60000 ( 18%) | Loss:  0.170621\n",
            "train epoch: 2 | batch staus: 11520/60000 ( 19%) | Loss:  0.126943\n",
            "train epoch: 2 | batch staus: 12160/60000 ( 20%) | Loss:  0.333441\n",
            "train epoch: 2 | batch staus: 12800/60000 ( 21%) | Loss:  0.209049\n",
            "train epoch: 2 | batch staus: 13440/60000 ( 22%) | Loss:  0.245412\n",
            "train epoch: 2 | batch staus: 14080/60000 ( 23%) | Loss:  0.314182\n",
            "train epoch: 2 | batch staus: 14720/60000 ( 25%) | Loss:  0.188517\n",
            "train epoch: 2 | batch staus: 15360/60000 ( 26%) | Loss:  0.203084\n",
            "train epoch: 2 | batch staus: 16000/60000 ( 27%) | Loss:  0.191090\n",
            "train epoch: 2 | batch staus: 16640/60000 ( 28%) | Loss:  0.166038\n",
            "train epoch: 2 | batch staus: 17280/60000 ( 29%) | Loss:  0.198936\n",
            "train epoch: 2 | batch staus: 17920/60000 ( 30%) | Loss:  0.209079\n",
            "train epoch: 2 | batch staus: 18560/60000 ( 31%) | Loss:  0.115851\n",
            "train epoch: 2 | batch staus: 19200/60000 ( 32%) | Loss:  0.101418\n",
            "train epoch: 2 | batch staus: 19840/60000 ( 33%) | Loss:  0.137169\n",
            "train epoch: 2 | batch staus: 20480/60000 ( 34%) | Loss:  0.283283\n",
            "train epoch: 2 | batch staus: 21120/60000 ( 35%) | Loss:  0.194716\n",
            "train epoch: 2 | batch staus: 21760/60000 ( 36%) | Loss:  0.230935\n",
            "train epoch: 2 | batch staus: 22400/60000 ( 37%) | Loss:  0.172998\n",
            "train epoch: 2 | batch staus: 23040/60000 ( 38%) | Loss:  0.214070\n",
            "train epoch: 2 | batch staus: 23680/60000 ( 39%) | Loss:  0.069104\n",
            "train epoch: 2 | batch staus: 24320/60000 ( 41%) | Loss:  0.231685\n",
            "train epoch: 2 | batch staus: 24960/60000 ( 42%) | Loss:  0.100219\n",
            "train epoch: 2 | batch staus: 25600/60000 ( 43%) | Loss:  0.284880\n",
            "train epoch: 2 | batch staus: 26240/60000 ( 44%) | Loss:  0.161626\n",
            "train epoch: 2 | batch staus: 26880/60000 ( 45%) | Loss:  0.093259\n",
            "train epoch: 2 | batch staus: 27520/60000 ( 46%) | Loss:  0.139575\n",
            "train epoch: 2 | batch staus: 28160/60000 ( 47%) | Loss:  0.106521\n",
            "train epoch: 2 | batch staus: 28800/60000 ( 48%) | Loss:  0.356056\n",
            "train epoch: 2 | batch staus: 29440/60000 ( 49%) | Loss:  0.141314\n",
            "train epoch: 2 | batch staus: 30080/60000 ( 50%) | Loss:  0.117349\n",
            "train epoch: 2 | batch staus: 30720/60000 ( 51%) | Loss:  0.108802\n",
            "train epoch: 2 | batch staus: 31360/60000 ( 52%) | Loss:  0.072874\n",
            "train epoch: 2 | batch staus: 32000/60000 ( 53%) | Loss:  0.224609\n",
            "train epoch: 2 | batch staus: 32640/60000 ( 54%) | Loss:  0.128392\n",
            "train epoch: 2 | batch staus: 33280/60000 ( 55%) | Loss:  0.129296\n",
            "train epoch: 2 | batch staus: 33920/60000 ( 57%) | Loss:  0.182169\n",
            "train epoch: 2 | batch staus: 34560/60000 ( 58%) | Loss:  0.214404\n",
            "train epoch: 2 | batch staus: 35200/60000 ( 59%) | Loss:  0.089987\n",
            "train epoch: 2 | batch staus: 35840/60000 ( 60%) | Loss:  0.082922\n",
            "train epoch: 2 | batch staus: 36480/60000 ( 61%) | Loss:  0.294822\n",
            "train epoch: 2 | batch staus: 37120/60000 ( 62%) | Loss:  0.205758\n",
            "train epoch: 2 | batch staus: 37760/60000 ( 63%) | Loss:  0.145423\n",
            "train epoch: 2 | batch staus: 38400/60000 ( 64%) | Loss:  0.092897\n",
            "train epoch: 2 | batch staus: 39040/60000 ( 65%) | Loss:  0.094015\n",
            "train epoch: 2 | batch staus: 39680/60000 ( 66%) | Loss:  0.074659\n",
            "train epoch: 2 | batch staus: 40320/60000 ( 67%) | Loss:  0.238061\n",
            "train epoch: 2 | batch staus: 40960/60000 ( 68%) | Loss:  0.233408\n",
            "train epoch: 2 | batch staus: 41600/60000 ( 69%) | Loss:  0.113435\n",
            "train epoch: 2 | batch staus: 42240/60000 ( 70%) | Loss:  0.087424\n",
            "train epoch: 2 | batch staus: 42880/60000 ( 71%) | Loss:  0.066137\n",
            "train epoch: 2 | batch staus: 43520/60000 ( 72%) | Loss:  0.139545\n",
            "train epoch: 2 | batch staus: 44160/60000 ( 74%) | Loss:  0.074725\n",
            "train epoch: 2 | batch staus: 44800/60000 ( 75%) | Loss:  0.240390\n",
            "train epoch: 2 | batch staus: 45440/60000 ( 76%) | Loss:  0.061426\n",
            "train epoch: 2 | batch staus: 46080/60000 ( 77%) | Loss:  0.250274\n",
            "train epoch: 2 | batch staus: 46720/60000 ( 78%) | Loss:  0.109337\n",
            "train epoch: 2 | batch staus: 47360/60000 ( 79%) | Loss:  0.124919\n",
            "train epoch: 2 | batch staus: 48000/60000 ( 80%) | Loss:  0.055592\n",
            "train epoch: 2 | batch staus: 48640/60000 ( 81%) | Loss:  0.228266\n",
            "train epoch: 2 | batch staus: 49280/60000 ( 82%) | Loss:  0.110744\n",
            "train epoch: 2 | batch staus: 49920/60000 ( 83%) | Loss:  0.058782\n",
            "train epoch: 2 | batch staus: 50560/60000 ( 84%) | Loss:  0.165613\n",
            "train epoch: 2 | batch staus: 51200/60000 ( 85%) | Loss:  0.202318\n",
            "train epoch: 2 | batch staus: 51840/60000 ( 86%) | Loss:  0.056652\n",
            "train epoch: 2 | batch staus: 52480/60000 ( 87%) | Loss:  0.075921\n",
            "train epoch: 2 | batch staus: 53120/60000 ( 88%) | Loss:  0.046295\n",
            "train epoch: 2 | batch staus: 53760/60000 ( 90%) | Loss:  0.148606\n",
            "train epoch: 2 | batch staus: 54400/60000 ( 91%) | Loss:  0.146385\n",
            "train epoch: 2 | batch staus: 55040/60000 ( 92%) | Loss:  0.230680\n",
            "train epoch: 2 | batch staus: 55680/60000 ( 93%) | Loss:  0.176534\n",
            "train epoch: 2 | batch staus: 56320/60000 ( 94%) | Loss:  0.149380\n",
            "train epoch: 2 | batch staus: 56960/60000 ( 95%) | Loss:  0.097160\n",
            "train epoch: 2 | batch staus: 57600/60000 ( 96%) | Loss:  0.199522\n",
            "train epoch: 2 | batch staus: 58240/60000 ( 97%) | Loss:  0.036738\n",
            "train epoch: 2 | batch staus: 58880/60000 ( 98%) | Loss:  0.052194\n",
            "train epoch: 2 | batch staus: 59520/60000 ( 99%) | Loss:  0.158170\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0017, Accuracy: 9678/10000(97%)\n",
            "Testing time: 0m 25s\n",
            "train epoch: 3 | batch staus: 0/60000 ( 0%) | Loss:  0.061041\n",
            "train epoch: 3 | batch staus: 640/60000 ( 1%) | Loss:  0.196598\n",
            "train epoch: 3 | batch staus: 1280/60000 ( 2%) | Loss:  0.079743\n",
            "train epoch: 3 | batch staus: 1920/60000 ( 3%) | Loss:  0.193918\n",
            "train epoch: 3 | batch staus: 2560/60000 ( 4%) | Loss:  0.063956\n",
            "train epoch: 3 | batch staus: 3200/60000 ( 5%) | Loss:  0.092439\n",
            "train epoch: 3 | batch staus: 3840/60000 ( 6%) | Loss:  0.080669\n",
            "train epoch: 3 | batch staus: 4480/60000 ( 7%) | Loss:  0.077854\n",
            "train epoch: 3 | batch staus: 5120/60000 ( 9%) | Loss:  0.070256\n",
            "train epoch: 3 | batch staus: 5760/60000 ( 10%) | Loss:  0.203897\n",
            "train epoch: 3 | batch staus: 6400/60000 ( 11%) | Loss:  0.148305\n",
            "train epoch: 3 | batch staus: 7040/60000 ( 12%) | Loss:  0.137749\n",
            "train epoch: 3 | batch staus: 7680/60000 ( 13%) | Loss:  0.161198\n",
            "train epoch: 3 | batch staus: 8320/60000 ( 14%) | Loss:  0.080727\n",
            "train epoch: 3 | batch staus: 8960/60000 ( 15%) | Loss:  0.180599\n",
            "train epoch: 3 | batch staus: 9600/60000 ( 16%) | Loss:  0.058003\n",
            "train epoch: 3 | batch staus: 10240/60000 ( 17%) | Loss:  0.201954\n",
            "train epoch: 3 | batch staus: 10880/60000 ( 18%) | Loss:  0.063777\n",
            "train epoch: 3 | batch staus: 11520/60000 ( 19%) | Loss:  0.040480\n",
            "train epoch: 3 | batch staus: 12160/60000 ( 20%) | Loss:  0.068693\n",
            "train epoch: 3 | batch staus: 12800/60000 ( 21%) | Loss:  0.121978\n",
            "train epoch: 3 | batch staus: 13440/60000 ( 22%) | Loss:  0.038995\n",
            "train epoch: 3 | batch staus: 14080/60000 ( 23%) | Loss:  0.035321\n",
            "train epoch: 3 | batch staus: 14720/60000 ( 25%) | Loss:  0.149782\n",
            "train epoch: 3 | batch staus: 15360/60000 ( 26%) | Loss:  0.145776\n",
            "train epoch: 3 | batch staus: 16000/60000 ( 27%) | Loss:  0.107751\n",
            "train epoch: 3 | batch staus: 16640/60000 ( 28%) | Loss:  0.137574\n",
            "train epoch: 3 | batch staus: 17280/60000 ( 29%) | Loss:  0.103692\n",
            "train epoch: 3 | batch staus: 17920/60000 ( 30%) | Loss:  0.104700\n",
            "train epoch: 3 | batch staus: 18560/60000 ( 31%) | Loss:  0.082209\n",
            "train epoch: 3 | batch staus: 19200/60000 ( 32%) | Loss:  0.161219\n",
            "train epoch: 3 | batch staus: 19840/60000 ( 33%) | Loss:  0.029467\n",
            "train epoch: 3 | batch staus: 20480/60000 ( 34%) | Loss:  0.132198\n",
            "train epoch: 3 | batch staus: 21120/60000 ( 35%) | Loss:  0.157476\n",
            "train epoch: 3 | batch staus: 21760/60000 ( 36%) | Loss:  0.115498\n",
            "train epoch: 3 | batch staus: 22400/60000 ( 37%) | Loss:  0.216794\n",
            "train epoch: 3 | batch staus: 23040/60000 ( 38%) | Loss:  0.191762\n",
            "train epoch: 3 | batch staus: 23680/60000 ( 39%) | Loss:  0.091755\n",
            "train epoch: 3 | batch staus: 24320/60000 ( 41%) | Loss:  0.095935\n",
            "train epoch: 3 | batch staus: 24960/60000 ( 42%) | Loss:  0.046378\n",
            "train epoch: 3 | batch staus: 25600/60000 ( 43%) | Loss:  0.027747\n",
            "train epoch: 3 | batch staus: 26240/60000 ( 44%) | Loss:  0.231882\n",
            "train epoch: 3 | batch staus: 26880/60000 ( 45%) | Loss:  0.101410\n",
            "train epoch: 3 | batch staus: 27520/60000 ( 46%) | Loss:  0.093112\n",
            "train epoch: 3 | batch staus: 28160/60000 ( 47%) | Loss:  0.086592\n",
            "train epoch: 3 | batch staus: 28800/60000 ( 48%) | Loss:  0.030327\n",
            "train epoch: 3 | batch staus: 29440/60000 ( 49%) | Loss:  0.253026\n",
            "train epoch: 3 | batch staus: 30080/60000 ( 50%) | Loss:  0.015461\n",
            "train epoch: 3 | batch staus: 30720/60000 ( 51%) | Loss:  0.079300\n",
            "train epoch: 3 | batch staus: 31360/60000 ( 52%) | Loss:  0.137242\n",
            "train epoch: 3 | batch staus: 32000/60000 ( 53%) | Loss:  0.075845\n",
            "train epoch: 3 | batch staus: 32640/60000 ( 54%) | Loss:  0.172166\n",
            "train epoch: 3 | batch staus: 33280/60000 ( 55%) | Loss:  0.130537\n",
            "train epoch: 3 | batch staus: 33920/60000 ( 57%) | Loss:  0.073783\n",
            "train epoch: 3 | batch staus: 34560/60000 ( 58%) | Loss:  0.059567\n",
            "train epoch: 3 | batch staus: 35200/60000 ( 59%) | Loss:  0.109957\n",
            "train epoch: 3 | batch staus: 35840/60000 ( 60%) | Loss:  0.111896\n",
            "train epoch: 3 | batch staus: 36480/60000 ( 61%) | Loss:  0.076537\n",
            "train epoch: 3 | batch staus: 37120/60000 ( 62%) | Loss:  0.177925\n",
            "train epoch: 3 | batch staus: 37760/60000 ( 63%) | Loss:  0.119035\n",
            "train epoch: 3 | batch staus: 38400/60000 ( 64%) | Loss:  0.123860\n",
            "train epoch: 3 | batch staus: 39040/60000 ( 65%) | Loss:  0.050957\n",
            "train epoch: 3 | batch staus: 39680/60000 ( 66%) | Loss:  0.104833\n",
            "train epoch: 3 | batch staus: 40320/60000 ( 67%) | Loss:  0.063690\n",
            "train epoch: 3 | batch staus: 40960/60000 ( 68%) | Loss:  0.324596\n",
            "train epoch: 3 | batch staus: 41600/60000 ( 69%) | Loss:  0.220888\n",
            "train epoch: 3 | batch staus: 42240/60000 ( 70%) | Loss:  0.097682\n",
            "train epoch: 3 | batch staus: 42880/60000 ( 71%) | Loss:  0.056915\n",
            "train epoch: 3 | batch staus: 43520/60000 ( 72%) | Loss:  0.090740\n",
            "train epoch: 3 | batch staus: 44160/60000 ( 74%) | Loss:  0.028402\n",
            "train epoch: 3 | batch staus: 44800/60000 ( 75%) | Loss:  0.068184\n",
            "train epoch: 3 | batch staus: 45440/60000 ( 76%) | Loss:  0.021689\n",
            "train epoch: 3 | batch staus: 46080/60000 ( 77%) | Loss:  0.094086\n",
            "train epoch: 3 | batch staus: 46720/60000 ( 78%) | Loss:  0.097512\n",
            "train epoch: 3 | batch staus: 47360/60000 ( 79%) | Loss:  0.064746\n",
            "train epoch: 3 | batch staus: 48000/60000 ( 80%) | Loss:  0.010911\n",
            "train epoch: 3 | batch staus: 48640/60000 ( 81%) | Loss:  0.094510\n",
            "train epoch: 3 | batch staus: 49280/60000 ( 82%) | Loss:  0.161752\n",
            "train epoch: 3 | batch staus: 49920/60000 ( 83%) | Loss:  0.070728\n",
            "train epoch: 3 | batch staus: 50560/60000 ( 84%) | Loss:  0.073358\n",
            "train epoch: 3 | batch staus: 51200/60000 ( 85%) | Loss:  0.092724\n",
            "train epoch: 3 | batch staus: 51840/60000 ( 86%) | Loss:  0.049603\n",
            "train epoch: 3 | batch staus: 52480/60000 ( 87%) | Loss:  0.123349\n",
            "train epoch: 3 | batch staus: 53120/60000 ( 88%) | Loss:  0.046578\n",
            "train epoch: 3 | batch staus: 53760/60000 ( 90%) | Loss:  0.049716\n",
            "train epoch: 3 | batch staus: 54400/60000 ( 91%) | Loss:  0.104087\n",
            "train epoch: 3 | batch staus: 55040/60000 ( 92%) | Loss:  0.073079\n",
            "train epoch: 3 | batch staus: 55680/60000 ( 93%) | Loss:  0.037860\n",
            "train epoch: 3 | batch staus: 56320/60000 ( 94%) | Loss:  0.372955\n",
            "train epoch: 3 | batch staus: 56960/60000 ( 95%) | Loss:  0.053433\n",
            "train epoch: 3 | batch staus: 57600/60000 ( 96%) | Loss:  0.108059\n",
            "train epoch: 3 | batch staus: 58240/60000 ( 97%) | Loss:  0.098928\n",
            "train epoch: 3 | batch staus: 58880/60000 ( 98%) | Loss:  0.166431\n",
            "train epoch: 3 | batch staus: 59520/60000 ( 99%) | Loss:  0.106145\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0013, Accuracy: 9751/10000(98%)\n",
            "Testing time: 0m 25s\n",
            "train epoch: 4 | batch staus: 0/60000 ( 0%) | Loss:  0.174139\n",
            "train epoch: 4 | batch staus: 640/60000 ( 1%) | Loss:  0.101973\n",
            "train epoch: 4 | batch staus: 1280/60000 ( 2%) | Loss:  0.059523\n",
            "train epoch: 4 | batch staus: 1920/60000 ( 3%) | Loss:  0.162925\n",
            "train epoch: 4 | batch staus: 2560/60000 ( 4%) | Loss:  0.069332\n",
            "train epoch: 4 | batch staus: 3200/60000 ( 5%) | Loss:  0.055667\n",
            "train epoch: 4 | batch staus: 3840/60000 ( 6%) | Loss:  0.111119\n",
            "train epoch: 4 | batch staus: 4480/60000 ( 7%) | Loss:  0.039033\n",
            "train epoch: 4 | batch staus: 5120/60000 ( 9%) | Loss:  0.209294\n",
            "train epoch: 4 | batch staus: 5760/60000 ( 10%) | Loss:  0.052445\n",
            "train epoch: 4 | batch staus: 6400/60000 ( 11%) | Loss:  0.188546\n",
            "train epoch: 4 | batch staus: 7040/60000 ( 12%) | Loss:  0.031314\n",
            "train epoch: 4 | batch staus: 7680/60000 ( 13%) | Loss:  0.073497\n",
            "train epoch: 4 | batch staus: 8320/60000 ( 14%) | Loss:  0.017305\n",
            "train epoch: 4 | batch staus: 8960/60000 ( 15%) | Loss:  0.093865\n",
            "train epoch: 4 | batch staus: 9600/60000 ( 16%) | Loss:  0.084387\n",
            "train epoch: 4 | batch staus: 10240/60000 ( 17%) | Loss:  0.151271\n",
            "train epoch: 4 | batch staus: 10880/60000 ( 18%) | Loss:  0.138354\n",
            "train epoch: 4 | batch staus: 11520/60000 ( 19%) | Loss:  0.043384\n",
            "train epoch: 4 | batch staus: 12160/60000 ( 20%) | Loss:  0.049874\n",
            "train epoch: 4 | batch staus: 12800/60000 ( 21%) | Loss:  0.045707\n",
            "train epoch: 4 | batch staus: 13440/60000 ( 22%) | Loss:  0.034766\n",
            "train epoch: 4 | batch staus: 14080/60000 ( 23%) | Loss:  0.037519\n",
            "train epoch: 4 | batch staus: 14720/60000 ( 25%) | Loss:  0.054681\n",
            "train epoch: 4 | batch staus: 15360/60000 ( 26%) | Loss:  0.053075\n",
            "train epoch: 4 | batch staus: 16000/60000 ( 27%) | Loss:  0.069082\n",
            "train epoch: 4 | batch staus: 16640/60000 ( 28%) | Loss:  0.178969\n",
            "train epoch: 4 | batch staus: 17280/60000 ( 29%) | Loss:  0.038158\n",
            "train epoch: 4 | batch staus: 17920/60000 ( 30%) | Loss:  0.164867\n",
            "train epoch: 4 | batch staus: 18560/60000 ( 31%) | Loss:  0.073713\n",
            "train epoch: 4 | batch staus: 19200/60000 ( 32%) | Loss:  0.218811\n",
            "train epoch: 4 | batch staus: 19840/60000 ( 33%) | Loss:  0.093200\n",
            "train epoch: 4 | batch staus: 20480/60000 ( 34%) | Loss:  0.190609\n",
            "train epoch: 4 | batch staus: 21120/60000 ( 35%) | Loss:  0.099377\n",
            "train epoch: 4 | batch staus: 21760/60000 ( 36%) | Loss:  0.012386\n",
            "train epoch: 4 | batch staus: 22400/60000 ( 37%) | Loss:  0.058359\n",
            "train epoch: 4 | batch staus: 23040/60000 ( 38%) | Loss:  0.193184\n",
            "train epoch: 4 | batch staus: 23680/60000 ( 39%) | Loss:  0.088536\n",
            "train epoch: 4 | batch staus: 24320/60000 ( 41%) | Loss:  0.085144\n",
            "train epoch: 4 | batch staus: 24960/60000 ( 42%) | Loss:  0.071943\n",
            "train epoch: 4 | batch staus: 25600/60000 ( 43%) | Loss:  0.059468\n",
            "train epoch: 4 | batch staus: 26240/60000 ( 44%) | Loss:  0.027456\n",
            "train epoch: 4 | batch staus: 26880/60000 ( 45%) | Loss:  0.336684\n",
            "train epoch: 4 | batch staus: 27520/60000 ( 46%) | Loss:  0.029242\n",
            "train epoch: 4 | batch staus: 28160/60000 ( 47%) | Loss:  0.143563\n",
            "train epoch: 4 | batch staus: 28800/60000 ( 48%) | Loss:  0.041885\n",
            "train epoch: 4 | batch staus: 29440/60000 ( 49%) | Loss:  0.062726\n",
            "train epoch: 4 | batch staus: 30080/60000 ( 50%) | Loss:  0.181635\n",
            "train epoch: 4 | batch staus: 30720/60000 ( 51%) | Loss:  0.083874\n",
            "train epoch: 4 | batch staus: 31360/60000 ( 52%) | Loss:  0.034006\n",
            "train epoch: 4 | batch staus: 32000/60000 ( 53%) | Loss:  0.029058\n",
            "train epoch: 4 | batch staus: 32640/60000 ( 54%) | Loss:  0.066987\n",
            "train epoch: 4 | batch staus: 33280/60000 ( 55%) | Loss:  0.110097\n",
            "train epoch: 4 | batch staus: 33920/60000 ( 57%) | Loss:  0.050222\n",
            "train epoch: 4 | batch staus: 34560/60000 ( 58%) | Loss:  0.074430\n",
            "train epoch: 4 | batch staus: 35200/60000 ( 59%) | Loss:  0.034575\n",
            "train epoch: 4 | batch staus: 35840/60000 ( 60%) | Loss:  0.038802\n",
            "train epoch: 4 | batch staus: 36480/60000 ( 61%) | Loss:  0.144394\n",
            "train epoch: 4 | batch staus: 37120/60000 ( 62%) | Loss:  0.143141\n",
            "train epoch: 4 | batch staus: 37760/60000 ( 63%) | Loss:  0.056891\n",
            "train epoch: 4 | batch staus: 38400/60000 ( 64%) | Loss:  0.036141\n",
            "train epoch: 4 | batch staus: 39040/60000 ( 65%) | Loss:  0.062540\n",
            "train epoch: 4 | batch staus: 39680/60000 ( 66%) | Loss:  0.091548\n",
            "train epoch: 4 | batch staus: 40320/60000 ( 67%) | Loss:  0.217033\n",
            "train epoch: 4 | batch staus: 40960/60000 ( 68%) | Loss:  0.045591\n",
            "train epoch: 4 | batch staus: 41600/60000 ( 69%) | Loss:  0.040016\n",
            "train epoch: 4 | batch staus: 42240/60000 ( 70%) | Loss:  0.076629\n",
            "train epoch: 4 | batch staus: 42880/60000 ( 71%) | Loss:  0.060530\n",
            "train epoch: 4 | batch staus: 43520/60000 ( 72%) | Loss:  0.084221\n",
            "train epoch: 4 | batch staus: 44160/60000 ( 74%) | Loss:  0.028866\n",
            "train epoch: 4 | batch staus: 44800/60000 ( 75%) | Loss:  0.059402\n",
            "train epoch: 4 | batch staus: 45440/60000 ( 76%) | Loss:  0.229317\n",
            "train epoch: 4 | batch staus: 46080/60000 ( 77%) | Loss:  0.050445\n",
            "train epoch: 4 | batch staus: 46720/60000 ( 78%) | Loss:  0.084140\n",
            "train epoch: 4 | batch staus: 47360/60000 ( 79%) | Loss:  0.090513\n",
            "train epoch: 4 | batch staus: 48000/60000 ( 80%) | Loss:  0.067534\n",
            "train epoch: 4 | batch staus: 48640/60000 ( 81%) | Loss:  0.060421\n",
            "train epoch: 4 | batch staus: 49280/60000 ( 82%) | Loss:  0.024036\n",
            "train epoch: 4 | batch staus: 49920/60000 ( 83%) | Loss:  0.131159\n",
            "train epoch: 4 | batch staus: 50560/60000 ( 84%) | Loss:  0.077338\n",
            "train epoch: 4 | batch staus: 51200/60000 ( 85%) | Loss:  0.116152\n",
            "train epoch: 4 | batch staus: 51840/60000 ( 86%) | Loss:  0.147246\n",
            "train epoch: 4 | batch staus: 52480/60000 ( 87%) | Loss:  0.169879\n",
            "train epoch: 4 | batch staus: 53120/60000 ( 88%) | Loss:  0.087363\n",
            "train epoch: 4 | batch staus: 53760/60000 ( 90%) | Loss:  0.126745\n",
            "train epoch: 4 | batch staus: 54400/60000 ( 91%) | Loss:  0.057311\n",
            "train epoch: 4 | batch staus: 55040/60000 ( 92%) | Loss:  0.121751\n",
            "train epoch: 4 | batch staus: 55680/60000 ( 93%) | Loss:  0.072549\n",
            "train epoch: 4 | batch staus: 56320/60000 ( 94%) | Loss:  0.025332\n",
            "train epoch: 4 | batch staus: 56960/60000 ( 95%) | Loss:  0.034678\n",
            "train epoch: 4 | batch staus: 57600/60000 ( 96%) | Loss:  0.099555\n",
            "train epoch: 4 | batch staus: 58240/60000 ( 97%) | Loss:  0.028400\n",
            "train epoch: 4 | batch staus: 58880/60000 ( 98%) | Loss:  0.106617\n",
            "train epoch: 4 | batch staus: 59520/60000 ( 99%) | Loss:  0.058663\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0010, Accuracy: 9811/10000(98%)\n",
            "Testing time: 0m 25s\n",
            "train epoch: 5 | batch staus: 0/60000 ( 0%) | Loss:  0.098871\n",
            "train epoch: 5 | batch staus: 640/60000 ( 1%) | Loss:  0.154815\n",
            "train epoch: 5 | batch staus: 1280/60000 ( 2%) | Loss:  0.037039\n",
            "train epoch: 5 | batch staus: 1920/60000 ( 3%) | Loss:  0.144928\n",
            "train epoch: 5 | batch staus: 2560/60000 ( 4%) | Loss:  0.026502\n",
            "train epoch: 5 | batch staus: 3200/60000 ( 5%) | Loss:  0.070729\n",
            "train epoch: 5 | batch staus: 3840/60000 ( 6%) | Loss:  0.153998\n",
            "train epoch: 5 | batch staus: 4480/60000 ( 7%) | Loss:  0.070491\n",
            "train epoch: 5 | batch staus: 5120/60000 ( 9%) | Loss:  0.071222\n",
            "train epoch: 5 | batch staus: 5760/60000 ( 10%) | Loss:  0.175241\n",
            "train epoch: 5 | batch staus: 6400/60000 ( 11%) | Loss:  0.077027\n",
            "train epoch: 5 | batch staus: 7040/60000 ( 12%) | Loss:  0.111490\n",
            "train epoch: 5 | batch staus: 7680/60000 ( 13%) | Loss:  0.286112\n",
            "train epoch: 5 | batch staus: 8320/60000 ( 14%) | Loss:  0.070531\n",
            "train epoch: 5 | batch staus: 8960/60000 ( 15%) | Loss:  0.016939\n",
            "train epoch: 5 | batch staus: 9600/60000 ( 16%) | Loss:  0.120544\n",
            "train epoch: 5 | batch staus: 10240/60000 ( 17%) | Loss:  0.048518\n",
            "train epoch: 5 | batch staus: 10880/60000 ( 18%) | Loss:  0.072890\n",
            "train epoch: 5 | batch staus: 11520/60000 ( 19%) | Loss:  0.025550\n",
            "train epoch: 5 | batch staus: 12160/60000 ( 20%) | Loss:  0.072359\n",
            "train epoch: 5 | batch staus: 12800/60000 ( 21%) | Loss:  0.083581\n",
            "train epoch: 5 | batch staus: 13440/60000 ( 22%) | Loss:  0.076612\n",
            "train epoch: 5 | batch staus: 14080/60000 ( 23%) | Loss:  0.046087\n",
            "train epoch: 5 | batch staus: 14720/60000 ( 25%) | Loss:  0.089468\n",
            "train epoch: 5 | batch staus: 15360/60000 ( 26%) | Loss:  0.083420\n",
            "train epoch: 5 | batch staus: 16000/60000 ( 27%) | Loss:  0.065796\n",
            "train epoch: 5 | batch staus: 16640/60000 ( 28%) | Loss:  0.028853\n",
            "train epoch: 5 | batch staus: 17280/60000 ( 29%) | Loss:  0.100949\n",
            "train epoch: 5 | batch staus: 17920/60000 ( 30%) | Loss:  0.033360\n",
            "train epoch: 5 | batch staus: 18560/60000 ( 31%) | Loss:  0.037856\n",
            "train epoch: 5 | batch staus: 19200/60000 ( 32%) | Loss:  0.109378\n",
            "train epoch: 5 | batch staus: 19840/60000 ( 33%) | Loss:  0.034827\n",
            "train epoch: 5 | batch staus: 20480/60000 ( 34%) | Loss:  0.055991\n",
            "train epoch: 5 | batch staus: 21120/60000 ( 35%) | Loss:  0.149143\n",
            "train epoch: 5 | batch staus: 21760/60000 ( 36%) | Loss:  0.028683\n",
            "train epoch: 5 | batch staus: 22400/60000 ( 37%) | Loss:  0.014949\n",
            "train epoch: 5 | batch staus: 23040/60000 ( 38%) | Loss:  0.065189\n",
            "train epoch: 5 | batch staus: 23680/60000 ( 39%) | Loss:  0.050483\n",
            "train epoch: 5 | batch staus: 24320/60000 ( 41%) | Loss:  0.106441\n",
            "train epoch: 5 | batch staus: 24960/60000 ( 42%) | Loss:  0.087613\n",
            "train epoch: 5 | batch staus: 25600/60000 ( 43%) | Loss:  0.029401\n",
            "train epoch: 5 | batch staus: 26240/60000 ( 44%) | Loss:  0.150024\n",
            "train epoch: 5 | batch staus: 26880/60000 ( 45%) | Loss:  0.082177\n",
            "train epoch: 5 | batch staus: 27520/60000 ( 46%) | Loss:  0.034371\n",
            "train epoch: 5 | batch staus: 28160/60000 ( 47%) | Loss:  0.054001\n",
            "train epoch: 5 | batch staus: 28800/60000 ( 48%) | Loss:  0.081214\n",
            "train epoch: 5 | batch staus: 29440/60000 ( 49%) | Loss:  0.087463\n",
            "train epoch: 5 | batch staus: 30080/60000 ( 50%) | Loss:  0.044853\n",
            "train epoch: 5 | batch staus: 30720/60000 ( 51%) | Loss:  0.043232\n",
            "train epoch: 5 | batch staus: 31360/60000 ( 52%) | Loss:  0.126564\n",
            "train epoch: 5 | batch staus: 32000/60000 ( 53%) | Loss:  0.065418\n",
            "train epoch: 5 | batch staus: 32640/60000 ( 54%) | Loss:  0.050483\n",
            "train epoch: 5 | batch staus: 33280/60000 ( 55%) | Loss:  0.026752\n",
            "train epoch: 5 | batch staus: 33920/60000 ( 57%) | Loss:  0.085338\n",
            "train epoch: 5 | batch staus: 34560/60000 ( 58%) | Loss:  0.047803\n",
            "train epoch: 5 | batch staus: 35200/60000 ( 59%) | Loss:  0.089947\n",
            "train epoch: 5 | batch staus: 35840/60000 ( 60%) | Loss:  0.028257\n",
            "train epoch: 5 | batch staus: 36480/60000 ( 61%) | Loss:  0.056422\n",
            "train epoch: 5 | batch staus: 37120/60000 ( 62%) | Loss:  0.021376\n",
            "train epoch: 5 | batch staus: 37760/60000 ( 63%) | Loss:  0.108429\n",
            "train epoch: 5 | batch staus: 38400/60000 ( 64%) | Loss:  0.056762\n",
            "train epoch: 5 | batch staus: 39040/60000 ( 65%) | Loss:  0.103887\n",
            "train epoch: 5 | batch staus: 39680/60000 ( 66%) | Loss:  0.106714\n",
            "train epoch: 5 | batch staus: 40320/60000 ( 67%) | Loss:  0.254209\n",
            "train epoch: 5 | batch staus: 40960/60000 ( 68%) | Loss:  0.111495\n",
            "train epoch: 5 | batch staus: 41600/60000 ( 69%) | Loss:  0.082840\n",
            "train epoch: 5 | batch staus: 42240/60000 ( 70%) | Loss:  0.146102\n",
            "train epoch: 5 | batch staus: 42880/60000 ( 71%) | Loss:  0.045721\n",
            "train epoch: 5 | batch staus: 43520/60000 ( 72%) | Loss:  0.138522\n",
            "train epoch: 5 | batch staus: 44160/60000 ( 74%) | Loss:  0.286079\n",
            "train epoch: 5 | batch staus: 44800/60000 ( 75%) | Loss:  0.016771\n",
            "train epoch: 5 | batch staus: 45440/60000 ( 76%) | Loss:  0.022190\n",
            "train epoch: 5 | batch staus: 46080/60000 ( 77%) | Loss:  0.102015\n",
            "train epoch: 5 | batch staus: 46720/60000 ( 78%) | Loss:  0.176989\n",
            "train epoch: 5 | batch staus: 47360/60000 ( 79%) | Loss:  0.072023\n",
            "train epoch: 5 | batch staus: 48000/60000 ( 80%) | Loss:  0.211470\n",
            "train epoch: 5 | batch staus: 48640/60000 ( 81%) | Loss:  0.042593\n",
            "train epoch: 5 | batch staus: 49280/60000 ( 82%) | Loss:  0.079560\n",
            "train epoch: 5 | batch staus: 49920/60000 ( 83%) | Loss:  0.060794\n",
            "train epoch: 5 | batch staus: 50560/60000 ( 84%) | Loss:  0.049618\n",
            "train epoch: 5 | batch staus: 51200/60000 ( 85%) | Loss:  0.078190\n",
            "train epoch: 5 | batch staus: 51840/60000 ( 86%) | Loss:  0.131350\n",
            "train epoch: 5 | batch staus: 52480/60000 ( 87%) | Loss:  0.066257\n",
            "train epoch: 5 | batch staus: 53120/60000 ( 88%) | Loss:  0.080923\n",
            "train epoch: 5 | batch staus: 53760/60000 ( 90%) | Loss:  0.064899\n",
            "train epoch: 5 | batch staus: 54400/60000 ( 91%) | Loss:  0.063755\n",
            "train epoch: 5 | batch staus: 55040/60000 ( 92%) | Loss:  0.236987\n",
            "train epoch: 5 | batch staus: 55680/60000 ( 93%) | Loss:  0.029190\n",
            "train epoch: 5 | batch staus: 56320/60000 ( 94%) | Loss:  0.110486\n",
            "train epoch: 5 | batch staus: 56960/60000 ( 95%) | Loss:  0.142758\n",
            "train epoch: 5 | batch staus: 57600/60000 ( 96%) | Loss:  0.105169\n",
            "train epoch: 5 | batch staus: 58240/60000 ( 97%) | Loss:  0.122775\n",
            "train epoch: 5 | batch staus: 58880/60000 ( 98%) | Loss:  0.036860\n",
            "train epoch: 5 | batch staus: 59520/60000 ( 99%) | Loss:  0.121713\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0009, Accuracy: 9831/10000(98%)\n",
            "Testing time: 0m 25s\n",
            "train epoch: 6 | batch staus: 0/60000 ( 0%) | Loss:  0.102127\n",
            "train epoch: 6 | batch staus: 640/60000 ( 1%) | Loss:  0.021869\n",
            "train epoch: 6 | batch staus: 1280/60000 ( 2%) | Loss:  0.124239\n",
            "train epoch: 6 | batch staus: 1920/60000 ( 3%) | Loss:  0.050034\n",
            "train epoch: 6 | batch staus: 2560/60000 ( 4%) | Loss:  0.103206\n",
            "train epoch: 6 | batch staus: 3200/60000 ( 5%) | Loss:  0.034717\n",
            "train epoch: 6 | batch staus: 3840/60000 ( 6%) | Loss:  0.136925\n",
            "train epoch: 6 | batch staus: 4480/60000 ( 7%) | Loss:  0.022924\n",
            "train epoch: 6 | batch staus: 5120/60000 ( 9%) | Loss:  0.123929\n",
            "train epoch: 6 | batch staus: 5760/60000 ( 10%) | Loss:  0.124315\n",
            "train epoch: 6 | batch staus: 6400/60000 ( 11%) | Loss:  0.064191\n",
            "train epoch: 6 | batch staus: 7040/60000 ( 12%) | Loss:  0.109860\n",
            "train epoch: 6 | batch staus: 7680/60000 ( 13%) | Loss:  0.071025\n",
            "train epoch: 6 | batch staus: 8320/60000 ( 14%) | Loss:  0.026290\n",
            "train epoch: 6 | batch staus: 8960/60000 ( 15%) | Loss:  0.045199\n",
            "train epoch: 6 | batch staus: 9600/60000 ( 16%) | Loss:  0.103931\n",
            "train epoch: 6 | batch staus: 10240/60000 ( 17%) | Loss:  0.046909\n",
            "train epoch: 6 | batch staus: 10880/60000 ( 18%) | Loss:  0.103608\n",
            "train epoch: 6 | batch staus: 11520/60000 ( 19%) | Loss:  0.023170\n",
            "train epoch: 6 | batch staus: 12160/60000 ( 20%) | Loss:  0.066593\n",
            "train epoch: 6 | batch staus: 12800/60000 ( 21%) | Loss:  0.062202\n",
            "train epoch: 6 | batch staus: 13440/60000 ( 22%) | Loss:  0.117522\n",
            "train epoch: 6 | batch staus: 14080/60000 ( 23%) | Loss:  0.016880\n",
            "train epoch: 6 | batch staus: 14720/60000 ( 25%) | Loss:  0.056556\n",
            "train epoch: 6 | batch staus: 15360/60000 ( 26%) | Loss:  0.024622\n",
            "train epoch: 6 | batch staus: 16000/60000 ( 27%) | Loss:  0.012307\n",
            "train epoch: 6 | batch staus: 16640/60000 ( 28%) | Loss:  0.027505\n",
            "train epoch: 6 | batch staus: 17280/60000 ( 29%) | Loss:  0.042581\n",
            "train epoch: 6 | batch staus: 17920/60000 ( 30%) | Loss:  0.030020\n",
            "train epoch: 6 | batch staus: 18560/60000 ( 31%) | Loss:  0.090651\n",
            "train epoch: 6 | batch staus: 19200/60000 ( 32%) | Loss:  0.054300\n",
            "train epoch: 6 | batch staus: 19840/60000 ( 33%) | Loss:  0.022977\n",
            "train epoch: 6 | batch staus: 20480/60000 ( 34%) | Loss:  0.018467\n",
            "train epoch: 6 | batch staus: 21120/60000 ( 35%) | Loss:  0.040376\n",
            "train epoch: 6 | batch staus: 21760/60000 ( 36%) | Loss:  0.024746\n",
            "train epoch: 6 | batch staus: 22400/60000 ( 37%) | Loss:  0.034581\n",
            "train epoch: 6 | batch staus: 23040/60000 ( 38%) | Loss:  0.056534\n",
            "train epoch: 6 | batch staus: 23680/60000 ( 39%) | Loss:  0.011304\n",
            "train epoch: 6 | batch staus: 24320/60000 ( 41%) | Loss:  0.024528\n",
            "train epoch: 6 | batch staus: 24960/60000 ( 42%) | Loss:  0.056484\n",
            "train epoch: 6 | batch staus: 25600/60000 ( 43%) | Loss:  0.098535\n",
            "train epoch: 6 | batch staus: 26240/60000 ( 44%) | Loss:  0.008784\n",
            "train epoch: 6 | batch staus: 26880/60000 ( 45%) | Loss:  0.036022\n",
            "train epoch: 6 | batch staus: 27520/60000 ( 46%) | Loss:  0.048801\n",
            "train epoch: 6 | batch staus: 28160/60000 ( 47%) | Loss:  0.085558\n",
            "train epoch: 6 | batch staus: 28800/60000 ( 48%) | Loss:  0.184473\n",
            "train epoch: 6 | batch staus: 29440/60000 ( 49%) | Loss:  0.114258\n",
            "train epoch: 6 | batch staus: 30080/60000 ( 50%) | Loss:  0.043073\n",
            "train epoch: 6 | batch staus: 30720/60000 ( 51%) | Loss:  0.057490\n",
            "train epoch: 6 | batch staus: 31360/60000 ( 52%) | Loss:  0.059598\n",
            "train epoch: 6 | batch staus: 32000/60000 ( 53%) | Loss:  0.062974\n",
            "train epoch: 6 | batch staus: 32640/60000 ( 54%) | Loss:  0.037770\n",
            "train epoch: 6 | batch staus: 33280/60000 ( 55%) | Loss:  0.041244\n",
            "train epoch: 6 | batch staus: 33920/60000 ( 57%) | Loss:  0.041692\n",
            "train epoch: 6 | batch staus: 34560/60000 ( 58%) | Loss:  0.072096\n",
            "train epoch: 6 | batch staus: 35200/60000 ( 59%) | Loss:  0.019814\n",
            "train epoch: 6 | batch staus: 35840/60000 ( 60%) | Loss:  0.143443\n",
            "train epoch: 6 | batch staus: 36480/60000 ( 61%) | Loss:  0.060432\n",
            "train epoch: 6 | batch staus: 37120/60000 ( 62%) | Loss:  0.046947\n",
            "train epoch: 6 | batch staus: 37760/60000 ( 63%) | Loss:  0.013374\n",
            "train epoch: 6 | batch staus: 38400/60000 ( 64%) | Loss:  0.062007\n",
            "train epoch: 6 | batch staus: 39040/60000 ( 65%) | Loss:  0.152762\n",
            "train epoch: 6 | batch staus: 39680/60000 ( 66%) | Loss:  0.090617\n",
            "train epoch: 6 | batch staus: 40320/60000 ( 67%) | Loss:  0.054608\n",
            "train epoch: 6 | batch staus: 40960/60000 ( 68%) | Loss:  0.146807\n",
            "train epoch: 6 | batch staus: 41600/60000 ( 69%) | Loss:  0.028602\n",
            "train epoch: 6 | batch staus: 42240/60000 ( 70%) | Loss:  0.085126\n",
            "train epoch: 6 | batch staus: 42880/60000 ( 71%) | Loss:  0.078106\n",
            "train epoch: 6 | batch staus: 43520/60000 ( 72%) | Loss:  0.101483\n",
            "train epoch: 6 | batch staus: 44160/60000 ( 74%) | Loss:  0.016971\n",
            "train epoch: 6 | batch staus: 44800/60000 ( 75%) | Loss:  0.083333\n",
            "train epoch: 6 | batch staus: 45440/60000 ( 76%) | Loss:  0.098490\n",
            "train epoch: 6 | batch staus: 46080/60000 ( 77%) | Loss:  0.073450\n",
            "train epoch: 6 | batch staus: 46720/60000 ( 78%) | Loss:  0.044117\n",
            "train epoch: 6 | batch staus: 47360/60000 ( 79%) | Loss:  0.032366\n",
            "train epoch: 6 | batch staus: 48000/60000 ( 80%) | Loss:  0.052211\n",
            "train epoch: 6 | batch staus: 48640/60000 ( 81%) | Loss:  0.004972\n",
            "train epoch: 6 | batch staus: 49280/60000 ( 82%) | Loss:  0.035221\n",
            "train epoch: 6 | batch staus: 49920/60000 ( 83%) | Loss:  0.125132\n",
            "train epoch: 6 | batch staus: 50560/60000 ( 84%) | Loss:  0.072704\n",
            "train epoch: 6 | batch staus: 51200/60000 ( 85%) | Loss:  0.070145\n",
            "train epoch: 6 | batch staus: 51840/60000 ( 86%) | Loss:  0.024829\n",
            "train epoch: 6 | batch staus: 52480/60000 ( 87%) | Loss:  0.119127\n",
            "train epoch: 6 | batch staus: 53120/60000 ( 88%) | Loss:  0.025905\n",
            "train epoch: 6 | batch staus: 53760/60000 ( 90%) | Loss:  0.027232\n",
            "train epoch: 6 | batch staus: 54400/60000 ( 91%) | Loss:  0.096470\n",
            "train epoch: 6 | batch staus: 55040/60000 ( 92%) | Loss:  0.093554\n",
            "train epoch: 6 | batch staus: 55680/60000 ( 93%) | Loss:  0.041901\n",
            "train epoch: 6 | batch staus: 56320/60000 ( 94%) | Loss:  0.083302\n",
            "train epoch: 6 | batch staus: 56960/60000 ( 95%) | Loss:  0.034859\n",
            "train epoch: 6 | batch staus: 57600/60000 ( 96%) | Loss:  0.063937\n",
            "train epoch: 6 | batch staus: 58240/60000 ( 97%) | Loss:  0.038081\n",
            "train epoch: 6 | batch staus: 58880/60000 ( 98%) | Loss:  0.014499\n",
            "train epoch: 6 | batch staus: 59520/60000 ( 99%) | Loss:  0.043519\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0009, Accuracy: 9825/10000(98%)\n",
            "Testing time: 0m 25s\n",
            "train epoch: 7 | batch staus: 0/60000 ( 0%) | Loss:  0.018421\n",
            "train epoch: 7 | batch staus: 640/60000 ( 1%) | Loss:  0.101198\n",
            "train epoch: 7 | batch staus: 1280/60000 ( 2%) | Loss:  0.060270\n",
            "train epoch: 7 | batch staus: 1920/60000 ( 3%) | Loss:  0.041390\n",
            "train epoch: 7 | batch staus: 2560/60000 ( 4%) | Loss:  0.030944\n",
            "train epoch: 7 | batch staus: 3200/60000 ( 5%) | Loss:  0.023711\n",
            "train epoch: 7 | batch staus: 3840/60000 ( 6%) | Loss:  0.035060\n",
            "train epoch: 7 | batch staus: 4480/60000 ( 7%) | Loss:  0.018707\n",
            "train epoch: 7 | batch staus: 5120/60000 ( 9%) | Loss:  0.030000\n",
            "train epoch: 7 | batch staus: 5760/60000 ( 10%) | Loss:  0.016493\n",
            "train epoch: 7 | batch staus: 6400/60000 ( 11%) | Loss:  0.099486\n",
            "train epoch: 7 | batch staus: 7040/60000 ( 12%) | Loss:  0.049372\n",
            "train epoch: 7 | batch staus: 7680/60000 ( 13%) | Loss:  0.036904\n",
            "train epoch: 7 | batch staus: 8320/60000 ( 14%) | Loss:  0.012567\n",
            "train epoch: 7 | batch staus: 8960/60000 ( 15%) | Loss:  0.025575\n",
            "train epoch: 7 | batch staus: 9600/60000 ( 16%) | Loss:  0.066529\n",
            "train epoch: 7 | batch staus: 10240/60000 ( 17%) | Loss:  0.092475\n",
            "train epoch: 7 | batch staus: 10880/60000 ( 18%) | Loss:  0.019434\n",
            "train epoch: 7 | batch staus: 11520/60000 ( 19%) | Loss:  0.234137\n",
            "train epoch: 7 | batch staus: 12160/60000 ( 20%) | Loss:  0.025053\n",
            "train epoch: 7 | batch staus: 12800/60000 ( 21%) | Loss:  0.012218\n",
            "train epoch: 7 | batch staus: 13440/60000 ( 22%) | Loss:  0.082082\n",
            "train epoch: 7 | batch staus: 14080/60000 ( 23%) | Loss:  0.066337\n",
            "train epoch: 7 | batch staus: 14720/60000 ( 25%) | Loss:  0.031217\n",
            "train epoch: 7 | batch staus: 15360/60000 ( 26%) | Loss:  0.047513\n",
            "train epoch: 7 | batch staus: 16000/60000 ( 27%) | Loss:  0.067590\n",
            "train epoch: 7 | batch staus: 16640/60000 ( 28%) | Loss:  0.013949\n",
            "train epoch: 7 | batch staus: 17280/60000 ( 29%) | Loss:  0.094555\n",
            "train epoch: 7 | batch staus: 17920/60000 ( 30%) | Loss:  0.043947\n",
            "train epoch: 7 | batch staus: 18560/60000 ( 31%) | Loss:  0.165062\n",
            "train epoch: 7 | batch staus: 19200/60000 ( 32%) | Loss:  0.063276\n",
            "train epoch: 7 | batch staus: 19840/60000 ( 33%) | Loss:  0.007333\n",
            "train epoch: 7 | batch staus: 20480/60000 ( 34%) | Loss:  0.048088\n",
            "train epoch: 7 | batch staus: 21120/60000 ( 35%) | Loss:  0.082712\n",
            "train epoch: 7 | batch staus: 21760/60000 ( 36%) | Loss:  0.054117\n",
            "train epoch: 7 | batch staus: 22400/60000 ( 37%) | Loss:  0.052530\n",
            "train epoch: 7 | batch staus: 23040/60000 ( 38%) | Loss:  0.025974\n",
            "train epoch: 7 | batch staus: 23680/60000 ( 39%) | Loss:  0.118931\n",
            "train epoch: 7 | batch staus: 24320/60000 ( 41%) | Loss:  0.106454\n",
            "train epoch: 7 | batch staus: 24960/60000 ( 42%) | Loss:  0.129223\n",
            "train epoch: 7 | batch staus: 25600/60000 ( 43%) | Loss:  0.065709\n",
            "train epoch: 7 | batch staus: 26240/60000 ( 44%) | Loss:  0.040979\n",
            "train epoch: 7 | batch staus: 26880/60000 ( 45%) | Loss:  0.087267\n",
            "train epoch: 7 | batch staus: 27520/60000 ( 46%) | Loss:  0.039675\n",
            "train epoch: 7 | batch staus: 28160/60000 ( 47%) | Loss:  0.049599\n",
            "train epoch: 7 | batch staus: 28800/60000 ( 48%) | Loss:  0.036193\n",
            "train epoch: 7 | batch staus: 29440/60000 ( 49%) | Loss:  0.048049\n",
            "train epoch: 7 | batch staus: 30080/60000 ( 50%) | Loss:  0.119014\n",
            "train epoch: 7 | batch staus: 30720/60000 ( 51%) | Loss:  0.065516\n",
            "train epoch: 7 | batch staus: 31360/60000 ( 52%) | Loss:  0.013519\n",
            "train epoch: 7 | batch staus: 32000/60000 ( 53%) | Loss:  0.052252\n",
            "train epoch: 7 | batch staus: 32640/60000 ( 54%) | Loss:  0.042980\n",
            "train epoch: 7 | batch staus: 33280/60000 ( 55%) | Loss:  0.101032\n",
            "train epoch: 7 | batch staus: 33920/60000 ( 57%) | Loss:  0.011611\n",
            "train epoch: 7 | batch staus: 34560/60000 ( 58%) | Loss:  0.013937\n",
            "train epoch: 7 | batch staus: 35200/60000 ( 59%) | Loss:  0.022654\n",
            "train epoch: 7 | batch staus: 35840/60000 ( 60%) | Loss:  0.064191\n",
            "train epoch: 7 | batch staus: 36480/60000 ( 61%) | Loss:  0.104420\n",
            "train epoch: 7 | batch staus: 37120/60000 ( 62%) | Loss:  0.064292\n",
            "train epoch: 7 | batch staus: 37760/60000 ( 63%) | Loss:  0.067639\n",
            "train epoch: 7 | batch staus: 38400/60000 ( 64%) | Loss:  0.024308\n",
            "train epoch: 7 | batch staus: 39040/60000 ( 65%) | Loss:  0.053891\n",
            "train epoch: 7 | batch staus: 39680/60000 ( 66%) | Loss:  0.077964\n",
            "train epoch: 7 | batch staus: 40320/60000 ( 67%) | Loss:  0.111665\n",
            "train epoch: 7 | batch staus: 40960/60000 ( 68%) | Loss:  0.044416\n",
            "train epoch: 7 | batch staus: 41600/60000 ( 69%) | Loss:  0.021270\n",
            "train epoch: 7 | batch staus: 42240/60000 ( 70%) | Loss:  0.049160\n",
            "train epoch: 7 | batch staus: 42880/60000 ( 71%) | Loss:  0.049475\n",
            "train epoch: 7 | batch staus: 43520/60000 ( 72%) | Loss:  0.071037\n",
            "train epoch: 7 | batch staus: 44160/60000 ( 74%) | Loss:  0.021615\n",
            "train epoch: 7 | batch staus: 44800/60000 ( 75%) | Loss:  0.044208\n",
            "train epoch: 7 | batch staus: 45440/60000 ( 76%) | Loss:  0.019350\n",
            "train epoch: 7 | batch staus: 46080/60000 ( 77%) | Loss:  0.014005\n",
            "train epoch: 7 | batch staus: 46720/60000 ( 78%) | Loss:  0.082673\n",
            "train epoch: 7 | batch staus: 47360/60000 ( 79%) | Loss:  0.088336\n",
            "train epoch: 7 | batch staus: 48000/60000 ( 80%) | Loss:  0.104632\n",
            "train epoch: 7 | batch staus: 48640/60000 ( 81%) | Loss:  0.033786\n",
            "train epoch: 7 | batch staus: 49280/60000 ( 82%) | Loss:  0.118939\n",
            "train epoch: 7 | batch staus: 49920/60000 ( 83%) | Loss:  0.014595\n",
            "train epoch: 7 | batch staus: 50560/60000 ( 84%) | Loss:  0.024583\n",
            "train epoch: 7 | batch staus: 51200/60000 ( 85%) | Loss:  0.027738\n",
            "train epoch: 7 | batch staus: 51840/60000 ( 86%) | Loss:  0.099417\n",
            "train epoch: 7 | batch staus: 52480/60000 ( 87%) | Loss:  0.109042\n",
            "train epoch: 7 | batch staus: 53120/60000 ( 88%) | Loss:  0.041167\n",
            "train epoch: 7 | batch staus: 53760/60000 ( 90%) | Loss:  0.045049\n",
            "train epoch: 7 | batch staus: 54400/60000 ( 91%) | Loss:  0.068763\n",
            "train epoch: 7 | batch staus: 55040/60000 ( 92%) | Loss:  0.077333\n",
            "train epoch: 7 | batch staus: 55680/60000 ( 93%) | Loss:  0.027904\n",
            "train epoch: 7 | batch staus: 56320/60000 ( 94%) | Loss:  0.010414\n",
            "train epoch: 7 | batch staus: 56960/60000 ( 95%) | Loss:  0.040400\n",
            "train epoch: 7 | batch staus: 57600/60000 ( 96%) | Loss:  0.063517\n",
            "train epoch: 7 | batch staus: 58240/60000 ( 97%) | Loss:  0.029678\n",
            "train epoch: 7 | batch staus: 58880/60000 ( 98%) | Loss:  0.046685\n",
            "train epoch: 7 | batch staus: 59520/60000 ( 99%) | Loss:  0.038874\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0008, Accuracy: 9851/10000(99%)\n",
            "Testing time: 0m 25s\n",
            "train epoch: 8 | batch staus: 0/60000 ( 0%) | Loss:  0.037610\n",
            "train epoch: 8 | batch staus: 640/60000 ( 1%) | Loss:  0.068936\n",
            "train epoch: 8 | batch staus: 1280/60000 ( 2%) | Loss:  0.023875\n",
            "train epoch: 8 | batch staus: 1920/60000 ( 3%) | Loss:  0.020501\n",
            "train epoch: 8 | batch staus: 2560/60000 ( 4%) | Loss:  0.070262\n",
            "train epoch: 8 | batch staus: 3200/60000 ( 5%) | Loss:  0.022858\n",
            "train epoch: 8 | batch staus: 3840/60000 ( 6%) | Loss:  0.096624\n",
            "train epoch: 8 | batch staus: 4480/60000 ( 7%) | Loss:  0.005847\n",
            "train epoch: 8 | batch staus: 5120/60000 ( 9%) | Loss:  0.075414\n",
            "train epoch: 8 | batch staus: 5760/60000 ( 10%) | Loss:  0.026856\n",
            "train epoch: 8 | batch staus: 6400/60000 ( 11%) | Loss:  0.109183\n",
            "train epoch: 8 | batch staus: 7040/60000 ( 12%) | Loss:  0.020738\n",
            "train epoch: 8 | batch staus: 7680/60000 ( 13%) | Loss:  0.037830\n",
            "train epoch: 8 | batch staus: 8320/60000 ( 14%) | Loss:  0.062118\n",
            "train epoch: 8 | batch staus: 8960/60000 ( 15%) | Loss:  0.022666\n",
            "train epoch: 8 | batch staus: 9600/60000 ( 16%) | Loss:  0.097222\n",
            "train epoch: 8 | batch staus: 10240/60000 ( 17%) | Loss:  0.038686\n",
            "train epoch: 8 | batch staus: 10880/60000 ( 18%) | Loss:  0.038527\n",
            "train epoch: 8 | batch staus: 11520/60000 ( 19%) | Loss:  0.045870\n",
            "train epoch: 8 | batch staus: 12160/60000 ( 20%) | Loss:  0.074651\n",
            "train epoch: 8 | batch staus: 12800/60000 ( 21%) | Loss:  0.092778\n",
            "train epoch: 8 | batch staus: 13440/60000 ( 22%) | Loss:  0.079925\n",
            "train epoch: 8 | batch staus: 14080/60000 ( 23%) | Loss:  0.024014\n",
            "train epoch: 8 | batch staus: 14720/60000 ( 25%) | Loss:  0.038746\n",
            "train epoch: 8 | batch staus: 15360/60000 ( 26%) | Loss:  0.021478\n",
            "train epoch: 8 | batch staus: 16000/60000 ( 27%) | Loss:  0.078172\n",
            "train epoch: 8 | batch staus: 16640/60000 ( 28%) | Loss:  0.039033\n",
            "train epoch: 8 | batch staus: 17280/60000 ( 29%) | Loss:  0.110534\n",
            "train epoch: 8 | batch staus: 17920/60000 ( 30%) | Loss:  0.011580\n",
            "train epoch: 8 | batch staus: 18560/60000 ( 31%) | Loss:  0.011035\n",
            "train epoch: 8 | batch staus: 19200/60000 ( 32%) | Loss:  0.031284\n",
            "train epoch: 8 | batch staus: 19840/60000 ( 33%) | Loss:  0.025960\n",
            "train epoch: 8 | batch staus: 20480/60000 ( 34%) | Loss:  0.061168\n",
            "train epoch: 8 | batch staus: 21120/60000 ( 35%) | Loss:  0.083630\n",
            "train epoch: 8 | batch staus: 21760/60000 ( 36%) | Loss:  0.268576\n",
            "train epoch: 8 | batch staus: 22400/60000 ( 37%) | Loss:  0.057427\n",
            "train epoch: 8 | batch staus: 23040/60000 ( 38%) | Loss:  0.157544\n",
            "train epoch: 8 | batch staus: 23680/60000 ( 39%) | Loss:  0.056731\n",
            "train epoch: 8 | batch staus: 24320/60000 ( 41%) | Loss:  0.087558\n",
            "train epoch: 8 | batch staus: 24960/60000 ( 42%) | Loss:  0.018819\n",
            "train epoch: 8 | batch staus: 25600/60000 ( 43%) | Loss:  0.034886\n",
            "train epoch: 8 | batch staus: 26240/60000 ( 44%) | Loss:  0.016014\n",
            "train epoch: 8 | batch staus: 26880/60000 ( 45%) | Loss:  0.027568\n",
            "train epoch: 8 | batch staus: 27520/60000 ( 46%) | Loss:  0.039037\n",
            "train epoch: 8 | batch staus: 28160/60000 ( 47%) | Loss:  0.008039\n",
            "train epoch: 8 | batch staus: 28800/60000 ( 48%) | Loss:  0.016712\n",
            "train epoch: 8 | batch staus: 29440/60000 ( 49%) | Loss:  0.104479\n",
            "train epoch: 8 | batch staus: 30080/60000 ( 50%) | Loss:  0.058105\n",
            "train epoch: 8 | batch staus: 30720/60000 ( 51%) | Loss:  0.012321\n",
            "train epoch: 8 | batch staus: 31360/60000 ( 52%) | Loss:  0.013652\n",
            "train epoch: 8 | batch staus: 32000/60000 ( 53%) | Loss:  0.108928\n",
            "train epoch: 8 | batch staus: 32640/60000 ( 54%) | Loss:  0.055000\n",
            "train epoch: 8 | batch staus: 33280/60000 ( 55%) | Loss:  0.166158\n",
            "train epoch: 8 | batch staus: 33920/60000 ( 57%) | Loss:  0.101383\n",
            "train epoch: 8 | batch staus: 34560/60000 ( 58%) | Loss:  0.012073\n",
            "train epoch: 8 | batch staus: 35200/60000 ( 59%) | Loss:  0.026741\n",
            "train epoch: 8 | batch staus: 35840/60000 ( 60%) | Loss:  0.033667\n",
            "train epoch: 8 | batch staus: 36480/60000 ( 61%) | Loss:  0.105451\n",
            "train epoch: 8 | batch staus: 37120/60000 ( 62%) | Loss:  0.094916\n",
            "train epoch: 8 | batch staus: 37760/60000 ( 63%) | Loss:  0.043302\n",
            "train epoch: 8 | batch staus: 38400/60000 ( 64%) | Loss:  0.008611\n",
            "train epoch: 8 | batch staus: 39040/60000 ( 65%) | Loss:  0.208913\n",
            "train epoch: 8 | batch staus: 39680/60000 ( 66%) | Loss:  0.034610\n",
            "train epoch: 8 | batch staus: 40320/60000 ( 67%) | Loss:  0.056733\n",
            "train epoch: 8 | batch staus: 40960/60000 ( 68%) | Loss:  0.041399\n",
            "train epoch: 8 | batch staus: 41600/60000 ( 69%) | Loss:  0.079909\n",
            "train epoch: 8 | batch staus: 42240/60000 ( 70%) | Loss:  0.020135\n",
            "train epoch: 8 | batch staus: 42880/60000 ( 71%) | Loss:  0.054632\n",
            "train epoch: 8 | batch staus: 43520/60000 ( 72%) | Loss:  0.079391\n",
            "train epoch: 8 | batch staus: 44160/60000 ( 74%) | Loss:  0.015757\n",
            "train epoch: 8 | batch staus: 44800/60000 ( 75%) | Loss:  0.049815\n",
            "train epoch: 8 | batch staus: 45440/60000 ( 76%) | Loss:  0.154801\n",
            "train epoch: 8 | batch staus: 46080/60000 ( 77%) | Loss:  0.060712\n",
            "train epoch: 8 | batch staus: 46720/60000 ( 78%) | Loss:  0.075786\n",
            "train epoch: 8 | batch staus: 47360/60000 ( 79%) | Loss:  0.017694\n",
            "train epoch: 8 | batch staus: 48000/60000 ( 80%) | Loss:  0.044480\n",
            "train epoch: 8 | batch staus: 48640/60000 ( 81%) | Loss:  0.016555\n",
            "train epoch: 8 | batch staus: 49280/60000 ( 82%) | Loss:  0.019105\n",
            "train epoch: 8 | batch staus: 49920/60000 ( 83%) | Loss:  0.052783\n",
            "train epoch: 8 | batch staus: 50560/60000 ( 84%) | Loss:  0.033540\n",
            "train epoch: 8 | batch staus: 51200/60000 ( 85%) | Loss:  0.009613\n",
            "train epoch: 8 | batch staus: 51840/60000 ( 86%) | Loss:  0.064570\n",
            "train epoch: 8 | batch staus: 52480/60000 ( 87%) | Loss:  0.025800\n",
            "train epoch: 8 | batch staus: 53120/60000 ( 88%) | Loss:  0.007884\n",
            "train epoch: 8 | batch staus: 53760/60000 ( 90%) | Loss:  0.124871\n",
            "train epoch: 8 | batch staus: 54400/60000 ( 91%) | Loss:  0.017505\n",
            "train epoch: 8 | batch staus: 55040/60000 ( 92%) | Loss:  0.006883\n",
            "train epoch: 8 | batch staus: 55680/60000 ( 93%) | Loss:  0.018222\n",
            "train epoch: 8 | batch staus: 56320/60000 ( 94%) | Loss:  0.027923\n",
            "train epoch: 8 | batch staus: 56960/60000 ( 95%) | Loss:  0.061901\n",
            "train epoch: 8 | batch staus: 57600/60000 ( 96%) | Loss:  0.049722\n",
            "train epoch: 8 | batch staus: 58240/60000 ( 97%) | Loss:  0.098380\n",
            "train epoch: 8 | batch staus: 58880/60000 ( 98%) | Loss:  0.018022\n",
            "train epoch: 8 | batch staus: 59520/60000 ( 99%) | Loss:  0.072205\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0008, Accuracy: 9856/10000(99%)\n",
            "Testing time: 0m 25s\n",
            "train epoch: 9 | batch staus: 0/60000 ( 0%) | Loss:  0.080478\n",
            "train epoch: 9 | batch staus: 640/60000 ( 1%) | Loss:  0.036447\n",
            "train epoch: 9 | batch staus: 1280/60000 ( 2%) | Loss:  0.028014\n",
            "train epoch: 9 | batch staus: 1920/60000 ( 3%) | Loss:  0.148783\n",
            "train epoch: 9 | batch staus: 2560/60000 ( 4%) | Loss:  0.050369\n",
            "train epoch: 9 | batch staus: 3200/60000 ( 5%) | Loss:  0.037749\n",
            "train epoch: 9 | batch staus: 3840/60000 ( 6%) | Loss:  0.021950\n",
            "train epoch: 9 | batch staus: 4480/60000 ( 7%) | Loss:  0.040031\n",
            "train epoch: 9 | batch staus: 5120/60000 ( 9%) | Loss:  0.021838\n",
            "train epoch: 9 | batch staus: 5760/60000 ( 10%) | Loss:  0.034172\n",
            "train epoch: 9 | batch staus: 6400/60000 ( 11%) | Loss:  0.048713\n",
            "train epoch: 9 | batch staus: 7040/60000 ( 12%) | Loss:  0.017691\n",
            "train epoch: 9 | batch staus: 7680/60000 ( 13%) | Loss:  0.088906\n",
            "train epoch: 9 | batch staus: 8320/60000 ( 14%) | Loss:  0.116038\n",
            "train epoch: 9 | batch staus: 8960/60000 ( 15%) | Loss:  0.026421\n",
            "train epoch: 9 | batch staus: 9600/60000 ( 16%) | Loss:  0.079463\n",
            "train epoch: 9 | batch staus: 10240/60000 ( 17%) | Loss:  0.066575\n",
            "train epoch: 9 | batch staus: 10880/60000 ( 18%) | Loss:  0.010315\n",
            "train epoch: 9 | batch staus: 11520/60000 ( 19%) | Loss:  0.040360\n",
            "train epoch: 9 | batch staus: 12160/60000 ( 20%) | Loss:  0.033474\n",
            "train epoch: 9 | batch staus: 12800/60000 ( 21%) | Loss:  0.087804\n",
            "train epoch: 9 | batch staus: 13440/60000 ( 22%) | Loss:  0.066029\n",
            "train epoch: 9 | batch staus: 14080/60000 ( 23%) | Loss:  0.091642\n",
            "train epoch: 9 | batch staus: 14720/60000 ( 25%) | Loss:  0.129930\n",
            "train epoch: 9 | batch staus: 15360/60000 ( 26%) | Loss:  0.044313\n",
            "train epoch: 9 | batch staus: 16000/60000 ( 27%) | Loss:  0.171482\n",
            "train epoch: 9 | batch staus: 16640/60000 ( 28%) | Loss:  0.018611\n",
            "train epoch: 9 | batch staus: 17280/60000 ( 29%) | Loss:  0.035344\n",
            "train epoch: 9 | batch staus: 17920/60000 ( 30%) | Loss:  0.007005\n",
            "train epoch: 9 | batch staus: 18560/60000 ( 31%) | Loss:  0.074756\n",
            "train epoch: 9 | batch staus: 19200/60000 ( 32%) | Loss:  0.017925\n",
            "train epoch: 9 | batch staus: 19840/60000 ( 33%) | Loss:  0.021580\n",
            "train epoch: 9 | batch staus: 20480/60000 ( 34%) | Loss:  0.078235\n",
            "train epoch: 9 | batch staus: 21120/60000 ( 35%) | Loss:  0.030765\n",
            "train epoch: 9 | batch staus: 21760/60000 ( 36%) | Loss:  0.004623\n",
            "train epoch: 9 | batch staus: 22400/60000 ( 37%) | Loss:  0.075920\n",
            "train epoch: 9 | batch staus: 23040/60000 ( 38%) | Loss:  0.042095\n",
            "train epoch: 9 | batch staus: 23680/60000 ( 39%) | Loss:  0.084064\n",
            "train epoch: 9 | batch staus: 24320/60000 ( 41%) | Loss:  0.037379\n",
            "train epoch: 9 | batch staus: 24960/60000 ( 42%) | Loss:  0.064448\n",
            "train epoch: 9 | batch staus: 25600/60000 ( 43%) | Loss:  0.012092\n",
            "train epoch: 9 | batch staus: 26240/60000 ( 44%) | Loss:  0.034911\n",
            "train epoch: 9 | batch staus: 26880/60000 ( 45%) | Loss:  0.052321\n",
            "train epoch: 9 | batch staus: 27520/60000 ( 46%) | Loss:  0.103235\n",
            "train epoch: 9 | batch staus: 28160/60000 ( 47%) | Loss:  0.046148\n",
            "train epoch: 9 | batch staus: 28800/60000 ( 48%) | Loss:  0.137776\n",
            "train epoch: 9 | batch staus: 29440/60000 ( 49%) | Loss:  0.045871\n",
            "train epoch: 9 | batch staus: 30080/60000 ( 50%) | Loss:  0.025053\n",
            "train epoch: 9 | batch staus: 30720/60000 ( 51%) | Loss:  0.076391\n",
            "train epoch: 9 | batch staus: 31360/60000 ( 52%) | Loss:  0.009245\n",
            "train epoch: 9 | batch staus: 32000/60000 ( 53%) | Loss:  0.017286\n",
            "train epoch: 9 | batch staus: 32640/60000 ( 54%) | Loss:  0.100460\n",
            "train epoch: 9 | batch staus: 33280/60000 ( 55%) | Loss:  0.017772\n",
            "train epoch: 9 | batch staus: 33920/60000 ( 57%) | Loss:  0.058571\n",
            "train epoch: 9 | batch staus: 34560/60000 ( 58%) | Loss:  0.005570\n",
            "train epoch: 9 | batch staus: 35200/60000 ( 59%) | Loss:  0.017177\n",
            "train epoch: 9 | batch staus: 35840/60000 ( 60%) | Loss:  0.041064\n",
            "train epoch: 9 | batch staus: 36480/60000 ( 61%) | Loss:  0.033557\n",
            "train epoch: 9 | batch staus: 37120/60000 ( 62%) | Loss:  0.060314\n",
            "train epoch: 9 | batch staus: 37760/60000 ( 63%) | Loss:  0.107070\n",
            "train epoch: 9 | batch staus: 38400/60000 ( 64%) | Loss:  0.036152\n",
            "train epoch: 9 | batch staus: 39040/60000 ( 65%) | Loss:  0.029247\n",
            "train epoch: 9 | batch staus: 39680/60000 ( 66%) | Loss:  0.034578\n",
            "train epoch: 9 | batch staus: 40320/60000 ( 67%) | Loss:  0.095307\n",
            "train epoch: 9 | batch staus: 40960/60000 ( 68%) | Loss:  0.126830\n",
            "train epoch: 9 | batch staus: 41600/60000 ( 69%) | Loss:  0.038174\n",
            "train epoch: 9 | batch staus: 42240/60000 ( 70%) | Loss:  0.008698\n",
            "train epoch: 9 | batch staus: 42880/60000 ( 71%) | Loss:  0.051452\n",
            "train epoch: 9 | batch staus: 43520/60000 ( 72%) | Loss:  0.078686\n",
            "train epoch: 9 | batch staus: 44160/60000 ( 74%) | Loss:  0.021626\n",
            "train epoch: 9 | batch staus: 44800/60000 ( 75%) | Loss:  0.006808\n",
            "train epoch: 9 | batch staus: 45440/60000 ( 76%) | Loss:  0.011206\n",
            "train epoch: 9 | batch staus: 46080/60000 ( 77%) | Loss:  0.052553\n",
            "train epoch: 9 | batch staus: 46720/60000 ( 78%) | Loss:  0.006361\n",
            "train epoch: 9 | batch staus: 47360/60000 ( 79%) | Loss:  0.054171\n",
            "train epoch: 9 | batch staus: 48000/60000 ( 80%) | Loss:  0.124833\n",
            "train epoch: 9 | batch staus: 48640/60000 ( 81%) | Loss:  0.006594\n",
            "train epoch: 9 | batch staus: 49280/60000 ( 82%) | Loss:  0.031058\n",
            "train epoch: 9 | batch staus: 49920/60000 ( 83%) | Loss:  0.084243\n",
            "train epoch: 9 | batch staus: 50560/60000 ( 84%) | Loss:  0.047952\n",
            "train epoch: 9 | batch staus: 51200/60000 ( 85%) | Loss:  0.021332\n",
            "train epoch: 9 | batch staus: 51840/60000 ( 86%) | Loss:  0.022458\n",
            "train epoch: 9 | batch staus: 52480/60000 ( 87%) | Loss:  0.048476\n",
            "train epoch: 9 | batch staus: 53120/60000 ( 88%) | Loss:  0.034167\n",
            "train epoch: 9 | batch staus: 53760/60000 ( 90%) | Loss:  0.096004\n",
            "train epoch: 9 | batch staus: 54400/60000 ( 91%) | Loss:  0.065891\n",
            "train epoch: 9 | batch staus: 55040/60000 ( 92%) | Loss:  0.042385\n",
            "train epoch: 9 | batch staus: 55680/60000 ( 93%) | Loss:  0.022846\n",
            "train epoch: 9 | batch staus: 56320/60000 ( 94%) | Loss:  0.020657\n",
            "train epoch: 9 | batch staus: 56960/60000 ( 95%) | Loss:  0.031510\n",
            "train epoch: 9 | batch staus: 57600/60000 ( 96%) | Loss:  0.087693\n",
            "train epoch: 9 | batch staus: 58240/60000 ( 97%) | Loss:  0.108371\n",
            "train epoch: 9 | batch staus: 58880/60000 ( 98%) | Loss:  0.083679\n",
            "train epoch: 9 | batch staus: 59520/60000 ( 99%) | Loss:  0.003406\n",
            "Training time: 0m 23s\n",
            "=======\n",
            " test set: average loss:  0.0007, Accuracy: 9863/10000(99%)\n",
            "Testing time: 0m 25s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w00GJSaqovnX"
      },
      "source": [
        ""
      ]
    }
  ]
}