{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled21.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyOeuJUzmfV6Bh/0FIYF64dA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SIDED00R/machinelearning/blob/main/machinelearning1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "sIF5plCDA2cA",
        "outputId": "ecc84d26-0b2d-4fce-f030-50eaf8f44161"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "# handbook\n",
        "# from torch.autograd import Variable\n",
        "# handbook\n",
        "from layers import *\n",
        "from data import voc, coco\n",
        "import os\n",
        "\n",
        "\n",
        "class SSD(nn.Module):\n",
        "    \"\"\"Single Shot Multibox Architecture\n",
        "    The network is composed of a base VGG network followed by the\n",
        "    added multibox conv layers.  Each multibox layer branches into\n",
        "        1) conv2d for class conf scores\n",
        "        2) conv2d for localization predictions\n",
        "        3) associated priorbox layer to produce default bounding\n",
        "           boxes specific to the layer's feature map size.\n",
        "    See: https://arxiv.org/pdf/1512.02325.pdf for more details.\n",
        "    Args:\n",
        "        phase: (string) Can be \"test\" or \"train\"\n",
        "        size: input image size\n",
        "        base: VGG16 layers for input, size of either 300 or 500\n",
        "        extras: extra layers that feed to multibox loc and conf layers\n",
        "        head: \"multibox head\" consists of loc and conf conv layers\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, phase, size, base, extras, head, num_classes):\n",
        "        super(SSD, self).__init__()\n",
        "        self.phase = phase\n",
        "        self.num_classes = num_classes\n",
        "        self.cfg = (coco, voc)[num_classes == 21]\n",
        "        self.priorbox = PriorBox(self.cfg)\n",
        "        # handbook\n",
        "        # self.priors = Variable(self.priorbox.forward(), volatile=True)\n",
        "        self.priors = self.priorbox.forward()\n",
        "        # handbook\n",
        "        self.size = size\n",
        "\n",
        "        # SSD network\n",
        "        self.vgg = nn.ModuleList(base)\n",
        "        # Layer learns to scale the l2 normalized features from conv4_3\n",
        "        self.L2Norm = L2Norm(512, 20)\n",
        "        self.extras = nn.ModuleList(extras)\n",
        "        # オフセットと確信度のネットワークリスト\n",
        "        self.loc = nn.ModuleList(head[0])\n",
        "        self.conf = nn.ModuleList(head[1])\n",
        "\n",
        "        # demo実行時\n",
        "        if phase == 'test':\n",
        "            self.softmax = nn.Softmax(dim=-1)\n",
        "            # PyTorch1.5.0 support new-style autograd function\n",
        "            #self.detect = Detect(num_classes, 0, 200, 0.01, 0.45)\n",
        "            self.detect = Detect()\n",
        "            # PyTorch1.5.0 support new-style autograd function\n",
        "\n",
        "    # 順伝播\n",
        "    def forward(self, x):\n",
        "        \"\"\"Applies network layers and ops on input image(s) x.\n",
        "        Args:\n",
        "            x: input image or batch of images. Shape: [batch,3,300,300].\n",
        "        Return:\n",
        "            Depending on phase:\n",
        "            test:\n",
        "                Variable(tensor) of output class label predictions,\n",
        "                confidence score, and corresponding location predictions for\n",
        "                each object detected. Shape: [batch,topk,7]\n",
        "            train:\n",
        "                list of concat outputs from:\n",
        "                    1: confidence layers, Shape: [batch*num_priors,num_classes]\n",
        "                    2: localization layers, Shape: [batch,num_priors*4]\n",
        "                    3: priorbox layers, Shape: [2,num_priors*4]\n",
        "        \"\"\"\n",
        "        sources = list()\n",
        "        loc = list()\n",
        "        conf = list()\n",
        "\n",
        "        # apply vgg up to conv4_3 relu\n",
        "        for k in range(23):\n",
        "            x = self.vgg[k](x)\n",
        "        # Conv4-3>Reluの計算結果にL2Normを適用しsourcesに追加\n",
        "        s = self.L2Norm(x)\n",
        "        sources.append(s)\n",
        "\n",
        "        # apply vgg up to fc7\n",
        "        for k in range(23, len(self.vgg)):\n",
        "            x = self.vgg[k](x)\n",
        "        # Conv7>Reluの計算結果をsourcesに追加\n",
        "        sources.append(x)\n",
        "\n",
        "        # 追加ネットワークにrelu関数を追加し順伝播\n",
        "        # 奇数番目の層の計算結果をsourcesに追加\n",
        "        # apply extra layers and cache source layer outputs\n",
        "        for k, v in enumerate(self.extras):\n",
        "            x = F.relu(v(x), inplace=True)\n",
        "            if k % 2 == 1:\n",
        "                sources.append(x)\n",
        "\n",
        "        # apply multibox head to source layers\n",
        "        for (x, l, c) in zip(sources, self.loc, self.conf):\n",
        "            # (バッチサイズ,C,W,H) → (バッチサイズ,W,H,C)にTranspose\n",
        "            loc.append(l(x).permute(0, 2, 3, 1).contiguous())\n",
        "            conf.append(c(x).permute(0, 2, 3, 1).contiguous())\n",
        "\n",
        "        loc = torch.cat([o.view(o.size(0), -1) for o in loc], 1)\n",
        "        conf = torch.cat([o.view(o.size(0), -1) for o in conf], 1)\n",
        "        # demo実行時\n",
        "        if self.phase == \"test\":\n",
        "            # PyTorch1.5.0 support new-style autograd function\n",
        "            #output = self.detect(\n",
        "            output = self.detect.apply(self.num_classes, 0, 200, 0.01, 0.45,\n",
        "            # PyTorch1.5.0 support new-style autograd function\n",
        "                loc.view(loc.size(0), -1, 4),                   # loc preds\n",
        "                self.softmax(conf.view(conf.size(0), -1,\n",
        "                             self.num_classes)),                # conf preds\n",
        "                self.priors.type(type(x.data))                  # default boxes\n",
        "            )\n",
        "        else:\n",
        "        # train実行時\n",
        "            output = (\n",
        "                loc.view(loc.size(0), -1, 4),\n",
        "                conf.view(conf.size(0), -1, self.num_classes),\n",
        "                self.priors\n",
        "            )\n",
        "        return output\n",
        "\n",
        "    def load_weights(self, base_file):\n",
        "        other, ext = os.path.splitext(base_file)\n",
        "        if ext == '.pkl' or '.pth':\n",
        "            print('Loading weights into state dict...')\n",
        "            self.load_state_dict(torch.load(base_file,\n",
        "                                 map_location=lambda storage, loc: storage))\n",
        "            print('Finished!')\n",
        "        else:\n",
        "            print('Sorry only .pth and .pkl files supported.')\n",
        "\n",
        "\n",
        "# This function is derived from torchvision VGG make_layers()\n",
        "# https://github.com/pytorch/vision/blob/master/torchvision/models/vgg.py\n",
        "# ベースネットワークのリスト作成\n",
        "def vgg(cfg, i, batch_norm=False):\n",
        "    layers = []\n",
        "    in_channels = i\n",
        "    for v in cfg:\n",
        "        # プーリング層　300×300　→　150×150\n",
        "        if v == 'M':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2)]\n",
        "        # プーリング層で小数点切り上げ　75×75 →　38×38\n",
        "        elif v == 'C':\n",
        "            layers += [nn.MaxPool2d(kernel_size=2, stride=2, ceil_mode=True)]\n",
        "        else:\n",
        "            conv2d = nn.Conv2d(in_channels, v, kernel_size=3, padding=1)\n",
        "            if batch_norm:\n",
        "                layers += [conv2d, nn.BatchNorm2d(v), nn.ReLU(inplace=True)]\n",
        "            else:\n",
        "                layers += [conv2d, nn.ReLU(inplace=True)]\n",
        "            in_channels = v\n",
        "    pool5 = nn.MaxPool2d(kernel_size=3, stride=1, padding=1)\n",
        "    conv6 = nn.Conv2d(512, 1024, kernel_size=3, padding=6, dilation=6)\n",
        "    conv7 = nn.Conv2d(1024, 1024, kernel_size=1)\n",
        "    layers += [pool5, conv6,\n",
        "               nn.ReLU(inplace=True), conv7, nn.ReLU(inplace=True)]\n",
        "    return layers\n",
        "\n",
        "\n",
        "# 追加ネットワークのリスト作成\n",
        "def add_extras(cfg, i, batch_norm=False):\n",
        "    # Extra layers added to VGG for feature scaling\n",
        "    layers = []\n",
        "    in_channels = i\n",
        "    flag = False\n",
        "    for k, v in enumerate(cfg):\n",
        "        if in_channels != 'S':\n",
        "            if v == 'S':\n",
        "                # strideが2\n",
        "                layers += [nn.Conv2d(in_channels, cfg[k + 1],\n",
        "                           kernel_size=(1, 3)[flag], stride=2, padding=1)]\n",
        "            else:\n",
        "                layers += [nn.Conv2d(in_channels, v, kernel_size=(1, 3)[flag])]\n",
        "            flag = not flag\n",
        "        in_channels = v\n",
        "    return layers\n",
        "\n",
        "# オフセット、確信度のネットワークのリスト作成\n",
        "def multibox(vgg, extra_layers, cfg, num_classes):\n",
        "    loc_layers = []\n",
        "    conf_layers = []\n",
        "    vgg_source = [21, -2]\n",
        "    # ベースの21のConv4-3と-2(最後から2番目)のConv7を特徴マップのリストに追加\n",
        "    for k, v in enumerate(vgg_source):\n",
        "        # 出力層の数はアスペクト比の数×座標数\n",
        "        loc_layers += [nn.Conv2d(vgg[v].out_channels,\n",
        "                                 cfg[k] * 4, kernel_size=3, padding=1)]\n",
        "        # 出力層の数はアスペクト比の数×クラス数\n",
        "        conf_layers += [nn.Conv2d(vgg[v].out_channels,\n",
        "                        cfg[k] * num_classes, kernel_size=3, padding=1)]\n",
        "    # 追加ネットの内、奇数番目の層を特徴マップのリストに追加\n",
        "    for k, v in enumerate(extra_layers[1::2], 2):\n",
        "        # 出力層の数はアスペクト比の数×座標数\n",
        "        loc_layers += [nn.Conv2d(v.out_channels, cfg[k]\n",
        "                                 * 4, kernel_size=3, padding=1)]\n",
        "        # 出力層の数はアスペクト比の数×クラス数\n",
        "        conf_layers += [nn.Conv2d(v.out_channels, cfg[k]\n",
        "                                  * num_classes, kernel_size=3, padding=1)]\n",
        "    return vgg, extra_layers, (loc_layers, conf_layers)\n",
        "\n",
        "# 数字は入力チャンネル、M,Cはプーリング、Sはstride=2\n",
        "base = {\n",
        "    '300': [64, 64, 'M', 128, 128, 'M', 256, 256, 256, 'C', 512, 512, 512, 'M',\n",
        "            512, 512, 512],\n",
        "    '512': [],\n",
        "}\n",
        "extras = {\n",
        "    '300': [256, 'S', 512, 128, 'S', 256, 128, 256, 128, 256],\n",
        "    '512': [],\n",
        "}\n",
        "# 特徴マップ毎のアスペクト比の数\n",
        "mbox = {\n",
        "    '300': [4, 6, 6, 6, 4, 4],  # number of boxes per feature map location\n",
        "    '512': [],\n",
        "}\n",
        "\n",
        "# ネットワークのリスト作成\n",
        "def build_ssd(phase, size=300, num_classes=21):\n",
        "    if phase != \"test\" and phase != \"train\":\n",
        "        print(\"ERROR: Phase: \" + phase + \" not recognized\")\n",
        "        return\n",
        "    if size != 300:\n",
        "        print(\"ERROR: You specified size \" + repr(size) + \". However, \" +\n",
        "              \"currently only SSD300 (size=300) is supported!\")\n",
        "        return\n",
        "    # ベース、追加、オフセット、確信度のネットワークリストはクラスSSDの引数\n",
        "    base_, extras_, head_ = multibox(vgg(base[str(size)], 3),\n",
        "                                     add_extras(extras[str(size)], 1024),\n",
        "                                     mbox[str(size)], num_classes)\n",
        "    return SSD(phase, size, base_, extras_, head_, num_classes)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-31168d76c870>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# from torch.autograd import Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# handbook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mlayers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcoco\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'layers'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 378
        },
        "id": "15hWF4QeA3wk",
        "outputId": "381ffbc7-eaa0-4730-9a2b-49be8815cdef"
      },
      "source": [
        "import torch\n",
        "from torch.autograd import Function\n",
        "from ..box_utils import decode, nms\n",
        "from data import voc as cfg\n",
        "\n",
        "\n",
        "class Detect(Function):\n",
        "    \"\"\"At test time, Detect is the final layer of SSD.  Decode location preds,\n",
        "    apply non-maximum suppression to location predictions based on conf\n",
        "    scores and threshold to a top_k number of output predictions for both\n",
        "    confidence score and locations.\n",
        "    \"\"\"\n",
        "    # PyTorch1.5.0 support new-style autograd function\n",
        "    #def __init__(self, num_classes, bkg_label, top_k, conf_thresh, nms_thresh):\n",
        "    #    self.num_classes = num_classes\n",
        "    #    self.background_label = bkg_label\n",
        "    #    self.top_k = top_k\n",
        "    #    # Parameters used in nms.\n",
        "    #    self.nms_thresh = nms_thresh\n",
        "    #    if nms_thresh <= 0:\n",
        "    #        raise ValueError('nms_threshold must be non negative.')\n",
        "    #    self.conf_thresh = conf_thresh\n",
        "    #    self.variance = cfg['variance']\n",
        "\n",
        "    #def forward(self, loc_data, conf_data, prior_data):\n",
        "    @staticmethod\n",
        "    def forward(self, num_classes, bkg_label, top_k, conf_thresh, nms_thresh, loc_data, conf_data, prior_data):\n",
        "        self.num_classes = num_classes\n",
        "        self.background_label = bkg_label\n",
        "        self.top_k = top_k\n",
        "        # Parameters used in nms.\n",
        "        self.nms_thresh = nms_thresh\n",
        "        if nms_thresh <= 0:\n",
        "            raise ValueError('nms_threshold must be non negative.')\n",
        "        self.conf_thresh = conf_thresh\n",
        "        self.variance = cfg['variance']\n",
        "    # PyTorch1.5.0 support new-style autograd function\n",
        "        \"\"\"\n",
        "        Args:\n",
        "            loc_data: (tensor) Loc preds from loc layers\n",
        "                Shape: [batch,num_priors*4]\n",
        "            conf_data: (tensor) Shape: Conf preds from conf layers\n",
        "                Shape: [batch*num_priors,num_classes]\n",
        "            prior_data: (tensor) Prior boxes and variances from priorbox layers\n",
        "                Shape: [1,num_priors,4]\n",
        "        \"\"\"\n",
        "        num = loc_data.size(0)  # batch size\n",
        "        num_priors = prior_data.size(0)\n",
        "        # [バッチサイズN,クラス数21,トップ200件,確信度+位置]のゼロリストを作成\n",
        "        output = torch.zeros(num, self.num_classes, self.top_k, 5)\n",
        "        # 確信度を[バッチサイズN,クラス数,ボックス数]の順番に変更\n",
        "        conf_preds = conf_data.view(num, num_priors,\n",
        "                                    self.num_classes).transpose(2, 1)\n",
        "\n",
        "        # Decode predictions into bboxes.\n",
        "        for i in range(num):\n",
        "            decoded_boxes = decode(loc_data[i], prior_data, self.variance)\n",
        "            # For each class, perform nms\n",
        "            conf_scores = conf_preds[i].clone()\n",
        "\n",
        "            for cl in range(1, self.num_classes):\n",
        "                # 確信度の閾値を使ってボックスを削除\n",
        "                c_mask = conf_scores[cl].gt(self.conf_thresh)\n",
        "                scores = conf_scores[cl][c_mask]\n",
        "                # handbook\n",
        "                #if scores.dim() == 0:\n",
        "                if scores.size(0) == 0:\n",
        "                # handbook\n",
        "                    continue\n",
        "                l_mask = c_mask.unsqueeze(1).expand_as(decoded_boxes)\n",
        "                # ボックスのデコード処理\n",
        "                boxes = decoded_boxes[l_mask].view(-1, 4)\n",
        "                # idx of highest scoring and non-overlapping boxes per class\n",
        "                # boxesからNMSで重複するボックスを削除\n",
        "                ids, count = nms(boxes, scores, self.nms_thresh, self.top_k)\n",
        "                output[i, cl, :count] = \\\n",
        "                    torch.cat((scores[ids[:count]].unsqueeze(1),\n",
        "                               boxes[ids[:count]]), 1)\n",
        "        flt = output.contiguous().view(num, -1, 5)\n",
        "        _, idx = flt[:, :, 0].sort(1, descending=True)\n",
        "        _, rank = idx.sort(1)\n",
        "        flt[(rank < self.top_k).unsqueeze(-1).expand_as(flt)].fill_(0)\n",
        "        return output"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ImportError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-ebecbcbd2e23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbox_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdecode\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mdata\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mvoc\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mcfg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mImportError\u001b[0m: attempted relative import with no known parent package",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ],
          "errorDetails": {
            "actions": [
              {
                "action": "open_url",
                "actionText": "Open Examples",
                "url": "/notebooks/snippets/importing_libraries.ipynb"
              }
            ]
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m0nLixYBBJe7"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}