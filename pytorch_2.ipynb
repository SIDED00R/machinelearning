{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch#2.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyPlzw6IQmzCutqicYhyKS4Z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/SIDED00R/machinelearning/blob/main/pytorch_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yF_0Xs6bUN92",
        "outputId": "6e8fe887-774f-41d1-bdd4-28ccceb0be46"
      },
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "x_data=[1.0,2.0,3.0]\n",
        "y_data=[2.0,4.0,6.0]\n",
        "\n",
        "w=torch.tensor([1.0],requires_grad=True)\n",
        "\n",
        "def forward(x):\n",
        "  return x*w\n",
        "def loss(x,y):\n",
        "  y_pred=forward(x)\n",
        "  return (y_pred-y)**2\n",
        "\n",
        "for epoch in range(10):\n",
        "  for x_val,y_val in zip(x_data,y_data):\n",
        "    y_pred=forward(x_val)\n",
        "    l=loss(x_val,y_val)\n",
        "    l.backward() # Back propagation to update weights\n",
        "    print(\"\\tgrad: \",x_val,y_val,w.grad.item())\n",
        "    w.data=w.data-0.01*w.grad.item()\n",
        "    w.grad.data.zero_()\n",
        "\n",
        "  print(f\"Epoch: {epoch} l Loss: {l.item()}\")\n",
        "print(\"Prediction (after training\", 4, forward(4).item())"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\tgrad:  1.0 2.0 -2.0\n",
            "\tgrad:  2.0 4.0 -7.840000152587891\n",
            "\tgrad:  3.0 6.0 -16.228801727294922\n",
            "Epoch: 0 l Loss: 7.315943717956543\n",
            "\tgrad:  1.0 2.0 -1.478623867034912\n",
            "\tgrad:  2.0 4.0 -5.796205520629883\n",
            "\tgrad:  3.0 6.0 -11.998146057128906\n",
            "Epoch: 1 l Loss: 3.9987640380859375\n",
            "\tgrad:  1.0 2.0 -1.0931644439697266\n",
            "\tgrad:  2.0 4.0 -4.285204887390137\n",
            "\tgrad:  3.0 6.0 -8.870372772216797\n",
            "Epoch: 2 l Loss: 2.1856532096862793\n",
            "\tgrad:  1.0 2.0 -0.8081896305084229\n",
            "\tgrad:  2.0 4.0 -3.1681032180786133\n",
            "\tgrad:  3.0 6.0 -6.557973861694336\n",
            "Epoch: 3 l Loss: 1.1946394443511963\n",
            "\tgrad:  1.0 2.0 -0.5975041389465332\n",
            "\tgrad:  2.0 4.0 -2.3422164916992188\n",
            "\tgrad:  3.0 6.0 -4.848389625549316\n",
            "Epoch: 4 l Loss: 0.6529689431190491\n",
            "\tgrad:  1.0 2.0 -0.4417421817779541\n",
            "\tgrad:  2.0 4.0 -1.7316293716430664\n",
            "\tgrad:  3.0 6.0 -3.58447265625\n",
            "Epoch: 5 l Loss: 0.35690122842788696\n",
            "\tgrad:  1.0 2.0 -0.3265852928161621\n",
            "\tgrad:  2.0 4.0 -1.2802143096923828\n",
            "\tgrad:  3.0 6.0 -2.650045394897461\n",
            "Epoch: 6 l Loss: 0.195076122879982\n",
            "\tgrad:  1.0 2.0 -0.24144840240478516\n",
            "\tgrad:  2.0 4.0 -0.9464778900146484\n",
            "\tgrad:  3.0 6.0 -1.9592113494873047\n",
            "Epoch: 7 l Loss: 0.10662525147199631\n",
            "\tgrad:  1.0 2.0 -0.17850565910339355\n",
            "\tgrad:  2.0 4.0 -0.699742317199707\n",
            "\tgrad:  3.0 6.0 -1.4484672546386719\n",
            "Epoch: 8 l Loss: 0.0582793727517128\n",
            "\tgrad:  1.0 2.0 -0.1319713592529297\n",
            "\tgrad:  2.0 4.0 -0.5173273086547852\n",
            "\tgrad:  3.0 6.0 -1.070866584777832\n",
            "Epoch: 9 l Loss: 0.03185431286692619\n",
            "Prediction (after training 4 7.804864406585693\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB9w04J5Y80x",
        "outputId": "a3bf8bad-314f-413b-98fe-06aaadc86c2c"
      },
      "source": [
        "from torch import nn\n",
        "import torch\n",
        "from torch import tensor\n",
        "\n",
        "x_data=tensor([[1.0],[2.0],[3.0]])\n",
        "y_data=tensor([[2.0],[4.0],[6.0]])\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.linear = torch.nn.Linear(1, 1)\n",
        "    #(1,1) x->y( y= wx)\n",
        "    #(2,1) (x1,x2)->y : y=x1*x1 + x2*w2\n",
        "    #(2, 2) (x1,x2)->(y1, y2)\n",
        "  def forward(self, x):\n",
        "    y_pred=self.linear(x)\n",
        "    return y_pred\n",
        "  \n",
        "model=Model()\n",
        "criterion=torch.nn.MSELoss(reduction='sum')\n",
        "optimizer=torch.optim.SGD(model.parameters(), lr= 0.01)\n",
        "\n",
        "for epoch in range(500):\n",
        "  y_pred=model(x_data)\n",
        "  loss = criterion(y_pred,y_data)\n",
        "  print(f'Epoch: {epoch} | Loss: {loss.item()}')\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step() # w=w-0.01*w.grad().item()\n",
        "\n",
        "hour_var = tensor([4.0])\n",
        "y_pred=model(hour_var)\n",
        "print(\"Prediction (after training\", 4, model(hour_var).item() )\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 0 | Loss: 47.762786865234375\n",
            "Epoch: 1 | Loss: 21.411907196044922\n",
            "Epoch: 2 | Loss: 9.679096221923828\n",
            "Epoch: 3 | Loss: 4.453868865966797\n",
            "Epoch: 4 | Loss: 2.1256611347198486\n",
            "Epoch: 5 | Loss: 1.087154746055603\n",
            "Epoch: 6 | Loss: 0.6228173971176147\n",
            "Epoch: 7 | Loss: 0.4141119122505188\n",
            "Epoch: 8 | Loss: 0.31923481822013855\n",
            "Epoch: 9 | Loss: 0.27506023645401\n",
            "Epoch: 10 | Loss: 0.25348442792892456\n",
            "Epoch: 11 | Loss: 0.24199619889259338\n",
            "Epoch: 12 | Loss: 0.2350255250930786\n",
            "Epoch: 13 | Loss: 0.2300931215286255\n",
            "Epoch: 14 | Loss: 0.22609442472457886\n",
            "Epoch: 15 | Loss: 0.22253699600696564\n",
            "Epoch: 16 | Loss: 0.2192014902830124\n",
            "Epoch: 17 | Loss: 0.21599040925502777\n",
            "Epoch: 18 | Loss: 0.21285894513130188\n",
            "Epoch: 19 | Loss: 0.20978763699531555\n",
            "Epoch: 20 | Loss: 0.20676717162132263\n",
            "Epoch: 21 | Loss: 0.20379340648651123\n",
            "Epoch: 22 | Loss: 0.20086337625980377\n",
            "Epoch: 23 | Loss: 0.19797612726688385\n",
            "Epoch: 24 | Loss: 0.19513073563575745\n",
            "Epoch: 25 | Loss: 0.1923263818025589\n",
            "Epoch: 26 | Loss: 0.18956226110458374\n",
            "Epoch: 27 | Loss: 0.18683801591396332\n",
            "Epoch: 28 | Loss: 0.18415279686450958\n",
            "Epoch: 29 | Loss: 0.18150615692138672\n",
            "Epoch: 30 | Loss: 0.17889750003814697\n",
            "Epoch: 31 | Loss: 0.17632661759853363\n",
            "Epoch: 32 | Loss: 0.17379246652126312\n",
            "Epoch: 33 | Loss: 0.17129503190517426\n",
            "Epoch: 34 | Loss: 0.168832927942276\n",
            "Epoch: 35 | Loss: 0.16640663146972656\n",
            "Epoch: 36 | Loss: 0.16401509940624237\n",
            "Epoch: 37 | Loss: 0.16165798902511597\n",
            "Epoch: 38 | Loss: 0.15933459997177124\n",
            "Epoch: 39 | Loss: 0.15704472362995148\n",
            "Epoch: 40 | Loss: 0.15478774905204773\n",
            "Epoch: 41 | Loss: 0.15256330370903015\n",
            "Epoch: 42 | Loss: 0.15037088096141815\n",
            "Epoch: 43 | Loss: 0.14820978045463562\n",
            "Epoch: 44 | Loss: 0.14607977867126465\n",
            "Epoch: 45 | Loss: 0.14398008584976196\n",
            "Epoch: 46 | Loss: 0.14191091060638428\n",
            "Epoch: 47 | Loss: 0.1398714780807495\n",
            "Epoch: 48 | Loss: 0.13786117732524872\n",
            "Epoch: 49 | Loss: 0.13588014245033264\n",
            "Epoch: 50 | Loss: 0.13392730057239532\n",
            "Epoch: 51 | Loss: 0.13200247287750244\n",
            "Epoch: 52 | Loss: 0.13010552525520325\n",
            "Epoch: 53 | Loss: 0.12823565304279327\n",
            "Epoch: 54 | Loss: 0.12639246881008148\n",
            "Epoch: 55 | Loss: 0.12457624077796936\n",
            "Epoch: 56 | Loss: 0.12278599292039871\n",
            "Epoch: 57 | Loss: 0.1210210770368576\n",
            "Epoch: 58 | Loss: 0.1192818358540535\n",
            "Epoch: 59 | Loss: 0.11756773293018341\n",
            "Epoch: 60 | Loss: 0.11587798595428467\n",
            "Epoch: 61 | Loss: 0.11421268433332443\n",
            "Epoch: 62 | Loss: 0.11257124692201614\n",
            "Epoch: 63 | Loss: 0.11095338314771652\n",
            "Epoch: 64 | Loss: 0.10935887694358826\n",
            "Epoch: 65 | Loss: 0.10778715461492538\n",
            "Epoch: 66 | Loss: 0.10623820126056671\n",
            "Epoch: 67 | Loss: 0.10471124947071075\n",
            "Epoch: 68 | Loss: 0.10320651531219482\n",
            "Epoch: 69 | Loss: 0.1017233356833458\n",
            "Epoch: 70 | Loss: 0.10026121884584427\n",
            "Epoch: 71 | Loss: 0.09882029891014099\n",
            "Epoch: 72 | Loss: 0.0974000096321106\n",
            "Epoch: 73 | Loss: 0.09600038081407547\n",
            "Epoch: 74 | Loss: 0.09462064504623413\n",
            "Epoch: 75 | Loss: 0.09326093643903732\n",
            "Epoch: 76 | Loss: 0.09192057698965073\n",
            "Epoch: 77 | Loss: 0.09059961885213852\n",
            "Epoch: 78 | Loss: 0.08929740637540817\n",
            "Epoch: 79 | Loss: 0.08801419287919998\n",
            "Epoch: 80 | Loss: 0.08674920350313187\n",
            "Epoch: 81 | Loss: 0.08550233393907547\n",
            "Epoch: 82 | Loss: 0.08427365869283676\n",
            "Epoch: 83 | Loss: 0.08306248486042023\n",
            "Epoch: 84 | Loss: 0.08186877518892288\n",
            "Epoch: 85 | Loss: 0.08069221675395966\n",
            "Epoch: 86 | Loss: 0.07953251898288727\n",
            "Epoch: 87 | Loss: 0.07838963717222214\n",
            "Epoch: 88 | Loss: 0.07726296037435532\n",
            "Epoch: 89 | Loss: 0.07615260034799576\n",
            "Epoch: 90 | Loss: 0.07505811750888824\n",
            "Epoch: 91 | Loss: 0.07397949695587158\n",
            "Epoch: 92 | Loss: 0.07291627675294876\n",
            "Epoch: 93 | Loss: 0.07186824083328247\n",
            "Epoch: 94 | Loss: 0.0708354040980339\n",
            "Epoch: 95 | Loss: 0.06981730461120605\n",
            "Epoch: 96 | Loss: 0.0688139796257019\n",
            "Epoch: 97 | Loss: 0.06782509386539459\n",
            "Epoch: 98 | Loss: 0.06685040891170502\n",
            "Epoch: 99 | Loss: 0.0658896267414093\n",
            "Epoch: 100 | Loss: 0.06494271755218506\n",
            "Epoch: 101 | Loss: 0.06400935351848602\n",
            "Epoch: 102 | Loss: 0.06308940052986145\n",
            "Epoch: 103 | Loss: 0.06218267232179642\n",
            "Epoch: 104 | Loss: 0.06128909811377525\n",
            "Epoch: 105 | Loss: 0.060408126562833786\n",
            "Epoch: 106 | Loss: 0.059540044516325\n",
            "Epoch: 107 | Loss: 0.058684367686510086\n",
            "Epoch: 108 | Loss: 0.05784095078706741\n",
            "Epoch: 109 | Loss: 0.057009853422641754\n",
            "Epoch: 110 | Loss: 0.056190453469753265\n",
            "Epoch: 111 | Loss: 0.055382903665304184\n",
            "Epoch: 112 | Loss: 0.054586995393037796\n",
            "Epoch: 113 | Loss: 0.05380234867334366\n",
            "Epoch: 114 | Loss: 0.05302925407886505\n",
            "Epoch: 115 | Loss: 0.0522671714425087\n",
            "Epoch: 116 | Loss: 0.05151592195034027\n",
            "Epoch: 117 | Loss: 0.050775621086359024\n",
            "Epoch: 118 | Loss: 0.0500459223985672\n",
            "Epoch: 119 | Loss: 0.04932660982012749\n",
            "Epoch: 120 | Loss: 0.04861775040626526\n",
            "Epoch: 121 | Loss: 0.04791902378201485\n",
            "Epoch: 122 | Loss: 0.0472303070127964\n",
            "Epoch: 123 | Loss: 0.04655158147215843\n",
            "Epoch: 124 | Loss: 0.045882485806941986\n",
            "Epoch: 125 | Loss: 0.045223135501146317\n",
            "Epoch: 126 | Loss: 0.04457325488328934\n",
            "Epoch: 127 | Loss: 0.043932609260082245\n",
            "Epoch: 128 | Loss: 0.043301209807395935\n",
            "Epoch: 129 | Loss: 0.04267900064587593\n",
            "Epoch: 130 | Loss: 0.04206560552120209\n",
            "Epoch: 131 | Loss: 0.041461024433374405\n",
            "Epoch: 132 | Loss: 0.04086511582136154\n",
            "Epoch: 133 | Loss: 0.04027785360813141\n",
            "Epoch: 134 | Loss: 0.0396990105509758\n",
            "Epoch: 135 | Loss: 0.03912840038537979\n",
            "Epoch: 136 | Loss: 0.038566119968891144\n",
            "Epoch: 137 | Loss: 0.03801187500357628\n",
            "Epoch: 138 | Loss: 0.03746560215950012\n",
            "Epoch: 139 | Loss: 0.03692708909511566\n",
            "Epoch: 140 | Loss: 0.03639647364616394\n",
            "Epoch: 141 | Loss: 0.035873427987098694\n",
            "Epoch: 142 | Loss: 0.03535781055688858\n",
            "Epoch: 143 | Loss: 0.034849680960178375\n",
            "Epoch: 144 | Loss: 0.03434883803129196\n",
            "Epoch: 145 | Loss: 0.03385521471500397\n",
            "Epoch: 146 | Loss: 0.033368658274412155\n",
            "Epoch: 147 | Loss: 0.03288900852203369\n",
            "Epoch: 148 | Loss: 0.03241638094186783\n",
            "Epoch: 149 | Loss: 0.031950563192367554\n",
            "Epoch: 150 | Loss: 0.03149126097559929\n",
            "Epoch: 151 | Loss: 0.031038768589496613\n",
            "Epoch: 152 | Loss: 0.03059273399412632\n",
            "Epoch: 153 | Loss: 0.030152924358844757\n",
            "Epoch: 154 | Loss: 0.02971974015235901\n",
            "Epoch: 155 | Loss: 0.02929254248738289\n",
            "Epoch: 156 | Loss: 0.028871610760688782\n",
            "Epoch: 157 | Loss: 0.028456639498472214\n",
            "Epoch: 158 | Loss: 0.028047651052474976\n",
            "Epoch: 159 | Loss: 0.027644522488117218\n",
            "Epoch: 160 | Loss: 0.027247201651334763\n",
            "Epoch: 161 | Loss: 0.026855643838644028\n",
            "Epoch: 162 | Loss: 0.026469692587852478\n",
            "Epoch: 163 | Loss: 0.02608933113515377\n",
            "Epoch: 164 | Loss: 0.025714371353387833\n",
            "Epoch: 165 | Loss: 0.025344839319586754\n",
            "Epoch: 166 | Loss: 0.024980591610074043\n",
            "Epoch: 167 | Loss: 0.02462156116962433\n",
            "Epoch: 168 | Loss: 0.024267762899398804\n",
            "Epoch: 169 | Loss: 0.023918965831398964\n",
            "Epoch: 170 | Loss: 0.023575201630592346\n",
            "Epoch: 171 | Loss: 0.02323639765381813\n",
            "Epoch: 172 | Loss: 0.022902384400367737\n",
            "Epoch: 173 | Loss: 0.022573299705982208\n",
            "Epoch: 174 | Loss: 0.022248927503824234\n",
            "Epoch: 175 | Loss: 0.021929126232862473\n",
            "Epoch: 176 | Loss: 0.02161397412419319\n",
            "Epoch: 177 | Loss: 0.021303288638591766\n",
            "Epoch: 178 | Loss: 0.020997215062379837\n",
            "Epoch: 179 | Loss: 0.020695455372333527\n",
            "Epoch: 180 | Loss: 0.020398013293743134\n",
            "Epoch: 181 | Loss: 0.020104801282286644\n",
            "Epoch: 182 | Loss: 0.019815856590867043\n",
            "Epoch: 183 | Loss: 0.0195311326533556\n",
            "Epoch: 184 | Loss: 0.019250381737947464\n",
            "Epoch: 185 | Loss: 0.01897371932864189\n",
            "Epoch: 186 | Loss: 0.018701087683439255\n",
            "Epoch: 187 | Loss: 0.01843227818608284\n",
            "Epoch: 188 | Loss: 0.018167372792959213\n",
            "Epoch: 189 | Loss: 0.017906315624713898\n",
            "Epoch: 190 | Loss: 0.017648976296186447\n",
            "Epoch: 191 | Loss: 0.017395278438925743\n",
            "Epoch: 192 | Loss: 0.017145346850156784\n",
            "Epoch: 193 | Loss: 0.016898920759558678\n",
            "Epoch: 194 | Loss: 0.016656072810292244\n",
            "Epoch: 195 | Loss: 0.016416652128100395\n",
            "Epoch: 196 | Loss: 0.016180813312530518\n",
            "Epoch: 197 | Loss: 0.01594824343919754\n",
            "Epoch: 198 | Loss: 0.01571904867887497\n",
            "Epoch: 199 | Loss: 0.015493093058466911\n",
            "Epoch: 200 | Loss: 0.015270431526005268\n",
            "Epoch: 201 | Loss: 0.01505096536129713\n",
            "Epoch: 202 | Loss: 0.014834688976407051\n",
            "Epoch: 203 | Loss: 0.014621509239077568\n",
            "Epoch: 204 | Loss: 0.014411380514502525\n",
            "Epoch: 205 | Loss: 0.014204268343746662\n",
            "Epoch: 206 | Loss: 0.01400009449571371\n",
            "Epoch: 207 | Loss: 0.013798881322145462\n",
            "Epoch: 208 | Loss: 0.013600587844848633\n",
            "Epoch: 209 | Loss: 0.013405095785856247\n",
            "Epoch: 210 | Loss: 0.013212510384619236\n",
            "Epoch: 211 | Loss: 0.013022572733461857\n",
            "Epoch: 212 | Loss: 0.012835484929382801\n",
            "Epoch: 213 | Loss: 0.012651014141738415\n",
            "Epoch: 214 | Loss: 0.012469183653593063\n",
            "Epoch: 215 | Loss: 0.012289975769817829\n",
            "Epoch: 216 | Loss: 0.01211335975676775\n",
            "Epoch: 217 | Loss: 0.011939202435314655\n",
            "Epoch: 218 | Loss: 0.011767623946070671\n",
            "Epoch: 219 | Loss: 0.011598504148423672\n",
            "Epoch: 220 | Loss: 0.011431857943534851\n",
            "Epoch: 221 | Loss: 0.011267532594501972\n",
            "Epoch: 222 | Loss: 0.011105635203421116\n",
            "Epoch: 223 | Loss: 0.010945999063551426\n",
            "Epoch: 224 | Loss: 0.01078873872756958\n",
            "Epoch: 225 | Loss: 0.010633653961122036\n",
            "Epoch: 226 | Loss: 0.010480880737304688\n",
            "Epoch: 227 | Loss: 0.01033022440969944\n",
            "Epoch: 228 | Loss: 0.010181756690144539\n",
            "Epoch: 229 | Loss: 0.01003541611135006\n",
            "Epoch: 230 | Loss: 0.009891165420413017\n",
            "Epoch: 231 | Loss: 0.009749089367687702\n",
            "Epoch: 232 | Loss: 0.009608913213014603\n",
            "Epoch: 233 | Loss: 0.00947081670165062\n",
            "Epoch: 234 | Loss: 0.009334742091596127\n",
            "Epoch: 235 | Loss: 0.009200593456625938\n",
            "Epoch: 236 | Loss: 0.009068375453352928\n",
            "Epoch: 237 | Loss: 0.008938008919358253\n",
            "Epoch: 238 | Loss: 0.008809568360447884\n",
            "Epoch: 239 | Loss: 0.008682952262461185\n",
            "Epoch: 240 | Loss: 0.00855818297713995\n",
            "Epoch: 241 | Loss: 0.008435149677097797\n",
            "Epoch: 242 | Loss: 0.008313950151205063\n",
            "Epoch: 243 | Loss: 0.008194508031010628\n",
            "Epoch: 244 | Loss: 0.008076738566160202\n",
            "Epoch: 245 | Loss: 0.007960638031363487\n",
            "Epoch: 246 | Loss: 0.00784625206142664\n",
            "Epoch: 247 | Loss: 0.007733476348221302\n",
            "Epoch: 248 | Loss: 0.007622349075973034\n",
            "Epoch: 249 | Loss: 0.00751279853284359\n",
            "Epoch: 250 | Loss: 0.00740480562672019\n",
            "Epoch: 251 | Loss: 0.0072983745485544205\n",
            "Epoch: 252 | Loss: 0.007193522062152624\n",
            "Epoch: 253 | Loss: 0.007090119179338217\n",
            "Epoch: 254 | Loss: 0.006988232489675283\n",
            "Epoch: 255 | Loss: 0.006887797266244888\n",
            "Epoch: 256 | Loss: 0.006788774859160185\n",
            "Epoch: 257 | Loss: 0.006691220682114363\n",
            "Epoch: 258 | Loss: 0.0065951040014624596\n",
            "Epoch: 259 | Loss: 0.0065002781338989735\n",
            "Epoch: 260 | Loss: 0.006406869739294052\n",
            "Epoch: 261 | Loss: 0.006314793135970831\n",
            "Epoch: 262 | Loss: 0.006224039010703564\n",
            "Epoch: 263 | Loss: 0.0061345938593149185\n",
            "Epoch: 264 | Loss: 0.006046433001756668\n",
            "Epoch: 265 | Loss: 0.00595957413315773\n",
            "Epoch: 266 | Loss: 0.005873856600373983\n",
            "Epoch: 267 | Loss: 0.005789471790194511\n",
            "Epoch: 268 | Loss: 0.00570629583671689\n",
            "Epoch: 269 | Loss: 0.00562424398958683\n",
            "Epoch: 270 | Loss: 0.005543397273868322\n",
            "Epoch: 271 | Loss: 0.005463750101625919\n",
            "Epoch: 272 | Loss: 0.005385255441069603\n",
            "Epoch: 273 | Loss: 0.005307832732796669\n",
            "Epoch: 274 | Loss: 0.005231555551290512\n",
            "Epoch: 275 | Loss: 0.005156406667083502\n",
            "Epoch: 276 | Loss: 0.005082302261143923\n",
            "Epoch: 277 | Loss: 0.005009245127439499\n",
            "Epoch: 278 | Loss: 0.00493723526597023\n",
            "Epoch: 279 | Loss: 0.004866295028477907\n",
            "Epoch: 280 | Loss: 0.00479632243514061\n",
            "Epoch: 281 | Loss: 0.004727412946522236\n",
            "Epoch: 282 | Loss: 0.004659458063542843\n",
            "Epoch: 283 | Loss: 0.004592495504766703\n",
            "Epoch: 284 | Loss: 0.004526510834693909\n",
            "Epoch: 285 | Loss: 0.0044614458456635475\n",
            "Epoch: 286 | Loss: 0.004397365264594555\n",
            "Epoch: 287 | Loss: 0.004334146156907082\n",
            "Epoch: 288 | Loss: 0.004271875135600567\n",
            "Epoch: 289 | Loss: 0.004210461862385273\n",
            "Epoch: 290 | Loss: 0.004149931482970715\n",
            "Epoch: 291 | Loss: 0.004090330097824335\n",
            "Epoch: 292 | Loss: 0.0040315184742212296\n",
            "Epoch: 293 | Loss: 0.003973572049289942\n",
            "Epoch: 294 | Loss: 0.0039164782501757145\n",
            "Epoch: 295 | Loss: 0.003860180964693427\n",
            "Epoch: 296 | Loss: 0.0038046925328671932\n",
            "Epoch: 297 | Loss: 0.0037500294856727123\n",
            "Epoch: 298 | Loss: 0.003696154337376356\n",
            "Epoch: 299 | Loss: 0.0036430375184863806\n",
            "Epoch: 300 | Loss: 0.003590670879930258\n",
            "Epoch: 301 | Loss: 0.003539098659530282\n",
            "Epoch: 302 | Loss: 0.003488212125375867\n",
            "Epoch: 303 | Loss: 0.0034380690194666386\n",
            "Epoch: 304 | Loss: 0.0033886744640767574\n",
            "Epoch: 305 | Loss: 0.003339977003633976\n",
            "Epoch: 306 | Loss: 0.003291965462267399\n",
            "Epoch: 307 | Loss: 0.003244645893573761\n",
            "Epoch: 308 | Loss: 0.0031980108469724655\n",
            "Epoch: 309 | Loss: 0.0031520628836005926\n",
            "Epoch: 310 | Loss: 0.0031067775562405586\n",
            "Epoch: 311 | Loss: 0.003062106668949127\n",
            "Epoch: 312 | Loss: 0.003018100978806615\n",
            "Epoch: 313 | Loss: 0.0029747183434665203\n",
            "Epoch: 314 | Loss: 0.002931983210146427\n",
            "Epoch: 315 | Loss: 0.0028898355085402727\n",
            "Epoch: 316 | Loss: 0.0028483159840106964\n",
            "Epoch: 317 | Loss: 0.0028073706198483706\n",
            "Epoch: 318 | Loss: 0.002767021767795086\n",
            "Epoch: 319 | Loss: 0.002727256156504154\n",
            "Epoch: 320 | Loss: 0.002688055858016014\n",
            "Epoch: 321 | Loss: 0.0026494269259274006\n",
            "Epoch: 322 | Loss: 0.002611338859423995\n",
            "Epoch: 323 | Loss: 0.0025738007389009\n",
            "Epoch: 324 | Loss: 0.0025368332862854004\n",
            "Epoch: 325 | Loss: 0.0025003713089972734\n",
            "Epoch: 326 | Loss: 0.0024644392542541027\n",
            "Epoch: 327 | Loss: 0.0024290019646286964\n",
            "Epoch: 328 | Loss: 0.0023941146209836006\n",
            "Epoch: 329 | Loss: 0.0023596882820129395\n",
            "Epoch: 330 | Loss: 0.0023257918655872345\n",
            "Epoch: 331 | Loss: 0.002292363438755274\n",
            "Epoch: 332 | Loss: 0.0022594230249524117\n",
            "Epoch: 333 | Loss: 0.002226948505267501\n",
            "Epoch: 334 | Loss: 0.0021949377842247486\n",
            "Epoch: 335 | Loss: 0.0021633997093886137\n",
            "Epoch: 336 | Loss: 0.002132307505235076\n",
            "Epoch: 337 | Loss: 0.0021016800310462713\n",
            "Epoch: 338 | Loss: 0.0020714516285806894\n",
            "Epoch: 339 | Loss: 0.002041680971160531\n",
            "Epoch: 340 | Loss: 0.00201233197003603\n",
            "Epoch: 341 | Loss: 0.0019834155682474375\n",
            "Epoch: 342 | Loss: 0.0019549219869077206\n",
            "Epoch: 343 | Loss: 0.0019268256146460772\n",
            "Epoch: 344 | Loss: 0.0018991330871358514\n",
            "Epoch: 345 | Loss: 0.0018718570936471224\n",
            "Epoch: 346 | Loss: 0.0018449409399181604\n",
            "Epoch: 347 | Loss: 0.0018184180371463299\n",
            "Epoch: 348 | Loss: 0.001792296301573515\n",
            "Epoch: 349 | Loss: 0.0017665468621999025\n",
            "Epoch: 350 | Loss: 0.0017411415465176105\n",
            "Epoch: 351 | Loss: 0.0017161249415948987\n",
            "Epoch: 352 | Loss: 0.0016914638690650463\n",
            "Epoch: 353 | Loss: 0.0016671355115249753\n",
            "Epoch: 354 | Loss: 0.0016431908588856459\n",
            "Epoch: 355 | Loss: 0.001619564602151513\n",
            "Epoch: 356 | Loss: 0.0015963091282173991\n",
            "Epoch: 357 | Loss: 0.0015733533073216677\n",
            "Epoch: 358 | Loss: 0.0015507354401051998\n",
            "Epoch: 359 | Loss: 0.0015284722903743386\n",
            "Epoch: 360 | Loss: 0.0015064873732626438\n",
            "Epoch: 361 | Loss: 0.0014848433202132583\n",
            "Epoch: 362 | Loss: 0.0014635048573836684\n",
            "Epoch: 363 | Loss: 0.0014424711698666215\n",
            "Epoch: 364 | Loss: 0.001421754015609622\n",
            "Epoch: 365 | Loss: 0.001401302171871066\n",
            "Epoch: 366 | Loss: 0.00138117338065058\n",
            "Epoch: 367 | Loss: 0.0013613166520372033\n",
            "Epoch: 368 | Loss: 0.0013417679583653808\n",
            "Epoch: 369 | Loss: 0.001322464202530682\n",
            "Epoch: 370 | Loss: 0.0013034765142947435\n",
            "Epoch: 371 | Loss: 0.0012847200268879533\n",
            "Epoch: 372 | Loss: 0.0012662712251767516\n",
            "Epoch: 373 | Loss: 0.0012480770237743855\n",
            "Epoch: 374 | Loss: 0.0012301347451284528\n",
            "Epoch: 375 | Loss: 0.0012124620843678713\n",
            "Epoch: 376 | Loss: 0.0011950219050049782\n",
            "Epoch: 377 | Loss: 0.0011778536718338728\n",
            "Epoch: 378 | Loss: 0.0011609324719756842\n",
            "Epoch: 379 | Loss: 0.001144245732575655\n",
            "Epoch: 380 | Loss: 0.001127799041569233\n",
            "Epoch: 381 | Loss: 0.0011115914676338434\n",
            "Epoch: 382 | Loss: 0.0010956110199913383\n",
            "Epoch: 383 | Loss: 0.0010798608418554068\n",
            "Epoch: 384 | Loss: 0.0010643688729032874\n",
            "Epoch: 385 | Loss: 0.001049058511853218\n",
            "Epoch: 386 | Loss: 0.0010339751606807113\n",
            "Epoch: 387 | Loss: 0.0010191177716478705\n",
            "Epoch: 388 | Loss: 0.0010044840164482594\n",
            "Epoch: 389 | Loss: 0.0009900329168885946\n",
            "Epoch: 390 | Loss: 0.0009758137166500092\n",
            "Epoch: 391 | Loss: 0.0009617875330150127\n",
            "Epoch: 392 | Loss: 0.0009479577420279384\n",
            "Epoch: 393 | Loss: 0.0009343507117591798\n",
            "Epoch: 394 | Loss: 0.0009209162672050297\n",
            "Epoch: 395 | Loss: 0.0009076736168935895\n",
            "Epoch: 396 | Loss: 0.0008946416201069951\n",
            "Epoch: 397 | Loss: 0.0008817868074402213\n",
            "Epoch: 398 | Loss: 0.0008691123803146183\n",
            "Epoch: 399 | Loss: 0.0008566147880628705\n",
            "Epoch: 400 | Loss: 0.0008442989783361554\n",
            "Epoch: 401 | Loss: 0.0008321579662151635\n",
            "Epoch: 402 | Loss: 0.000820206303615123\n",
            "Epoch: 403 | Loss: 0.0008084155851975083\n",
            "Epoch: 404 | Loss: 0.000796795473434031\n",
            "Epoch: 405 | Loss: 0.0007853589486330748\n",
            "Epoch: 406 | Loss: 0.0007740730652585626\n",
            "Epoch: 407 | Loss: 0.0007629314204677939\n",
            "Epoch: 408 | Loss: 0.0007519806968048215\n",
            "Epoch: 409 | Loss: 0.0007411612314172089\n",
            "Epoch: 410 | Loss: 0.0007305207545869052\n",
            "Epoch: 411 | Loss: 0.0007200275431387126\n",
            "Epoch: 412 | Loss: 0.0007096627959981561\n",
            "Epoch: 413 | Loss: 0.0006994777941145003\n",
            "Epoch: 414 | Loss: 0.0006894136895425618\n",
            "Epoch: 415 | Loss: 0.0006795119843445718\n",
            "Epoch: 416 | Loss: 0.0006697525968775153\n",
            "Epoch: 417 | Loss: 0.0006601146305911243\n",
            "Epoch: 418 | Loss: 0.0006506399367935956\n",
            "Epoch: 419 | Loss: 0.0006412838120013475\n",
            "Epoch: 420 | Loss: 0.0006320655811578035\n",
            "Epoch: 421 | Loss: 0.0006229750579223037\n",
            "Epoch: 422 | Loss: 0.0006140397163107991\n",
            "Epoch: 423 | Loss: 0.0006052132230252028\n",
            "Epoch: 424 | Loss: 0.0005965117597952485\n",
            "Epoch: 425 | Loss: 0.0005879352684132755\n",
            "Epoch: 426 | Loss: 0.0005794853204861283\n",
            "Epoch: 427 | Loss: 0.0005711576086468995\n",
            "Epoch: 428 | Loss: 0.000562939909286797\n",
            "Epoch: 429 | Loss: 0.0005548584158532321\n",
            "Epoch: 430 | Loss: 0.0005468842573463917\n",
            "Epoch: 431 | Loss: 0.000539017841219902\n",
            "Epoch: 432 | Loss: 0.0005312754074111581\n",
            "Epoch: 433 | Loss: 0.0005236448487266898\n",
            "Epoch: 434 | Loss: 0.0005161130684427917\n",
            "Epoch: 435 | Loss: 0.0005086974706500769\n",
            "Epoch: 436 | Loss: 0.0005013954360038042\n",
            "Epoch: 437 | Loss: 0.0004941733786836267\n",
            "Epoch: 438 | Loss: 0.0004870793782174587\n",
            "Epoch: 439 | Loss: 0.00048008636804297566\n",
            "Epoch: 440 | Loss: 0.0004731793305836618\n",
            "Epoch: 441 | Loss: 0.0004663801228161901\n",
            "Epoch: 442 | Loss: 0.0004596762009896338\n",
            "Epoch: 443 | Loss: 0.00045306907850317657\n",
            "Epoch: 444 | Loss: 0.00044656265527009964\n",
            "Epoch: 445 | Loss: 0.0004401386540848762\n",
            "Epoch: 446 | Loss: 0.0004338181170169264\n",
            "Epoch: 447 | Loss: 0.00042757694609463215\n",
            "Epoch: 448 | Loss: 0.0004214370856061578\n",
            "Epoch: 449 | Loss: 0.00041537481592968106\n",
            "Epoch: 450 | Loss: 0.0004094117903150618\n",
            "Epoch: 451 | Loss: 0.00040352571522817016\n",
            "Epoch: 452 | Loss: 0.0003977240121457726\n",
            "Epoch: 453 | Loss: 0.00039200924220494926\n",
            "Epoch: 454 | Loss: 0.00038637692341580987\n",
            "Epoch: 455 | Loss: 0.0003808183246292174\n",
            "Epoch: 456 | Loss: 0.0003753438941203058\n",
            "Epoch: 457 | Loss: 0.00036996163544245064\n",
            "Epoch: 458 | Loss: 0.00036463828291743994\n",
            "Epoch: 459 | Loss: 0.0003593909787014127\n",
            "Epoch: 460 | Loss: 0.00035423639928922057\n",
            "Epoch: 461 | Loss: 0.0003491429379209876\n",
            "Epoch: 462 | Loss: 0.0003441188018769026\n",
            "Epoch: 463 | Loss: 0.00033918130793608725\n",
            "Epoch: 464 | Loss: 0.00033430717303417623\n",
            "Epoch: 465 | Loss: 0.0003295041969977319\n",
            "Epoch: 466 | Loss: 0.000324771594023332\n",
            "Epoch: 467 | Loss: 0.0003200898936484009\n",
            "Epoch: 468 | Loss: 0.00031549794948659837\n",
            "Epoch: 469 | Loss: 0.0003109699464403093\n",
            "Epoch: 470 | Loss: 0.00030649296240881085\n",
            "Epoch: 471 | Loss: 0.00030209089163690805\n",
            "Epoch: 472 | Loss: 0.00029774976428598166\n",
            "Epoch: 473 | Loss: 0.0002934689400717616\n",
            "Epoch: 474 | Loss: 0.0002892497868742794\n",
            "Epoch: 475 | Loss: 0.000285102374618873\n",
            "Epoch: 476 | Loss: 0.000281003478448838\n",
            "Epoch: 477 | Loss: 0.0002769594138953835\n",
            "Epoch: 478 | Loss: 0.0002729830448515713\n",
            "Epoch: 479 | Loss: 0.00026905740378424525\n",
            "Epoch: 480 | Loss: 0.0002651933173183352\n",
            "Epoch: 481 | Loss: 0.00026137882377952337\n",
            "Epoch: 482 | Loss: 0.0002576199476607144\n",
            "Epoch: 483 | Loss: 0.00025392440147697926\n",
            "Epoch: 484 | Loss: 0.0002502684947103262\n",
            "Epoch: 485 | Loss: 0.00024667923571541905\n",
            "Epoch: 486 | Loss: 0.00024312858295161277\n",
            "Epoch: 487 | Loss: 0.00023963248531799763\n",
            "Epoch: 488 | Loss: 0.00023619388230144978\n",
            "Epoch: 489 | Loss: 0.00023280229652300477\n",
            "Epoch: 490 | Loss: 0.0002294511068612337\n",
            "Epoch: 491 | Loss: 0.00022615306079387665\n",
            "Epoch: 492 | Loss: 0.00022290318156592548\n",
            "Epoch: 493 | Loss: 0.00021969839872326702\n",
            "Epoch: 494 | Loss: 0.00021654076408594847\n",
            "Epoch: 495 | Loss: 0.00021343230037018657\n",
            "Epoch: 496 | Loss: 0.00021036573161836714\n",
            "Epoch: 497 | Loss: 0.00020733893325086683\n",
            "Epoch: 498 | Loss: 0.00020435899205040187\n",
            "Epoch: 499 | Loss: 0.00020142043649684638\n",
            "Prediction (after training 4 7.98368501663208\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-r6govn3eu8F",
        "outputId": "af951169-4a19-47da-d25e-3b7716c98851"
      },
      "source": [
        "from torch import tensor\n",
        "from torch import nn\n",
        "from torch import sigmoid\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "\n",
        "\n",
        "x_data=tensor([[1.0],[2.0],[3.0], [4.0]])\n",
        "y_data=tensor([[0.0],[0.0],[1.0], [1.0]])\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Model, self).__init__()\n",
        "    self.linear = torch.nn.Linear(1, 1)\n",
        "  def forward(self, x):\n",
        "    y_pred=sigmoid(self.linear(x))\n",
        "    return y_pred\n",
        "model=Model()\n",
        "\n",
        "criterion=nn.BCELoss(reduction='mean')\n",
        "optimizer=optim.SGD(model.parameters(), lr=0.01)\n",
        "for epoch in range(1000):\n",
        "  y_pred=model(x_data)\n",
        "  loss = criterion(y_pred,y_data)\n",
        "  print(f'Epoch: {epoch+1} | Loss: {loss.item()}')\n",
        "\n",
        "  optimizer.zero_grad()\n",
        "  loss.backward()\n",
        "  optimizer.step() # w=w-0.01*w.grad().item()\n",
        "#After training\n",
        "hour_var=model(tensor([1.0]))\n",
        "print(f'Prediction after 1 hour of training: {hour_var.item():.4f} | Above 50%: {hour_var.item() >0.5}')\n",
        "hour_var=model(tensor([7.0]))\n",
        "print(f'Prediction after 7 hour of training: {hour_var.item():.4f} | Above 50%: {hour_var.item() >0.5}')\n",
        "hour_var=model(tensor([20.0]))\n",
        "print(f'Prediction after 20 hour of training: {hour_var.item():.4f} | Above 50%: {hour_var.item() >0.5}')\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch: 1 | Loss: 0.7001646757125854\n",
            "Epoch: 2 | Loss: 0.6983529925346375\n",
            "Epoch: 3 | Loss: 0.6966046094894409\n",
            "Epoch: 4 | Loss: 0.6949169635772705\n",
            "Epoch: 5 | Loss: 0.6932874917984009\n",
            "Epoch: 6 | Loss: 0.691713809967041\n",
            "Epoch: 7 | Loss: 0.6901935935020447\n",
            "Epoch: 8 | Loss: 0.6887243986129761\n",
            "Epoch: 9 | Loss: 0.6873043775558472\n",
            "Epoch: 10 | Loss: 0.6859310865402222\n",
            "Epoch: 11 | Loss: 0.6846029758453369\n",
            "Epoch: 12 | Loss: 0.6833178997039795\n",
            "Epoch: 13 | Loss: 0.6820740103721619\n",
            "Epoch: 14 | Loss: 0.6808698773384094\n",
            "Epoch: 15 | Loss: 0.6797034740447998\n",
            "Epoch: 16 | Loss: 0.6785736083984375\n",
            "Epoch: 17 | Loss: 0.6774783730506897\n",
            "Epoch: 18 | Loss: 0.6764166355133057\n",
            "Epoch: 19 | Loss: 0.6753867268562317\n",
            "Epoch: 20 | Loss: 0.6743873953819275\n",
            "Epoch: 21 | Loss: 0.6734175682067871\n",
            "Epoch: 22 | Loss: 0.6724758744239807\n",
            "Epoch: 23 | Loss: 0.671561062335968\n",
            "Epoch: 24 | Loss: 0.6706721186637878\n",
            "Epoch: 25 | Loss: 0.669808030128479\n",
            "Epoch: 26 | Loss: 0.6689676642417908\n",
            "Epoch: 27 | Loss: 0.6681500673294067\n",
            "Epoch: 28 | Loss: 0.6673543453216553\n",
            "Epoch: 29 | Loss: 0.66657954454422\n",
            "Epoch: 30 | Loss: 0.6658248901367188\n",
            "Epoch: 31 | Loss: 0.6650894284248352\n",
            "Epoch: 32 | Loss: 0.6643725037574768\n",
            "Epoch: 33 | Loss: 0.6636732816696167\n",
            "Epoch: 34 | Loss: 0.6629911065101624\n",
            "Epoch: 35 | Loss: 0.6623252034187317\n",
            "Epoch: 36 | Loss: 0.6616749167442322\n",
            "Epoch: 37 | Loss: 0.6610397100448608\n",
            "Epoch: 38 | Loss: 0.6604189276695251\n",
            "Epoch: 39 | Loss: 0.6598120927810669\n",
            "Epoch: 40 | Loss: 0.659218430519104\n",
            "Epoch: 41 | Loss: 0.6586374044418335\n",
            "Epoch: 42 | Loss: 0.6580687165260315\n",
            "Epoch: 43 | Loss: 0.6575118899345398\n",
            "Epoch: 44 | Loss: 0.6569662690162659\n",
            "Epoch: 45 | Loss: 0.6564314365386963\n",
            "Epoch: 46 | Loss: 0.6559069752693176\n",
            "Epoch: 47 | Loss: 0.6553927063941956\n",
            "Epoch: 48 | Loss: 0.6548879146575928\n",
            "Epoch: 49 | Loss: 0.6543923020362854\n",
            "Epoch: 50 | Loss: 0.6539056897163391\n",
            "Epoch: 51 | Loss: 0.6534274816513062\n",
            "Epoch: 52 | Loss: 0.652957558631897\n",
            "Epoch: 53 | Loss: 0.6524954438209534\n",
            "Epoch: 54 | Loss: 0.6520407795906067\n",
            "Epoch: 55 | Loss: 0.6515935659408569\n",
            "Epoch: 56 | Loss: 0.6511533260345459\n",
            "Epoch: 57 | Loss: 0.6507197022438049\n",
            "Epoch: 58 | Loss: 0.6502925753593445\n",
            "Epoch: 59 | Loss: 0.6498716473579407\n",
            "Epoch: 60 | Loss: 0.6494567394256592\n",
            "Epoch: 61 | Loss: 0.6490476131439209\n",
            "Epoch: 62 | Loss: 0.648643970489502\n",
            "Epoch: 63 | Loss: 0.6482455730438232\n",
            "Epoch: 64 | Loss: 0.6478524208068848\n",
            "Epoch: 65 | Loss: 0.6474641561508179\n",
            "Epoch: 66 | Loss: 0.6470806002616882\n",
            "Epoch: 67 | Loss: 0.6467016339302063\n",
            "Epoch: 68 | Loss: 0.646327018737793\n",
            "Epoch: 69 | Loss: 0.6459567546844482\n",
            "Epoch: 70 | Loss: 0.6455904245376587\n",
            "Epoch: 71 | Loss: 0.6452280879020691\n",
            "Epoch: 72 | Loss: 0.6448695063591003\n",
            "Epoch: 73 | Loss: 0.6445145606994629\n",
            "Epoch: 74 | Loss: 0.6441631317138672\n",
            "Epoch: 75 | Loss: 0.6438151597976685\n",
            "Epoch: 76 | Loss: 0.6434704065322876\n",
            "Epoch: 77 | Loss: 0.6431287527084351\n",
            "Epoch: 78 | Loss: 0.6427900791168213\n",
            "Epoch: 79 | Loss: 0.6424543261528015\n",
            "Epoch: 80 | Loss: 0.642121434211731\n",
            "Epoch: 81 | Loss: 0.6417912244796753\n",
            "Epoch: 82 | Loss: 0.6414636373519897\n",
            "Epoch: 83 | Loss: 0.6411386132240295\n",
            "Epoch: 84 | Loss: 0.6408160328865051\n",
            "Epoch: 85 | Loss: 0.6404956579208374\n",
            "Epoch: 86 | Loss: 0.6401776671409607\n",
            "Epoch: 87 | Loss: 0.6398618817329407\n",
            "Epoch: 88 | Loss: 0.6395480632781982\n",
            "Epoch: 89 | Loss: 0.6392365097999573\n",
            "Epoch: 90 | Loss: 0.6389267444610596\n",
            "Epoch: 91 | Loss: 0.6386189460754395\n",
            "Epoch: 92 | Loss: 0.6383129954338074\n",
            "Epoch: 93 | Loss: 0.638008713722229\n",
            "Epoch: 94 | Loss: 0.6377061605453491\n",
            "Epoch: 95 | Loss: 0.6374053955078125\n",
            "Epoch: 96 | Loss: 0.63710618019104\n",
            "Epoch: 97 | Loss: 0.6368083953857422\n",
            "Epoch: 98 | Loss: 0.6365121603012085\n",
            "Epoch: 99 | Loss: 0.6362174153327942\n",
            "Epoch: 100 | Loss: 0.6359241008758545\n",
            "Epoch: 101 | Loss: 0.6356320977210999\n",
            "Epoch: 102 | Loss: 0.6353413462638855\n",
            "Epoch: 103 | Loss: 0.6350519061088562\n",
            "Epoch: 104 | Loss: 0.6347637176513672\n",
            "Epoch: 105 | Loss: 0.6344766616821289\n",
            "Epoch: 106 | Loss: 0.6341908574104309\n",
            "Epoch: 107 | Loss: 0.6339061856269836\n",
            "Epoch: 108 | Loss: 0.6336223483085632\n",
            "Epoch: 109 | Loss: 0.6333397626876831\n",
            "Epoch: 110 | Loss: 0.6330581307411194\n",
            "Epoch: 111 | Loss: 0.6327775120735168\n",
            "Epoch: 112 | Loss: 0.6324978470802307\n",
            "Epoch: 113 | Loss: 0.6322190165519714\n",
            "Epoch: 114 | Loss: 0.6319411396980286\n",
            "Epoch: 115 | Loss: 0.6316641569137573\n",
            "Epoch: 116 | Loss: 0.6313880681991577\n",
            "Epoch: 117 | Loss: 0.6311126947402954\n",
            "Epoch: 118 | Loss: 0.63083815574646\n",
            "Epoch: 119 | Loss: 0.6305643916130066\n",
            "Epoch: 120 | Loss: 0.6302914023399353\n",
            "Epoch: 121 | Loss: 0.6300191283226013\n",
            "Epoch: 122 | Loss: 0.6297476291656494\n",
            "Epoch: 123 | Loss: 0.6294767260551453\n",
            "Epoch: 124 | Loss: 0.6292064785957336\n",
            "Epoch: 125 | Loss: 0.6289368867874146\n",
            "Epoch: 126 | Loss: 0.6286680102348328\n",
            "Epoch: 127 | Loss: 0.6283997297286987\n",
            "Epoch: 128 | Loss: 0.6281320452690125\n",
            "Epoch: 129 | Loss: 0.6278648972511292\n",
            "Epoch: 130 | Loss: 0.6275984048843384\n",
            "Epoch: 131 | Loss: 0.6273323893547058\n",
            "Epoch: 132 | Loss: 0.6270670294761658\n",
            "Epoch: 133 | Loss: 0.6268021464347839\n",
            "Epoch: 134 | Loss: 0.6265377998352051\n",
            "Epoch: 135 | Loss: 0.6262738108634949\n",
            "Epoch: 136 | Loss: 0.6260104179382324\n",
            "Epoch: 137 | Loss: 0.625747561454773\n",
            "Epoch: 138 | Loss: 0.6254851222038269\n",
            "Epoch: 139 | Loss: 0.6252231597900391\n",
            "Epoch: 140 | Loss: 0.6249615550041199\n",
            "Epoch: 141 | Loss: 0.6247005462646484\n",
            "Epoch: 142 | Loss: 0.6244398951530457\n",
            "Epoch: 143 | Loss: 0.6241797208786011\n",
            "Epoch: 144 | Loss: 0.6239198446273804\n",
            "Epoch: 145 | Loss: 0.6236604452133179\n",
            "Epoch: 146 | Loss: 0.623401403427124\n",
            "Epoch: 147 | Loss: 0.6231427788734436\n",
            "Epoch: 148 | Loss: 0.6228845119476318\n",
            "Epoch: 149 | Loss: 0.6226266622543335\n",
            "Epoch: 150 | Loss: 0.6223691701889038\n",
            "Epoch: 151 | Loss: 0.6221119165420532\n",
            "Epoch: 152 | Loss: 0.6218551397323608\n",
            "Epoch: 153 | Loss: 0.6215986609458923\n",
            "Epoch: 154 | Loss: 0.6213425993919373\n",
            "Epoch: 155 | Loss: 0.6210867166519165\n",
            "Epoch: 156 | Loss: 0.6208313703536987\n",
            "Epoch: 157 | Loss: 0.6205762028694153\n",
            "Epoch: 158 | Loss: 0.6203213334083557\n",
            "Epoch: 159 | Loss: 0.6200668215751648\n",
            "Epoch: 160 | Loss: 0.6198126077651978\n",
            "Epoch: 161 | Loss: 0.6195586919784546\n",
            "Epoch: 162 | Loss: 0.6193050146102905\n",
            "Epoch: 163 | Loss: 0.6190517544746399\n",
            "Epoch: 164 | Loss: 0.6187987327575684\n",
            "Epoch: 165 | Loss: 0.6185458898544312\n",
            "Epoch: 166 | Loss: 0.6182934641838074\n",
            "Epoch: 167 | Loss: 0.6180412769317627\n",
            "Epoch: 168 | Loss: 0.6177893877029419\n",
            "Epoch: 169 | Loss: 0.6175377368927002\n",
            "Epoch: 170 | Loss: 0.6172863245010376\n",
            "Epoch: 171 | Loss: 0.6170351505279541\n",
            "Epoch: 172 | Loss: 0.6167842745780945\n",
            "Epoch: 173 | Loss: 0.6165336966514587\n",
            "Epoch: 174 | Loss: 0.6162833571434021\n",
            "Epoch: 175 | Loss: 0.6160332560539246\n",
            "Epoch: 176 | Loss: 0.6157833337783813\n",
            "Epoch: 177 | Loss: 0.615533709526062\n",
            "Epoch: 178 | Loss: 0.615284264087677\n",
            "Epoch: 179 | Loss: 0.6150351762771606\n",
            "Epoch: 180 | Loss: 0.6147862672805786\n",
            "Epoch: 181 | Loss: 0.6145375967025757\n",
            "Epoch: 182 | Loss: 0.6142891645431519\n",
            "Epoch: 183 | Loss: 0.6140409111976624\n",
            "Epoch: 184 | Loss: 0.6137929558753967\n",
            "Epoch: 185 | Loss: 0.6135451197624207\n",
            "Epoch: 186 | Loss: 0.6132976412773132\n",
            "Epoch: 187 | Loss: 0.6130502820014954\n",
            "Epoch: 188 | Loss: 0.6128032207489014\n",
            "Epoch: 189 | Loss: 0.6125563383102417\n",
            "Epoch: 190 | Loss: 0.6123096346855164\n",
            "Epoch: 191 | Loss: 0.6120631694793701\n",
            "Epoch: 192 | Loss: 0.6118168830871582\n",
            "Epoch: 193 | Loss: 0.6115708351135254\n",
            "Epoch: 194 | Loss: 0.6113250255584717\n",
            "Epoch: 195 | Loss: 0.6110793948173523\n",
            "Epoch: 196 | Loss: 0.610834002494812\n",
            "Epoch: 197 | Loss: 0.610588788986206\n",
            "Epoch: 198 | Loss: 0.6103438138961792\n",
            "Epoch: 199 | Loss: 0.6100990176200867\n",
            "Epoch: 200 | Loss: 0.6098544001579285\n",
            "Epoch: 201 | Loss: 0.6096100211143494\n",
            "Epoch: 202 | Loss: 0.6093658208847046\n",
            "Epoch: 203 | Loss: 0.6091217994689941\n",
            "Epoch: 204 | Loss: 0.608877956867218\n",
            "Epoch: 205 | Loss: 0.6086344122886658\n",
            "Epoch: 206 | Loss: 0.6083909869194031\n",
            "Epoch: 207 | Loss: 0.6081477999687195\n",
            "Epoch: 208 | Loss: 0.6079046726226807\n",
            "Epoch: 209 | Loss: 0.6076619029045105\n",
            "Epoch: 210 | Loss: 0.6074192523956299\n",
            "Epoch: 211 | Loss: 0.6071768403053284\n",
            "Epoch: 212 | Loss: 0.6069346070289612\n",
            "Epoch: 213 | Loss: 0.606692373752594\n",
            "Epoch: 214 | Loss: 0.6064505577087402\n",
            "Epoch: 215 | Loss: 0.6062088012695312\n",
            "Epoch: 216 | Loss: 0.6059672832489014\n",
            "Epoch: 217 | Loss: 0.6057260036468506\n",
            "Epoch: 218 | Loss: 0.6054848432540894\n",
            "Epoch: 219 | Loss: 0.6052439212799072\n",
            "Epoch: 220 | Loss: 0.6050030589103699\n",
            "Epoch: 221 | Loss: 0.6047624945640564\n",
            "Epoch: 222 | Loss: 0.6045221090316772\n",
            "Epoch: 223 | Loss: 0.6042818427085876\n",
            "Epoch: 224 | Loss: 0.6040417551994324\n",
            "Epoch: 225 | Loss: 0.6038019061088562\n",
            "Epoch: 226 | Loss: 0.6035622358322144\n",
            "Epoch: 227 | Loss: 0.6033226251602173\n",
            "Epoch: 228 | Loss: 0.6030833721160889\n",
            "Epoch: 229 | Loss: 0.6028441786766052\n",
            "Epoch: 230 | Loss: 0.6026052236557007\n",
            "Epoch: 231 | Loss: 0.6023663878440857\n",
            "Epoch: 232 | Loss: 0.6021277904510498\n",
            "Epoch: 233 | Loss: 0.6018893122673035\n",
            "Epoch: 234 | Loss: 0.6016510725021362\n",
            "Epoch: 235 | Loss: 0.6014129519462585\n",
            "Epoch: 236 | Loss: 0.6011749505996704\n",
            "Epoch: 237 | Loss: 0.6009372472763062\n",
            "Epoch: 238 | Loss: 0.6006996631622314\n",
            "Epoch: 239 | Loss: 0.6004623174667358\n",
            "Epoch: 240 | Loss: 0.600225031375885\n",
            "Epoch: 241 | Loss: 0.5999879837036133\n",
            "Epoch: 242 | Loss: 0.5997510552406311\n",
            "Epoch: 243 | Loss: 0.5995144248008728\n",
            "Epoch: 244 | Loss: 0.5992777943611145\n",
            "Epoch: 245 | Loss: 0.5990414619445801\n",
            "Epoch: 246 | Loss: 0.5988051295280457\n",
            "Epoch: 247 | Loss: 0.5985692143440247\n",
            "Epoch: 248 | Loss: 0.5983333587646484\n",
            "Epoch: 249 | Loss: 0.5980976223945618\n",
            "Epoch: 250 | Loss: 0.5978620648384094\n",
            "Epoch: 251 | Loss: 0.5976267457008362\n",
            "Epoch: 252 | Loss: 0.5973915457725525\n",
            "Epoch: 253 | Loss: 0.5971565842628479\n",
            "Epoch: 254 | Loss: 0.5969217419624329\n",
            "Epoch: 255 | Loss: 0.5966870784759521\n",
            "Epoch: 256 | Loss: 0.5964525938034058\n",
            "Epoch: 257 | Loss: 0.5962182283401489\n",
            "Epoch: 258 | Loss: 0.5959839820861816\n",
            "Epoch: 259 | Loss: 0.595750093460083\n",
            "Epoch: 260 | Loss: 0.5955161452293396\n",
            "Epoch: 261 | Loss: 0.5952825546264648\n",
            "Epoch: 262 | Loss: 0.5950490236282349\n",
            "Epoch: 263 | Loss: 0.5948156118392944\n",
            "Epoch: 264 | Loss: 0.5945825576782227\n",
            "Epoch: 265 | Loss: 0.5943495631217957\n",
            "Epoch: 266 | Loss: 0.5941166281700134\n",
            "Epoch: 267 | Loss: 0.5938840508460999\n",
            "Epoch: 268 | Loss: 0.593651533126831\n",
            "Epoch: 269 | Loss: 0.593419075012207\n",
            "Epoch: 270 | Loss: 0.5931869745254517\n",
            "Epoch: 271 | Loss: 0.5929549932479858\n",
            "Epoch: 272 | Loss: 0.5927231311798096\n",
            "Epoch: 273 | Loss: 0.5924913883209229\n",
            "Epoch: 274 | Loss: 0.5922600030899048\n",
            "Epoch: 275 | Loss: 0.5920285582542419\n",
            "Epoch: 276 | Loss: 0.5917973518371582\n",
            "Epoch: 277 | Loss: 0.5915663242340088\n",
            "Epoch: 278 | Loss: 0.5913355946540833\n",
            "Epoch: 279 | Loss: 0.5911047458648682\n",
            "Epoch: 280 | Loss: 0.5908743143081665\n",
            "Epoch: 281 | Loss: 0.5906438827514648\n",
            "Epoch: 282 | Loss: 0.5904136896133423\n",
            "Epoch: 283 | Loss: 0.5901836156845093\n",
            "Epoch: 284 | Loss: 0.5899537205696106\n",
            "Epoch: 285 | Loss: 0.5897240042686462\n",
            "Epoch: 286 | Loss: 0.5894944071769714\n",
            "Epoch: 287 | Loss: 0.5892651081085205\n",
            "Epoch: 288 | Loss: 0.5890358686447144\n",
            "Epoch: 289 | Loss: 0.5888067483901978\n",
            "Epoch: 290 | Loss: 0.5885778069496155\n",
            "Epoch: 291 | Loss: 0.5883490443229675\n",
            "Epoch: 292 | Loss: 0.5881205201148987\n",
            "Epoch: 293 | Loss: 0.5878920555114746\n",
            "Epoch: 294 | Loss: 0.5876637697219849\n",
            "Epoch: 295 | Loss: 0.5874356627464294\n",
            "Epoch: 296 | Loss: 0.5872077345848083\n",
            "Epoch: 297 | Loss: 0.586979866027832\n",
            "Epoch: 298 | Loss: 0.5867523550987244\n",
            "Epoch: 299 | Loss: 0.5865248441696167\n",
            "Epoch: 300 | Loss: 0.5862975120544434\n",
            "Epoch: 301 | Loss: 0.5860704183578491\n",
            "Epoch: 302 | Loss: 0.5858433842658997\n",
            "Epoch: 303 | Loss: 0.5856165885925293\n",
            "Epoch: 304 | Loss: 0.5853898525238037\n",
            "Epoch: 305 | Loss: 0.585163414478302\n",
            "Epoch: 306 | Loss: 0.5849370360374451\n",
            "Epoch: 307 | Loss: 0.5847108364105225\n",
            "Epoch: 308 | Loss: 0.5844848155975342\n",
            "Epoch: 309 | Loss: 0.5842589139938354\n",
            "Epoch: 310 | Loss: 0.584033191204071\n",
            "Epoch: 311 | Loss: 0.583807647228241\n",
            "Epoch: 312 | Loss: 0.5835822820663452\n",
            "Epoch: 313 | Loss: 0.583357036113739\n",
            "Epoch: 314 | Loss: 0.5831319093704224\n",
            "Epoch: 315 | Loss: 0.58290696144104\n",
            "Epoch: 316 | Loss: 0.582682192325592\n",
            "Epoch: 317 | Loss: 0.5824576020240784\n",
            "Epoch: 318 | Loss: 0.582233190536499\n",
            "Epoch: 319 | Loss: 0.5820088386535645\n",
            "Epoch: 320 | Loss: 0.581784725189209\n",
            "Epoch: 321 | Loss: 0.5815607309341431\n",
            "Epoch: 322 | Loss: 0.5813369154930115\n",
            "Epoch: 323 | Loss: 0.5811132192611694\n",
            "Epoch: 324 | Loss: 0.5808897018432617\n",
            "Epoch: 325 | Loss: 0.5806664228439331\n",
            "Epoch: 326 | Loss: 0.580443263053894\n",
            "Epoch: 327 | Loss: 0.580220103263855\n",
            "Epoch: 328 | Loss: 0.5799972414970398\n",
            "Epoch: 329 | Loss: 0.5797745585441589\n",
            "Epoch: 330 | Loss: 0.5795519351959229\n",
            "Epoch: 331 | Loss: 0.5793294906616211\n",
            "Epoch: 332 | Loss: 0.5791072845458984\n",
            "Epoch: 333 | Loss: 0.5788851976394653\n",
            "Epoch: 334 | Loss: 0.578663170337677\n",
            "Epoch: 335 | Loss: 0.5784413814544678\n",
            "Epoch: 336 | Loss: 0.5782197713851929\n",
            "Epoch: 337 | Loss: 0.5779983997344971\n",
            "Epoch: 338 | Loss: 0.5777770280838013\n",
            "Epoch: 339 | Loss: 0.5775558352470398\n",
            "Epoch: 340 | Loss: 0.5773347616195679\n",
            "Epoch: 341 | Loss: 0.577113926410675\n",
            "Epoch: 342 | Loss: 0.576893150806427\n",
            "Epoch: 343 | Loss: 0.5766726732254028\n",
            "Epoch: 344 | Loss: 0.5764522552490234\n",
            "Epoch: 345 | Loss: 0.5762320160865784\n",
            "Epoch: 346 | Loss: 0.5760119557380676\n",
            "Epoch: 347 | Loss: 0.5757919549942017\n",
            "Epoch: 348 | Loss: 0.5755721926689148\n",
            "Epoch: 349 | Loss: 0.5753525495529175\n",
            "Epoch: 350 | Loss: 0.5751330852508545\n",
            "Epoch: 351 | Loss: 0.5749136805534363\n",
            "Epoch: 352 | Loss: 0.5746946334838867\n",
            "Epoch: 353 | Loss: 0.5744755864143372\n",
            "Epoch: 354 | Loss: 0.5742566585540771\n",
            "Epoch: 355 | Loss: 0.5740380883216858\n",
            "Epoch: 356 | Loss: 0.5738193988800049\n",
            "Epoch: 357 | Loss: 0.5736010670661926\n",
            "Epoch: 358 | Loss: 0.5733828544616699\n",
            "Epoch: 359 | Loss: 0.5731647610664368\n",
            "Epoch: 360 | Loss: 0.5729467272758484\n",
            "Epoch: 361 | Loss: 0.5727289319038391\n",
            "Epoch: 362 | Loss: 0.5725113749504089\n",
            "Epoch: 363 | Loss: 0.5722938179969788\n",
            "Epoch: 364 | Loss: 0.5720764398574829\n",
            "Epoch: 365 | Loss: 0.5718592405319214\n",
            "Epoch: 366 | Loss: 0.5716422200202942\n",
            "Epoch: 367 | Loss: 0.5714253783226013\n",
            "Epoch: 368 | Loss: 0.571208655834198\n",
            "Epoch: 369 | Loss: 0.5709919929504395\n",
            "Epoch: 370 | Loss: 0.5707756280899048\n",
            "Epoch: 371 | Loss: 0.5705593824386597\n",
            "Epoch: 372 | Loss: 0.5703431963920593\n",
            "Epoch: 373 | Loss: 0.5701272487640381\n",
            "Epoch: 374 | Loss: 0.5699114203453064\n",
            "Epoch: 375 | Loss: 0.569695770740509\n",
            "Epoch: 376 | Loss: 0.5694802403450012\n",
            "Epoch: 377 | Loss: 0.569264829158783\n",
            "Epoch: 378 | Loss: 0.569049596786499\n",
            "Epoch: 379 | Loss: 0.5688345432281494\n",
            "Epoch: 380 | Loss: 0.5686197280883789\n",
            "Epoch: 381 | Loss: 0.5684049129486084\n",
            "Epoch: 382 | Loss: 0.5681902766227722\n",
            "Epoch: 383 | Loss: 0.5679757595062256\n",
            "Epoch: 384 | Loss: 0.5677614808082581\n",
            "Epoch: 385 | Loss: 0.5675472617149353\n",
            "Epoch: 386 | Loss: 0.5673332214355469\n",
            "Epoch: 387 | Loss: 0.5671193599700928\n",
            "Epoch: 388 | Loss: 0.5669056177139282\n",
            "Epoch: 389 | Loss: 0.5666921138763428\n",
            "Epoch: 390 | Loss: 0.5664786696434021\n",
            "Epoch: 391 | Loss: 0.5662654042243958\n",
            "Epoch: 392 | Loss: 0.5660521984100342\n",
            "Epoch: 393 | Loss: 0.5658392906188965\n",
            "Epoch: 394 | Loss: 0.5656264424324036\n",
            "Epoch: 395 | Loss: 0.565413773059845\n",
            "Epoch: 396 | Loss: 0.5652012228965759\n",
            "Epoch: 397 | Loss: 0.5649887919425964\n",
            "Epoch: 398 | Loss: 0.564776599407196\n",
            "Epoch: 399 | Loss: 0.5645645260810852\n",
            "Epoch: 400 | Loss: 0.5643525123596191\n",
            "Epoch: 401 | Loss: 0.564140796661377\n",
            "Epoch: 402 | Loss: 0.5639291405677795\n",
            "Epoch: 403 | Loss: 0.5637176036834717\n",
            "Epoch: 404 | Loss: 0.5635062456130981\n",
            "Epoch: 405 | Loss: 0.5632950663566589\n",
            "Epoch: 406 | Loss: 0.5630840063095093\n",
            "Epoch: 407 | Loss: 0.5628730654716492\n",
            "Epoch: 408 | Loss: 0.5626623034477234\n",
            "Epoch: 409 | Loss: 0.5624517202377319\n",
            "Epoch: 410 | Loss: 0.56224125623703\n",
            "Epoch: 411 | Loss: 0.5620309114456177\n",
            "Epoch: 412 | Loss: 0.5618207454681396\n",
            "Epoch: 413 | Loss: 0.561610758304596\n",
            "Epoch: 414 | Loss: 0.5614008903503418\n",
            "Epoch: 415 | Loss: 0.5611910820007324\n",
            "Epoch: 416 | Loss: 0.5609815120697021\n",
            "Epoch: 417 | Loss: 0.5607720613479614\n",
            "Epoch: 418 | Loss: 0.560562789440155\n",
            "Epoch: 419 | Loss: 0.5603536367416382\n",
            "Epoch: 420 | Loss: 0.5601446032524109\n",
            "Epoch: 421 | Loss: 0.5599356889724731\n",
            "Epoch: 422 | Loss: 0.5597270131111145\n",
            "Epoch: 423 | Loss: 0.5595184564590454\n",
            "Epoch: 424 | Loss: 0.5593100786209106\n",
            "Epoch: 425 | Loss: 0.5591017007827759\n",
            "Epoch: 426 | Loss: 0.5588935613632202\n",
            "Epoch: 427 | Loss: 0.5586856007575989\n",
            "Epoch: 428 | Loss: 0.5584778785705566\n",
            "Epoch: 429 | Loss: 0.5582700967788696\n",
            "Epoch: 430 | Loss: 0.5580625534057617\n",
            "Epoch: 431 | Loss: 0.5578550696372986\n",
            "Epoch: 432 | Loss: 0.5576478242874146\n",
            "Epoch: 433 | Loss: 0.5574406981468201\n",
            "Epoch: 434 | Loss: 0.5572337508201599\n",
            "Epoch: 435 | Loss: 0.5570269227027893\n",
            "Epoch: 436 | Loss: 0.5568202137947083\n",
            "Epoch: 437 | Loss: 0.5566136837005615\n",
            "Epoch: 438 | Loss: 0.5564072728157043\n",
            "Epoch: 439 | Loss: 0.5562009811401367\n",
            "Epoch: 440 | Loss: 0.5559949278831482\n",
            "Epoch: 441 | Loss: 0.5557889938354492\n",
            "Epoch: 442 | Loss: 0.555583119392395\n",
            "Epoch: 443 | Loss: 0.5553774237632751\n",
            "Epoch: 444 | Loss: 0.5551718473434448\n",
            "Epoch: 445 | Loss: 0.5549664497375488\n",
            "Epoch: 446 | Loss: 0.5547612309455872\n",
            "Epoch: 447 | Loss: 0.5545560717582703\n",
            "Epoch: 448 | Loss: 0.5543510913848877\n",
            "Epoch: 449 | Loss: 0.5541463494300842\n",
            "Epoch: 450 | Loss: 0.5539416074752808\n",
            "Epoch: 451 | Loss: 0.5537371039390564\n",
            "Epoch: 452 | Loss: 0.5535327196121216\n",
            "Epoch: 453 | Loss: 0.5533283948898315\n",
            "Epoch: 454 | Loss: 0.5531243085861206\n",
            "Epoch: 455 | Loss: 0.5529203414916992\n",
            "Epoch: 456 | Loss: 0.5527164936065674\n",
            "Epoch: 457 | Loss: 0.5525127649307251\n",
            "Epoch: 458 | Loss: 0.5523092150688171\n",
            "Epoch: 459 | Loss: 0.5521059036254883\n",
            "Epoch: 460 | Loss: 0.5519025325775146\n",
            "Epoch: 461 | Loss: 0.5516994595527649\n",
            "Epoch: 462 | Loss: 0.5514964461326599\n",
            "Epoch: 463 | Loss: 0.5512936115264893\n",
            "Epoch: 464 | Loss: 0.5510909557342529\n",
            "Epoch: 465 | Loss: 0.5508883595466614\n",
            "Epoch: 466 | Loss: 0.5506859421730042\n",
            "Epoch: 467 | Loss: 0.5504835844039917\n",
            "Epoch: 468 | Loss: 0.5502815246582031\n",
            "Epoch: 469 | Loss: 0.5500794649124146\n",
            "Epoch: 470 | Loss: 0.5498775839805603\n",
            "Epoch: 471 | Loss: 0.5496759414672852\n",
            "Epoch: 472 | Loss: 0.5494743585586548\n",
            "Epoch: 473 | Loss: 0.549272894859314\n",
            "Epoch: 474 | Loss: 0.5490716099739075\n",
            "Epoch: 475 | Loss: 0.5488704442977905\n",
            "Epoch: 476 | Loss: 0.5486694574356079\n",
            "Epoch: 477 | Loss: 0.5484684705734253\n",
            "Epoch: 478 | Loss: 0.5482678413391113\n",
            "Epoch: 479 | Loss: 0.5480672121047974\n",
            "Epoch: 480 | Loss: 0.5478667616844177\n",
            "Epoch: 481 | Loss: 0.5476664900779724\n",
            "Epoch: 482 | Loss: 0.5474662780761719\n",
            "Epoch: 483 | Loss: 0.5472662448883057\n",
            "Epoch: 484 | Loss: 0.547066330909729\n",
            "Epoch: 485 | Loss: 0.5468665361404419\n",
            "Epoch: 486 | Loss: 0.5466669201850891\n",
            "Epoch: 487 | Loss: 0.5464674234390259\n",
            "Epoch: 488 | Loss: 0.546268105506897\n",
            "Epoch: 489 | Loss: 0.5460688471794128\n",
            "Epoch: 490 | Loss: 0.545869767665863\n",
            "Epoch: 491 | Loss: 0.5456708669662476\n",
            "Epoch: 492 | Loss: 0.5454720258712769\n",
            "Epoch: 493 | Loss: 0.5452734231948853\n",
            "Epoch: 494 | Loss: 0.5450748205184937\n",
            "Epoch: 495 | Loss: 0.5448765158653259\n",
            "Epoch: 496 | Loss: 0.5446782112121582\n",
            "Epoch: 497 | Loss: 0.5444800853729248\n",
            "Epoch: 498 | Loss: 0.5442821383476257\n",
            "Epoch: 499 | Loss: 0.5440843105316162\n",
            "Epoch: 500 | Loss: 0.5438866019248962\n",
            "Epoch: 501 | Loss: 0.5436890125274658\n",
            "Epoch: 502 | Loss: 0.5434916019439697\n",
            "Epoch: 503 | Loss: 0.5432943105697632\n",
            "Epoch: 504 | Loss: 0.543097198009491\n",
            "Epoch: 505 | Loss: 0.5429001450538635\n",
            "Epoch: 506 | Loss: 0.5427032709121704\n",
            "Epoch: 507 | Loss: 0.5425065159797668\n",
            "Epoch: 508 | Loss: 0.5423099994659424\n",
            "Epoch: 509 | Loss: 0.5421134829521179\n",
            "Epoch: 510 | Loss: 0.541917085647583\n",
            "Epoch: 511 | Loss: 0.5417209267616272\n",
            "Epoch: 512 | Loss: 0.5415248870849609\n",
            "Epoch: 513 | Loss: 0.5413289666175842\n",
            "Epoch: 514 | Loss: 0.5411331057548523\n",
            "Epoch: 515 | Loss: 0.5409374833106995\n",
            "Epoch: 516 | Loss: 0.5407419800758362\n",
            "Epoch: 517 | Loss: 0.5405465960502625\n",
            "Epoch: 518 | Loss: 0.5403513312339783\n",
            "Epoch: 519 | Loss: 0.5401561856269836\n",
            "Epoch: 520 | Loss: 0.5399612188339233\n",
            "Epoch: 521 | Loss: 0.5397663712501526\n",
            "Epoch: 522 | Loss: 0.5395717024803162\n",
            "Epoch: 523 | Loss: 0.5393770933151245\n",
            "Epoch: 524 | Loss: 0.5391826033592224\n",
            "Epoch: 525 | Loss: 0.5389883518218994\n",
            "Epoch: 526 | Loss: 0.5387941598892212\n",
            "Epoch: 527 | Loss: 0.5386002063751221\n",
            "Epoch: 528 | Loss: 0.538406252861023\n",
            "Epoch: 529 | Loss: 0.5382124781608582\n",
            "Epoch: 530 | Loss: 0.5380188226699829\n",
            "Epoch: 531 | Loss: 0.537825345993042\n",
            "Epoch: 532 | Loss: 0.5376320481300354\n",
            "Epoch: 533 | Loss: 0.5374387502670288\n",
            "Epoch: 534 | Loss: 0.5372456312179565\n",
            "Epoch: 535 | Loss: 0.5370526909828186\n",
            "Epoch: 536 | Loss: 0.5368598699569702\n",
            "Epoch: 537 | Loss: 0.5366671085357666\n",
            "Epoch: 538 | Loss: 0.5364745259284973\n",
            "Epoch: 539 | Loss: 0.5362821221351624\n",
            "Epoch: 540 | Loss: 0.5360898375511169\n",
            "Epoch: 541 | Loss: 0.5358976125717163\n",
            "Epoch: 542 | Loss: 0.5357056260108948\n",
            "Epoch: 543 | Loss: 0.5355137586593628\n",
            "Epoch: 544 | Loss: 0.5353219509124756\n",
            "Epoch: 545 | Loss: 0.5351303815841675\n",
            "Epoch: 546 | Loss: 0.5349388122558594\n",
            "Epoch: 547 | Loss: 0.5347474217414856\n",
            "Epoch: 548 | Loss: 0.5345561504364014\n",
            "Epoch: 549 | Loss: 0.5343651175498962\n",
            "Epoch: 550 | Loss: 0.5341741442680359\n",
            "Epoch: 551 | Loss: 0.5339832901954651\n",
            "Epoch: 552 | Loss: 0.5337925553321838\n",
            "Epoch: 553 | Loss: 0.5336020588874817\n",
            "Epoch: 554 | Loss: 0.5334115028381348\n",
            "Epoch: 555 | Loss: 0.5332212448120117\n",
            "Epoch: 556 | Loss: 0.5330310463905334\n",
            "Epoch: 557 | Loss: 0.5328410267829895\n",
            "Epoch: 558 | Loss: 0.5326510667800903\n",
            "Epoch: 559 | Loss: 0.5324612855911255\n",
            "Epoch: 560 | Loss: 0.5322716236114502\n",
            "Epoch: 561 | Loss: 0.5320820808410645\n",
            "Epoch: 562 | Loss: 0.5318925976753235\n",
            "Epoch: 563 | Loss: 0.5317034125328064\n",
            "Epoch: 564 | Loss: 0.5315141677856445\n",
            "Epoch: 565 | Loss: 0.5313252806663513\n",
            "Epoch: 566 | Loss: 0.5311363935470581\n",
            "Epoch: 567 | Loss: 0.5309475660324097\n",
            "Epoch: 568 | Loss: 0.5307589769363403\n",
            "Epoch: 569 | Loss: 0.5305705070495605\n",
            "Epoch: 570 | Loss: 0.5303820967674255\n",
            "Epoch: 571 | Loss: 0.5301939249038696\n",
            "Epoch: 572 | Loss: 0.5300058126449585\n",
            "Epoch: 573 | Loss: 0.5298178195953369\n",
            "Epoch: 574 | Loss: 0.5296300649642944\n",
            "Epoch: 575 | Loss: 0.5294422507286072\n",
            "Epoch: 576 | Loss: 0.5292547345161438\n",
            "Epoch: 577 | Loss: 0.5290672183036804\n",
            "Epoch: 578 | Loss: 0.5288798809051514\n",
            "Epoch: 579 | Loss: 0.5286927819252014\n",
            "Epoch: 580 | Loss: 0.5285056829452515\n",
            "Epoch: 581 | Loss: 0.5283187627792358\n",
            "Epoch: 582 | Loss: 0.5281318426132202\n",
            "Epoch: 583 | Loss: 0.5279452204704285\n",
            "Epoch: 584 | Loss: 0.5277586579322815\n",
            "Epoch: 585 | Loss: 0.5275722742080688\n",
            "Epoch: 586 | Loss: 0.5273858904838562\n",
            "Epoch: 587 | Loss: 0.5271998047828674\n",
            "Epoch: 588 | Loss: 0.5270137190818787\n",
            "Epoch: 589 | Loss: 0.526827871799469\n",
            "Epoch: 590 | Loss: 0.5266420245170593\n",
            "Epoch: 591 | Loss: 0.5264564752578735\n",
            "Epoch: 592 | Loss: 0.526270866394043\n",
            "Epoch: 593 | Loss: 0.5260854959487915\n",
            "Epoch: 594 | Loss: 0.5259002447128296\n",
            "Epoch: 595 | Loss: 0.5257150530815125\n",
            "Epoch: 596 | Loss: 0.5255299806594849\n",
            "Epoch: 597 | Loss: 0.5253451466560364\n",
            "Epoch: 598 | Loss: 0.5251603722572327\n",
            "Epoch: 599 | Loss: 0.5249757170677185\n",
            "Epoch: 600 | Loss: 0.5247912406921387\n",
            "Epoch: 601 | Loss: 0.5246068239212036\n",
            "Epoch: 602 | Loss: 0.5244225859642029\n",
            "Epoch: 603 | Loss: 0.5242384076118469\n",
            "Epoch: 604 | Loss: 0.5240544676780701\n",
            "Epoch: 605 | Loss: 0.5238705277442932\n",
            "Epoch: 606 | Loss: 0.5236868262290955\n",
            "Epoch: 607 | Loss: 0.5235031843185425\n",
            "Epoch: 608 | Loss: 0.5233197212219238\n",
            "Epoch: 609 | Loss: 0.52313631772995\n",
            "Epoch: 610 | Loss: 0.5229530930519104\n",
            "Epoch: 611 | Loss: 0.5227699875831604\n",
            "Epoch: 612 | Loss: 0.5225869417190552\n",
            "Epoch: 613 | Loss: 0.5224040746688843\n",
            "Epoch: 614 | Loss: 0.5222213268280029\n",
            "Epoch: 615 | Loss: 0.5220387578010559\n",
            "Epoch: 616 | Loss: 0.5218562483787537\n",
            "Epoch: 617 | Loss: 0.5216737985610962\n",
            "Epoch: 618 | Loss: 0.5214916467666626\n",
            "Epoch: 619 | Loss: 0.521309494972229\n",
            "Epoch: 620 | Loss: 0.5211275219917297\n",
            "Epoch: 621 | Loss: 0.5209456086158752\n",
            "Epoch: 622 | Loss: 0.5207638740539551\n",
            "Epoch: 623 | Loss: 0.5205821990966797\n",
            "Epoch: 624 | Loss: 0.5204007625579834\n",
            "Epoch: 625 | Loss: 0.5202193856239319\n",
            "Epoch: 626 | Loss: 0.5200381278991699\n",
            "Epoch: 627 | Loss: 0.5198570489883423\n",
            "Epoch: 628 | Loss: 0.5196760892868042\n",
            "Epoch: 629 | Loss: 0.5194951891899109\n",
            "Epoch: 630 | Loss: 0.5193143486976624\n",
            "Epoch: 631 | Loss: 0.5191337466239929\n",
            "Epoch: 632 | Loss: 0.518953263759613\n",
            "Epoch: 633 | Loss: 0.5187729001045227\n",
            "Epoch: 634 | Loss: 0.5185925960540771\n",
            "Epoch: 635 | Loss: 0.5184124708175659\n",
            "Epoch: 636 | Loss: 0.5182324647903442\n",
            "Epoch: 637 | Loss: 0.5180525779724121\n",
            "Epoch: 638 | Loss: 0.5178727507591248\n",
            "Epoch: 639 | Loss: 0.5176932215690613\n",
            "Epoch: 640 | Loss: 0.5175136923789978\n",
            "Epoch: 641 | Loss: 0.5173342227935791\n",
            "Epoch: 642 | Loss: 0.5171549916267395\n",
            "Epoch: 643 | Loss: 0.5169758796691895\n",
            "Epoch: 644 | Loss: 0.5167967677116394\n",
            "Epoch: 645 | Loss: 0.5166178345680237\n",
            "Epoch: 646 | Loss: 0.5164391398429871\n",
            "Epoch: 647 | Loss: 0.5162605047225952\n",
            "Epoch: 648 | Loss: 0.5160819292068481\n",
            "Epoch: 649 | Loss: 0.5159035325050354\n",
            "Epoch: 650 | Loss: 0.5157251954078674\n",
            "Epoch: 651 | Loss: 0.5155470371246338\n",
            "Epoch: 652 | Loss: 0.5153689980506897\n",
            "Epoch: 653 | Loss: 0.5151910185813904\n",
            "Epoch: 654 | Loss: 0.5150132775306702\n",
            "Epoch: 655 | Loss: 0.5148354768753052\n",
            "Epoch: 656 | Loss: 0.5146579742431641\n",
            "Epoch: 657 | Loss: 0.5144805312156677\n",
            "Epoch: 658 | Loss: 0.5143032073974609\n",
            "Epoch: 659 | Loss: 0.5141260623931885\n",
            "Epoch: 660 | Loss: 0.5139489769935608\n",
            "Epoch: 661 | Loss: 0.5137719511985779\n",
            "Epoch: 662 | Loss: 0.5135951638221741\n",
            "Epoch: 663 | Loss: 0.5134183764457703\n",
            "Epoch: 664 | Loss: 0.5132418274879456\n",
            "Epoch: 665 | Loss: 0.5130653381347656\n",
            "Epoch: 666 | Loss: 0.5128889679908752\n",
            "Epoch: 667 | Loss: 0.5127127766609192\n",
            "Epoch: 668 | Loss: 0.5125366449356079\n",
            "Epoch: 669 | Loss: 0.5123606324195862\n",
            "Epoch: 670 | Loss: 0.512184739112854\n",
            "Epoch: 671 | Loss: 0.5120090246200562\n",
            "Epoch: 672 | Loss: 0.5118333697319031\n",
            "Epoch: 673 | Loss: 0.5116578340530396\n",
            "Epoch: 674 | Loss: 0.5114824771881104\n",
            "Epoch: 675 | Loss: 0.5113071799278259\n",
            "Epoch: 676 | Loss: 0.511132001876831\n",
            "Epoch: 677 | Loss: 0.5109570026397705\n",
            "Epoch: 678 | Loss: 0.51078200340271\n",
            "Epoch: 679 | Loss: 0.5106071829795837\n",
            "Epoch: 680 | Loss: 0.5104324817657471\n",
            "Epoch: 681 | Loss: 0.5102580189704895\n",
            "Epoch: 682 | Loss: 0.5100836157798767\n",
            "Epoch: 683 | Loss: 0.5099092721939087\n",
            "Epoch: 684 | Loss: 0.5097349882125854\n",
            "Epoch: 685 | Loss: 0.5095609426498413\n",
            "Epoch: 686 | Loss: 0.5093870162963867\n",
            "Epoch: 687 | Loss: 0.5092131495475769\n",
            "Epoch: 688 | Loss: 0.5090394020080566\n",
            "Epoch: 689 | Loss: 0.5088657140731812\n",
            "Epoch: 690 | Loss: 0.5086922645568848\n",
            "Epoch: 691 | Loss: 0.5085188746452332\n",
            "Epoch: 692 | Loss: 0.5083455443382263\n",
            "Epoch: 693 | Loss: 0.5081725120544434\n",
            "Epoch: 694 | Loss: 0.5079994201660156\n",
            "Epoch: 695 | Loss: 0.507826566696167\n",
            "Epoch: 696 | Loss: 0.5076537728309631\n",
            "Epoch: 697 | Loss: 0.5074810981750488\n",
            "Epoch: 698 | Loss: 0.5073084831237793\n",
            "Epoch: 699 | Loss: 0.5071361064910889\n",
            "Epoch: 700 | Loss: 0.5069637298583984\n",
            "Epoch: 701 | Loss: 0.5067915916442871\n",
            "Epoch: 702 | Loss: 0.5066195130348206\n",
            "Epoch: 703 | Loss: 0.506447434425354\n",
            "Epoch: 704 | Loss: 0.5062756538391113\n",
            "Epoch: 705 | Loss: 0.5061038732528687\n",
            "Epoch: 706 | Loss: 0.5059322118759155\n",
            "Epoch: 707 | Loss: 0.5057607889175415\n",
            "Epoch: 708 | Loss: 0.5055893659591675\n",
            "Epoch: 709 | Loss: 0.5054181218147278\n",
            "Epoch: 710 | Loss: 0.5052469968795776\n",
            "Epoch: 711 | Loss: 0.5050759315490723\n",
            "Epoch: 712 | Loss: 0.5049049854278564\n",
            "Epoch: 713 | Loss: 0.5047341585159302\n",
            "Epoch: 714 | Loss: 0.5045634508132935\n",
            "Epoch: 715 | Loss: 0.5043929219245911\n",
            "Epoch: 716 | Loss: 0.5042224526405334\n",
            "Epoch: 717 | Loss: 0.5040520429611206\n",
            "Epoch: 718 | Loss: 0.5038818717002869\n",
            "Epoch: 719 | Loss: 0.5037117600440979\n",
            "Epoch: 720 | Loss: 0.5035417675971985\n",
            "Epoch: 721 | Loss: 0.5033718347549438\n",
            "Epoch: 722 | Loss: 0.5032021403312683\n",
            "Epoch: 723 | Loss: 0.5030325055122375\n",
            "Epoch: 724 | Loss: 0.5028629302978516\n",
            "Epoch: 725 | Loss: 0.5026935338973999\n",
            "Epoch: 726 | Loss: 0.502524197101593\n",
            "Epoch: 727 | Loss: 0.5023549795150757\n",
            "Epoch: 728 | Loss: 0.5021858811378479\n",
            "Epoch: 729 | Loss: 0.5020169019699097\n",
            "Epoch: 730 | Loss: 0.5018481016159058\n",
            "Epoch: 731 | Loss: 0.5016793012619019\n",
            "Epoch: 732 | Loss: 0.5015107989311218\n",
            "Epoch: 733 | Loss: 0.501342236995697\n",
            "Epoch: 734 | Loss: 0.5011737942695618\n",
            "Epoch: 735 | Loss: 0.5010054707527161\n",
            "Epoch: 736 | Loss: 0.5008373856544495\n",
            "Epoch: 737 | Loss: 0.5006693601608276\n",
            "Epoch: 738 | Loss: 0.5005013942718506\n",
            "Epoch: 739 | Loss: 0.5003335475921631\n",
            "Epoch: 740 | Loss: 0.5001658797264099\n",
            "Epoch: 741 | Loss: 0.4999982714653015\n",
            "Epoch: 742 | Loss: 0.49983078241348267\n",
            "Epoch: 743 | Loss: 0.49966341257095337\n",
            "Epoch: 744 | Loss: 0.4994962215423584\n",
            "Epoch: 745 | Loss: 0.4993290305137634\n",
            "Epoch: 746 | Loss: 0.4991619884967804\n",
            "Epoch: 747 | Loss: 0.4989950656890869\n",
            "Epoch: 748 | Loss: 0.49882829189300537\n",
            "Epoch: 749 | Loss: 0.4986615777015686\n",
            "Epoch: 750 | Loss: 0.4984950125217438\n",
            "Epoch: 751 | Loss: 0.4983285367488861\n",
            "Epoch: 752 | Loss: 0.4981621205806732\n",
            "Epoch: 753 | Loss: 0.49799591302871704\n",
            "Epoch: 754 | Loss: 0.497829794883728\n",
            "Epoch: 755 | Loss: 0.4976637065410614\n",
            "Epoch: 756 | Loss: 0.4974977970123291\n",
            "Epoch: 757 | Loss: 0.49733200669288635\n",
            "Epoch: 758 | Loss: 0.49716633558273315\n",
            "Epoch: 759 | Loss: 0.4970008134841919\n",
            "Epoch: 760 | Loss: 0.49683529138565063\n",
            "Epoch: 761 | Loss: 0.4966699481010437\n",
            "Epoch: 762 | Loss: 0.4965047240257263\n",
            "Epoch: 763 | Loss: 0.4963395893573761\n",
            "Epoch: 764 | Loss: 0.49617457389831543\n",
            "Epoch: 765 | Loss: 0.49600961804389954\n",
            "Epoch: 766 | Loss: 0.4958449602127075\n",
            "Epoch: 767 | Loss: 0.49568018317222595\n",
            "Epoch: 768 | Loss: 0.4955156445503235\n",
            "Epoch: 769 | Loss: 0.4953511357307434\n",
            "Epoch: 770 | Loss: 0.49518686532974243\n",
            "Epoch: 771 | Loss: 0.4950225353240967\n",
            "Epoch: 772 | Loss: 0.49485844373703003\n",
            "Epoch: 773 | Loss: 0.49469438195228577\n",
            "Epoch: 774 | Loss: 0.4945305287837982\n",
            "Epoch: 775 | Loss: 0.49436670541763306\n",
            "Epoch: 776 | Loss: 0.49420300126075745\n",
            "Epoch: 777 | Loss: 0.49403947591781616\n",
            "Epoch: 778 | Loss: 0.49387601017951965\n",
            "Epoch: 779 | Loss: 0.4937126040458679\n",
            "Epoch: 780 | Loss: 0.4935493469238281\n",
            "Epoch: 781 | Loss: 0.4933862090110779\n",
            "Epoch: 782 | Loss: 0.4932232201099396\n",
            "Epoch: 783 | Loss: 0.49306032061576843\n",
            "Epoch: 784 | Loss: 0.4928974211215973\n",
            "Epoch: 785 | Loss: 0.49273476004600525\n",
            "Epoch: 786 | Loss: 0.4925721287727356\n",
            "Epoch: 787 | Loss: 0.49240967631340027\n",
            "Epoch: 788 | Loss: 0.49224725365638733\n",
            "Epoch: 789 | Loss: 0.4920850396156311\n",
            "Epoch: 790 | Loss: 0.4919228255748749\n",
            "Epoch: 791 | Loss: 0.491760790348053\n",
            "Epoch: 792 | Loss: 0.49159887433052063\n",
            "Epoch: 793 | Loss: 0.4914371073246002\n",
            "Epoch: 794 | Loss: 0.49127528071403503\n",
            "Epoch: 795 | Loss: 0.49111369252204895\n",
            "Epoch: 796 | Loss: 0.4909522533416748\n",
            "Epoch: 797 | Loss: 0.49079084396362305\n",
            "Epoch: 798 | Loss: 0.49062952399253845\n",
            "Epoch: 799 | Loss: 0.4904683828353882\n",
            "Epoch: 800 | Loss: 0.4903072714805603\n",
            "Epoch: 801 | Loss: 0.49014630913734436\n",
            "Epoch: 802 | Loss: 0.48998546600341797\n",
            "Epoch: 803 | Loss: 0.48982468247413635\n",
            "Epoch: 804 | Loss: 0.48966410756111145\n",
            "Epoch: 805 | Loss: 0.48950356245040894\n",
            "Epoch: 806 | Loss: 0.4893431067466736\n",
            "Epoch: 807 | Loss: 0.48918282985687256\n",
            "Epoch: 808 | Loss: 0.48902255296707153\n",
            "Epoch: 809 | Loss: 0.488862544298172\n",
            "Epoch: 810 | Loss: 0.4887024760246277\n",
            "Epoch: 811 | Loss: 0.4885425865650177\n",
            "Epoch: 812 | Loss: 0.48838284611701965\n",
            "Epoch: 813 | Loss: 0.488223135471344\n",
            "Epoch: 814 | Loss: 0.4880635440349579\n",
            "Epoch: 815 | Loss: 0.4879041612148285\n",
            "Epoch: 816 | Loss: 0.4877447485923767\n",
            "Epoch: 817 | Loss: 0.48758551478385925\n",
            "Epoch: 818 | Loss: 0.4874263405799866\n",
            "Epoch: 819 | Loss: 0.48726731538772583\n",
            "Epoch: 820 | Loss: 0.487108439207077\n",
            "Epoch: 821 | Loss: 0.4869495928287506\n",
            "Epoch: 822 | Loss: 0.48679083585739136\n",
            "Epoch: 823 | Loss: 0.48663225769996643\n",
            "Epoch: 824 | Loss: 0.48647376894950867\n",
            "Epoch: 825 | Loss: 0.48631536960601807\n",
            "Epoch: 826 | Loss: 0.486157089471817\n",
            "Epoch: 827 | Loss: 0.48599886894226074\n",
            "Epoch: 828 | Loss: 0.4858408570289612\n",
            "Epoch: 829 | Loss: 0.48568281531333923\n",
            "Epoch: 830 | Loss: 0.4855249524116516\n",
            "Epoch: 831 | Loss: 0.48536717891693115\n",
            "Epoch: 832 | Loss: 0.48520955443382263\n",
            "Epoch: 833 | Loss: 0.4850519895553589\n",
            "Epoch: 834 | Loss: 0.4848945438861847\n",
            "Epoch: 835 | Loss: 0.48473721742630005\n",
            "Epoch: 836 | Loss: 0.4845799207687378\n",
            "Epoch: 837 | Loss: 0.4844227731227875\n",
            "Epoch: 838 | Loss: 0.4842657446861267\n",
            "Epoch: 839 | Loss: 0.4841088652610779\n",
            "Epoch: 840 | Loss: 0.48395201563835144\n",
            "Epoch: 841 | Loss: 0.48379525542259216\n",
            "Epoch: 842 | Loss: 0.4836387038230896\n",
            "Epoch: 843 | Loss: 0.4834822118282318\n",
            "Epoch: 844 | Loss: 0.4833257794380188\n",
            "Epoch: 845 | Loss: 0.48316943645477295\n",
            "Epoch: 846 | Loss: 0.48301324248313904\n",
            "Epoch: 847 | Loss: 0.4828571677207947\n",
            "Epoch: 848 | Loss: 0.4827011823654175\n",
            "Epoch: 849 | Loss: 0.4825453460216522\n",
            "Epoch: 850 | Loss: 0.48238953948020935\n",
            "Epoch: 851 | Loss: 0.4822339415550232\n",
            "Epoch: 852 | Loss: 0.48207834362983704\n",
            "Epoch: 853 | Loss: 0.48192286491394043\n",
            "Epoch: 854 | Loss: 0.4817675054073334\n",
            "Epoch: 855 | Loss: 0.4816122055053711\n",
            "Epoch: 856 | Loss: 0.48145705461502075\n",
            "Epoch: 857 | Loss: 0.48130202293395996\n",
            "Epoch: 858 | Loss: 0.48114705085754395\n",
            "Epoch: 859 | Loss: 0.48099225759506226\n",
            "Epoch: 860 | Loss: 0.48083749413490295\n",
            "Epoch: 861 | Loss: 0.4806828200817108\n",
            "Epoch: 862 | Loss: 0.4805282652378082\n",
            "Epoch: 863 | Loss: 0.4803738594055176\n",
            "Epoch: 864 | Loss: 0.4802194833755493\n",
            "Epoch: 865 | Loss: 0.4800652861595154\n",
            "Epoch: 866 | Loss: 0.479911208152771\n",
            "Epoch: 867 | Loss: 0.4797571003437042\n",
            "Epoch: 868 | Loss: 0.47960320115089417\n",
            "Epoch: 869 | Loss: 0.47944939136505127\n",
            "Epoch: 870 | Loss: 0.47929564118385315\n",
            "Epoch: 871 | Loss: 0.4791420102119446\n",
            "Epoch: 872 | Loss: 0.47898855805397034\n",
            "Epoch: 873 | Loss: 0.4788351356983185\n",
            "Epoch: 874 | Loss: 0.4786818027496338\n",
            "Epoch: 875 | Loss: 0.47852861881256104\n",
            "Epoch: 876 | Loss: 0.4783754050731659\n",
            "Epoch: 877 | Loss: 0.47822242975234985\n",
            "Epoch: 878 | Loss: 0.4780695140361786\n",
            "Epoch: 879 | Loss: 0.4779167175292969\n",
            "Epoch: 880 | Loss: 0.4777640402317047\n",
            "Epoch: 881 | Loss: 0.4776114225387573\n",
            "Epoch: 882 | Loss: 0.4774588942527771\n",
            "Epoch: 883 | Loss: 0.4773064851760864\n",
            "Epoch: 884 | Loss: 0.4771541953086853\n",
            "Epoch: 885 | Loss: 0.47700196504592896\n",
            "Epoch: 886 | Loss: 0.47684991359710693\n",
            "Epoch: 887 | Loss: 0.4766978621482849\n",
            "Epoch: 888 | Loss: 0.4765460193157196\n",
            "Epoch: 889 | Loss: 0.4763942062854767\n",
            "Epoch: 890 | Loss: 0.4762425124645233\n",
            "Epoch: 891 | Loss: 0.4760909080505371\n",
            "Epoch: 892 | Loss: 0.47593939304351807\n",
            "Epoch: 893 | Loss: 0.4757879972457886\n",
            "Epoch: 894 | Loss: 0.47563672065734863\n",
            "Epoch: 895 | Loss: 0.47548553347587585\n",
            "Epoch: 896 | Loss: 0.47533440589904785\n",
            "Epoch: 897 | Loss: 0.4751834273338318\n",
            "Epoch: 898 | Loss: 0.4750325083732605\n",
            "Epoch: 899 | Loss: 0.47488167881965637\n",
            "Epoch: 900 | Loss: 0.47473105788230896\n",
            "Epoch: 901 | Loss: 0.47458043694496155\n",
            "Epoch: 902 | Loss: 0.4744298756122589\n",
            "Epoch: 903 | Loss: 0.474279522895813\n",
            "Epoch: 904 | Loss: 0.47412925958633423\n",
            "Epoch: 905 | Loss: 0.47397899627685547\n",
            "Epoch: 906 | Loss: 0.47382891178131104\n",
            "Epoch: 907 | Loss: 0.47367897629737854\n",
            "Epoch: 908 | Loss: 0.47352904081344604\n",
            "Epoch: 909 | Loss: 0.4733791947364807\n",
            "Epoch: 910 | Loss: 0.4732295274734497\n",
            "Epoch: 911 | Loss: 0.4730798900127411\n",
            "Epoch: 912 | Loss: 0.4729304313659668\n",
            "Epoch: 913 | Loss: 0.4727810323238373\n",
            "Epoch: 914 | Loss: 0.47263166308403015\n",
            "Epoch: 915 | Loss: 0.47248250246047974\n",
            "Epoch: 916 | Loss: 0.4723334014415741\n",
            "Epoch: 917 | Loss: 0.47218436002731323\n",
            "Epoch: 918 | Loss: 0.4720354378223419\n",
            "Epoch: 919 | Loss: 0.47188660502433777\n",
            "Epoch: 920 | Loss: 0.4717378616333008\n",
            "Epoch: 921 | Loss: 0.47158926725387573\n",
            "Epoch: 922 | Loss: 0.47144076228141785\n",
            "Epoch: 923 | Loss: 0.47129228711128235\n",
            "Epoch: 924 | Loss: 0.4711439609527588\n",
            "Epoch: 925 | Loss: 0.47099569439888\n",
            "Epoch: 926 | Loss: 0.47084760665893555\n",
            "Epoch: 927 | Loss: 0.4706995487213135\n",
            "Epoch: 928 | Loss: 0.47055160999298096\n",
            "Epoch: 929 | Loss: 0.4704037606716156\n",
            "Epoch: 930 | Loss: 0.4702560007572174\n",
            "Epoch: 931 | Loss: 0.47010838985443115\n",
            "Epoch: 932 | Loss: 0.4699608385562897\n",
            "Epoch: 933 | Loss: 0.46981334686279297\n",
            "Epoch: 934 | Loss: 0.4696660041809082\n",
            "Epoch: 935 | Loss: 0.469518780708313\n",
            "Epoch: 936 | Loss: 0.4693715572357178\n",
            "Epoch: 937 | Loss: 0.4692245125770569\n",
            "Epoch: 938 | Loss: 0.46907752752304077\n",
            "Epoch: 939 | Loss: 0.4689306914806366\n",
            "Epoch: 940 | Loss: 0.4687838852405548\n",
            "Epoch: 941 | Loss: 0.4686371982097626\n",
            "Epoch: 942 | Loss: 0.4684906005859375\n",
            "Epoch: 943 | Loss: 0.4683440923690796\n",
            "Epoch: 944 | Loss: 0.4681977331638336\n",
            "Epoch: 945 | Loss: 0.4680514335632324\n",
            "Epoch: 946 | Loss: 0.467905193567276\n",
            "Epoch: 947 | Loss: 0.4677591025829315\n",
            "Epoch: 948 | Loss: 0.4676130414009094\n",
            "Epoch: 949 | Loss: 0.46746718883514404\n",
            "Epoch: 950 | Loss: 0.46732133626937866\n",
            "Epoch: 951 | Loss: 0.4671756327152252\n",
            "Epoch: 952 | Loss: 0.46702995896339417\n",
            "Epoch: 953 | Loss: 0.46688440442085266\n",
            "Epoch: 954 | Loss: 0.46673905849456787\n",
            "Epoch: 955 | Loss: 0.4665937125682831\n",
            "Epoch: 956 | Loss: 0.46644842624664307\n",
            "Epoch: 957 | Loss: 0.4663032591342926\n",
            "Epoch: 958 | Loss: 0.4661582410335541\n",
            "Epoch: 959 | Loss: 0.46601325273513794\n",
            "Epoch: 960 | Loss: 0.46586841344833374\n",
            "Epoch: 961 | Loss: 0.46572360396385193\n",
            "Epoch: 962 | Loss: 0.46557900309562683\n",
            "Epoch: 963 | Loss: 0.46543440222740173\n",
            "Epoch: 964 | Loss: 0.4652899205684662\n",
            "Epoch: 965 | Loss: 0.465145468711853\n",
            "Epoch: 966 | Loss: 0.4650011658668518\n",
            "Epoch: 967 | Loss: 0.4648570120334625\n",
            "Epoch: 968 | Loss: 0.46471279859542847\n",
            "Epoch: 969 | Loss: 0.4645687937736511\n",
            "Epoch: 970 | Loss: 0.46442490816116333\n",
            "Epoch: 971 | Loss: 0.4642810523509979\n",
            "Epoch: 972 | Loss: 0.46413737535476685\n",
            "Epoch: 973 | Loss: 0.46399375796318054\n",
            "Epoch: 974 | Loss: 0.4638501703739166\n",
            "Epoch: 975 | Loss: 0.46370673179626465\n",
            "Epoch: 976 | Loss: 0.46356332302093506\n",
            "Epoch: 977 | Loss: 0.4634201228618622\n",
            "Epoch: 978 | Loss: 0.4632769227027893\n",
            "Epoch: 979 | Loss: 0.4631338119506836\n",
            "Epoch: 980 | Loss: 0.4629908502101898\n",
            "Epoch: 981 | Loss: 0.4628479480743408\n",
            "Epoch: 982 | Loss: 0.4627051055431366\n",
            "Epoch: 983 | Loss: 0.4625623822212219\n",
            "Epoch: 984 | Loss: 0.4624197781085968\n",
            "Epoch: 985 | Loss: 0.46227726340293884\n",
            "Epoch: 986 | Loss: 0.46213483810424805\n",
            "Epoch: 987 | Loss: 0.4619925022125244\n",
            "Epoch: 988 | Loss: 0.46185025572776794\n",
            "Epoch: 989 | Loss: 0.461708128452301\n",
            "Epoch: 990 | Loss: 0.4615660607814789\n",
            "Epoch: 991 | Loss: 0.4614240527153015\n",
            "Epoch: 992 | Loss: 0.46128225326538086\n",
            "Epoch: 993 | Loss: 0.4611404240131378\n",
            "Epoch: 994 | Loss: 0.4609987437725067\n",
            "Epoch: 995 | Loss: 0.4608571231365204\n",
            "Epoch: 996 | Loss: 0.460715651512146\n",
            "Epoch: 997 | Loss: 0.460574209690094\n",
            "Epoch: 998 | Loss: 0.46043288707733154\n",
            "Epoch: 999 | Loss: 0.46029165387153625\n",
            "Epoch: 1000 | Loss: 0.4601505398750305\n",
            "Prediction after 1 hour of training: 0.3856 | Above 50%: False\n",
            "Prediction after 7 hour of training: 0.9692 | Above 50%: True\n",
            "Prediction after 20 hour of training: 1.0000 | Above 50%: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UpDCssRNkod7"
      },
      "source": [
        ""
      ],
      "execution_count": 16,
      "outputs": []
    }
  ]
}